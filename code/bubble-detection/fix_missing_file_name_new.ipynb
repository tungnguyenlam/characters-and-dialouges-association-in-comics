{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"T6GLHVi1ZPBseih858yD\")\n",
    "project = rf.workspace(\"ngoc-tfn96\").project(\"speech-balloons-detection-txibf\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"voc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f61b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "END_WITH_LOCAL = 'bubble-detection'\n",
    "\n",
    "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (BASE_DIR.endswith('/content') or BASE_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Move and rename the annotation folder\n",
    "source_dir = os.path.join(BASE_DIR, 'Speech-Balloons-Detection-3')\n",
    "# Note: The destination is now inside the Manga109 data folder\n",
    "dest_parent_dir = os.path.join(BASE_DIR, '../../data/Manga109/')\n",
    "final_dest_dir = os.path.join(dest_parent_dir, 'Human_Annotate_300')\n",
    "\n",
    "if os.path.isdir(source_dir):\n",
    "    try:\n",
    "        # If the destination directory already exists, remove it to ensure a clean move\n",
    "        if os.path.exists(final_dest_dir):\n",
    "            print(f\"Destination '{final_dest_dir}' already exists. Removing it.\")\n",
    "            shutil.rmtree(final_dest_dir)\n",
    "        \n",
    "        # Move and rename the directory\n",
    "        shutil.move(source_dir, final_dest_dir)\n",
    "        print(f\"Successfully moved and renamed '{source_dir}' to '{final_dest_dir}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while moving the folder: {e}\")\n",
    "else:\n",
    "    print(f\"Source folder '{source_dir}' not found. Skipping move operation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Manga109_dir = os.path.join(BASE_DIR,'../../data/Manga109/Manga109_released_2023_12_07/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471dd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f.name for f in Path(Manga109_dir).iterdir() if f.is_dir()]\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted([f.name for f in Path(Manga109_dir).iterdir() if f.is_dir()])\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718129ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_path = []\n",
    "\n",
    "# Get the first 30 sorted (case-sensitive) folders (volumes)\n",
    "first_30_volumes = sorted([f for f in Path(Manga109_dir).iterdir() if f.is_dir()], key=lambda x: x.name)[:35]\n",
    "\n",
    "# For each volume, get the first 11 images sorted in ascending order\n",
    "for volume in first_30_volumes:\n",
    "    images = sorted([f for f in volume.iterdir() if f.is_file() and f.suffix.lower() == '.jpg'], key=lambda x: x.name)\n",
    "    for img_path in images[:21]:\n",
    "        original_image_path.append(str(img_path))\n",
    "\n",
    "print(len(original_image_path))\n",
    "\n",
    "human_annotate_dir = os.path.join(BASE_DIR,'../../data/Manga109/Human_Annotate_300/train')\n",
    "\n",
    "all_img_paths = []\n",
    "\n",
    "# for root, dirs, files in os.walk(human_annotate_dir):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "#             all_img_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Only scan immediate directory (no subdirectories)\n",
    "all_img_paths = []\n",
    "for file in os.listdir(human_annotate_dir):\n",
    "    file_path = os.path.join(human_annotate_dir, file)\n",
    "    if os.path.isfile(file_path) and file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        all_img_paths.append(file_path)\n",
    "\n",
    "print(len(all_img_paths))\n",
    "\n",
    "for volume in first_30_volumes:\n",
    "    os.makedirs(os.path.join(human_annotate_dir, volume.name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566dc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "\n",
    "# Option 1: Fast hash-based comparison (fastest)\n",
    "def compare_images_hash(path1, path2):\n",
    "    \"\"\"Fast comparison using file hash\"\"\"\n",
    "    try:\n",
    "        with open(path1, 'rb') as f1, open(path2, 'rb') as f2:\n",
    "            hash1 = hashlib.md5(f1.read()).hexdigest()\n",
    "            hash2 = hashlib.md5(f2.read()).hexdigest()\n",
    "            return hash1 == hash2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Option 2: Fast perceptual hash comparison\n",
    "def compare_images_phash(path1, path2, threshold=5):\n",
    "    \"\"\"Fast perceptual hash comparison\"\"\"\n",
    "    try:\n",
    "        import imagehash\n",
    "        from PIL import Image\n",
    "        \n",
    "        img1 = Image.open(path1)\n",
    "        img2 = Image.open(path2)\n",
    "        \n",
    "        hash1 = imagehash.phash(img1)\n",
    "        hash2 = imagehash.phash(img2)\n",
    "        \n",
    "        difference = hash1 - hash2\n",
    "        return difference <= threshold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Option 3: GPU-accelerated comparison using OpenCV with Metal Performance Shaders (Mac)\n",
    "def compare_images_fast(path1, path2, threshold=0.85):\n",
    "    \"\"\"Faster comparison with reduced image size and GPU acceleration where possible\"\"\"\n",
    "    img1 = cv2.imread(path1)\n",
    "    img2 = cv2.imread(path2)\n",
    "\n",
    "    if img1 is None or img2 is None:\n",
    "        return False\n",
    "    \n",
    "    # Resize images to smaller size for faster processing\n",
    "    target_size = (256, 256)  # Much smaller for speed\n",
    "    img1_small = cv2.resize(img1, target_size)\n",
    "    img2_small = cv2.resize(img2, target_size)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1_small, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2_small, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use template matching (faster than SSIM)\n",
    "    result = cv2.matchTemplate(gray1, gray2, cv2.TM_CCOEFF_NORMED)\n",
    "    similarity_score = np.max(result)\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image Original to compare')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image in Human Annotate')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.text(0.5, 0.5, f'Similarity Score: {similarity_score:.4f}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        time.sleep(0.2)\n",
    "        plt.close()\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Option 4: Multi-threaded batch comparison\n",
    "def compare_images_batch(original_paths, human_paths, comparison_func=compare_images_fast):\n",
    "    \"\"\"Process multiple images in parallel\"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    def compare_single(args):\n",
    "        orig_path, human_path = args\n",
    "        return comparison_func(orig_path, human_path), orig_path, human_path\n",
    "    \n",
    "    # Create all combinations to compare\n",
    "    comparisons = [(orig, human) for orig in original_paths for human in human_paths]\n",
    "    \n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        results = list(executor.map(compare_single, comparisons))\n",
    "    \n",
    "    # Filter matches\n",
    "    for is_match, orig_path, human_path in results:\n",
    "        if is_match:\n",
    "            matches.append((orig_path, human_path))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Choose your comparison function:\n",
    "# For exact matches: compare_images = compare_images_hash\n",
    "# For similar images: compare_images = compare_images_phash  \n",
    "# For flexible similarity: compare_images = compare_images_fast\n",
    "\n",
    "compare_images = compare_images_fast  # Default choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "count_found = 0\n",
    "original_image_path_len = len(original_image_path)\n",
    "print(f\"Total original images to find: {original_image_path_len}\")\n",
    "all_img_paths_len = len(all_img_paths)\n",
    "print(f\"Total images in human annotate directory: {all_img_paths_len}\")\n",
    "\n",
    "for img_path in tqdm(original_image_path, desc=\"Processing original images\"):\n",
    "    copy_img_path = os.path.join(human_annotate_dir, Path(img_path).parent.name)\n",
    "    copy_img_name = Path(img_path).name\n",
    "    for img_human in all_img_paths:\n",
    "        if compare_images(img_path, img_human):\n",
    "            found = True\n",
    "            # Copy and rename the image\n",
    "            shutil.copy(img_human, os.path.join(copy_img_path, copy_img_name))\n",
    "            # Copy and rename the XML if it exists\n",
    "            xml_human = os.path.splitext(img_human)[0] + \".xml\"\n",
    "            if os.path.exists(xml_human):\n",
    "                shutil.copy(xml_human, os.path.join(copy_img_path, os.path.splitext(copy_img_name)[0] + \".xml\"))\n",
    "                os.remove(xml_human)  # Remove the xml file after copying\n",
    "            # Remove img_human from all_img_paths and delete the file\n",
    "            all_img_paths.remove(img_human)\n",
    "            os.remove(img_human)  # Remove the image file after copying\n",
    "            count_found += 1\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the remaining files in train directory which are not matched\n",
    "print(f\"Remaining unmatched images to delete: {len(all_img_paths)}\")\n",
    "\n",
    "for file_path in all_img_paths:\n",
    "    try:\n",
    "        # Delete the image file itself\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "        # Delete the corresponding XML file\n",
    "        xml_path = os.path.splitext(file_path)[0] + \".xml\"\n",
    "        if os.path.exists(xml_path):\n",
    "            os.remove(xml_path)\n",
    "            \n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting file {file_path}: {e}\")\n",
    "\n",
    "print(\"Cleanup complete. All unmatched files have been deleted from the root of the train directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to XML format\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_unique_id():\n",
    "    \"\"\"Generate a unique 8-character hex ID.\"\"\"\n",
    "    return uuid.uuid4().hex[:8]\n",
    "\n",
    "def parse_roboflow_xml(xml_file_path):\n",
    "    \"\"\"Parse a Roboflow XML file and extract bounding box information.\"\"\"\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "    \n",
    "    # Collect all relevant speech balloons/bubbles (Speech-Balloons and classes containing \"no tail\")\n",
    "    speech_balloons = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        # Check if the class is \"Speech-Balloons\" or contains \"no tail\" (case-insensitive)\n",
    "        if name == 'Speech-Balloons' or 'No tail' in name.lower():\n",
    "            bndbox = obj.find('bndbox')\n",
    "            balloon = {\n",
    "                'xmin': int(bndbox.find('xmin').text),\n",
    "                'ymin': int(bndbox.find('ymin').text),\n",
    "                'xmax': int(bndbox.find('xmax').text),\n",
    "                'ymax': int(bndbox.find('ymax').text)\n",
    "            }\n",
    "            speech_balloons.append(balloon)\n",
    "    \n",
    "    return width, height, speech_balloons\n",
    "\n",
    "def create_manga109_xml(book_title, pages_data, output_path):\n",
    "    \"\"\"Create the consolidated XML file in the target Manga109-like format.\"\"\"\n",
    "    book = ET.Element('book', title=book_title)\n",
    "    characters = ET.SubElement(book, 'characters')\n",
    "    pages = ET.SubElement(book, 'pages')\n",
    "    \n",
    "    for page_index, page_data in sorted(pages_data.items()):\n",
    "        if page_data is None:\n",
    "            # Create an empty page entry if no XML was found\n",
    "            page_elem = ET.SubElement(pages, 'page', index=str(page_index), width=\"0\", height=\"0\")\n",
    "        else:\n",
    "            width, height, speech_balloons = page_data\n",
    "            page_elem = ET.SubElement(pages, 'page', index=str(page_index), width=str(width), height=str(height))\n",
    "            \n",
    "            # Rename all collected objects as \"bubble\"\n",
    "            for balloon in speech_balloons:\n",
    "                bubble_id = generate_unique_id()\n",
    "                ET.SubElement(page_elem, 'bubble', id=bubble_id,\n",
    "                              xmin=str(balloon['xmin']),\n",
    "                              ymin=str(balloon['ymin']),\n",
    "                              xmax=str(balloon['xmax']),\n",
    "                              ymax=str(balloon['ymax']))\n",
    "    \n",
    "    xml_string = ET.tostring(book, encoding='unicode')\n",
    "    dom = minidom.parseString(xml_string)\n",
    "    pretty_xml = dom.toprettyxml(indent=\"  \")\n",
    "    \n",
    "    # Write the pretty-printed XML to the output file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        # Write without the default XML declaration line\n",
    "        f.write('\\n'.join(pretty_xml.split('\\n')[1:]))\n",
    "\n",
    "def process_book_folders(input_root, output_root):\n",
    "    \"\"\"Iterate through book folders, parse their XMLs, and create consolidated files.\"\"\"\n",
    "    input_path = Path(input_root)\n",
    "    output_path = Path(output_root)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    book_folders = [f for f in input_path.iterdir() if f.is_dir()]\n",
    "    \n",
    "    for book_folder in tqdm(book_folders, desc=\"Processing books\"):\n",
    "        book_title = book_folder.name\n",
    "        xml_files = {}\n",
    "        max_page = -1\n",
    "        \n",
    "        for xml_file in book_folder.glob('*.xml'):\n",
    "            try:\n",
    "                page_num = int(xml_file.stem)\n",
    "                xml_files[page_num] = xml_file\n",
    "                max_page = max(max_page, page_num)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        pages_data = {}\n",
    "        for page_index in range(max_page + 1):\n",
    "            if page_index in xml_files:\n",
    "                try:\n",
    "                    width, height, speech_balloons = parse_roboflow_xml(xml_files[page_index])\n",
    "                    pages_data[page_index] = (width, height, speech_balloons)\n",
    "                except Exception:\n",
    "                    pages_data[page_index] = None # Mark as empty on error\n",
    "            else:\n",
    "                pages_data[page_index] = None # Mark as empty if no XML exists\n",
    "        \n",
    "        output_xml_path = output_path / f\"{book_title}.xml\"\n",
    "        create_manga109_xml(book_title, pages_data, output_xml_path)\n",
    "\n",
    "# --- Main Execution ---\n",
    "input_directory = human_annotate_dir\n",
    "output_directory = os.path.join(os.path.dirname(human_annotate_dir), 'annotations_xml')\n",
    "\n",
    "print(f\"Starting XML transformation...\")\n",
    "print(f\"Input annotations folder: {input_directory}\")\n",
    "print(f\"Output XML folder: {output_directory}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "process_book_folders(input_directory, output_directory)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Transformation complete.\")\n",
    "print(f\"Consolidated XML files have been saved to: {output_directory}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
