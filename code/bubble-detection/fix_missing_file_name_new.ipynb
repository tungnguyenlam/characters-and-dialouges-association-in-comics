{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f61b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "END_WITH_LOCAL = 'bubble-detection'\n",
    "\n",
    "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (BASE_DIR.endswith('/content') or BASE_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Manga109_dir = os.path.join(BASE_DIR,'../../data/Manga109/Manga109/Manga109_released_2023_12_07/Manga109_released_2023_12_07/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471dd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f.name for f in Path(Manga109_dir).iterdir() if f.is_dir()]\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted([f.name for f in Path(Manga109_dir).iterdir() if f.is_dir()])\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718129ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_path = []\n",
    "\n",
    "# Get the first 30 sorted (case-sensitive) folders (volumes)\n",
    "first_30_volumes = sorted([f for f in Path(Manga109_dir).iterdir() if f.is_dir()], key=lambda x: x.name)[:35]\n",
    "\n",
    "# For each volume, get the first 11 images sorted in ascending order\n",
    "for volume in first_30_volumes:\n",
    "    images = sorted([f for f in volume.iterdir() if f.is_file() and f.suffix.lower() == '.jpg'], key=lambda x: x.name)\n",
    "    for img_path in images[:21]:\n",
    "        original_image_path.append(str(img_path))\n",
    "\n",
    "print(len(original_image_path))\n",
    "\n",
    "human_annotate_dir = os.path.join(BASE_DIR,'../../data/Human_Annotate_300/train')\n",
    "\n",
    "all_img_paths = []\n",
    "\n",
    "# for root, dirs, files in os.walk(human_annotate_dir):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "#             all_img_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Only scan immediate directory (no subdirectories)\n",
    "all_img_paths = []\n",
    "for file in os.listdir(human_annotate_dir):\n",
    "    file_path = os.path.join(human_annotate_dir, file)\n",
    "    if os.path.isfile(file_path) and file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        all_img_paths.append(file_path)\n",
    "\n",
    "print(len(all_img_paths))\n",
    "\n",
    "for volume in first_30_volumes:\n",
    "    os.makedirs(os.path.join(human_annotate_dir, volume.name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566dc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "\n",
    "# Option 1: Fast hash-based comparison (fastest)\n",
    "def compare_images_hash(path1, path2):\n",
    "    \"\"\"Fast comparison using file hash\"\"\"\n",
    "    try:\n",
    "        with open(path1, 'rb') as f1, open(path2, 'rb') as f2:\n",
    "            hash1 = hashlib.md5(f1.read()).hexdigest()\n",
    "            hash2 = hashlib.md5(f2.read()).hexdigest()\n",
    "            return hash1 == hash2\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Option 2: Fast perceptual hash comparison\n",
    "def compare_images_phash(path1, path2, threshold=5):\n",
    "    \"\"\"Fast perceptual hash comparison\"\"\"\n",
    "    try:\n",
    "        import imagehash\n",
    "        from PIL import Image\n",
    "        \n",
    "        img1 = Image.open(path1)\n",
    "        img2 = Image.open(path2)\n",
    "        \n",
    "        hash1 = imagehash.phash(img1)\n",
    "        hash2 = imagehash.phash(img2)\n",
    "        \n",
    "        difference = hash1 - hash2\n",
    "        return difference <= threshold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Option 3: GPU-accelerated comparison using OpenCV with Metal Performance Shaders (Mac)\n",
    "def compare_images_fast(path1, path2, threshold=0.85):\n",
    "    \"\"\"Faster comparison with reduced image size and GPU acceleration where possible\"\"\"\n",
    "    img1 = cv2.imread(path1)\n",
    "    img2 = cv2.imread(path2)\n",
    "\n",
    "    if img1 is None or img2 is None:\n",
    "        return False\n",
    "    \n",
    "    # Resize images to smaller size for faster processing\n",
    "    target_size = (256, 256)  # Much smaller for speed\n",
    "    img1_small = cv2.resize(img1, target_size)\n",
    "    img2_small = cv2.resize(img2, target_size)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1_small, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2_small, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use template matching (faster than SSIM)\n",
    "    result = cv2.matchTemplate(gray1, gray2, cv2.TM_CCOEFF_NORMED)\n",
    "    similarity_score = np.max(result)\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image Original to compare')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image in Human Annotate')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.text(0.5, 0.5, f'Similarity Score: {similarity_score:.4f}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        time.sleep(0.2)\n",
    "        plt.close()\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Option 4: Multi-threaded batch comparison\n",
    "def compare_images_batch(original_paths, human_paths, comparison_func=compare_images_fast):\n",
    "    \"\"\"Process multiple images in parallel\"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    def compare_single(args):\n",
    "        orig_path, human_path = args\n",
    "        return comparison_func(orig_path, human_path), orig_path, human_path\n",
    "    \n",
    "    # Create all combinations to compare\n",
    "    comparisons = [(orig, human) for orig in original_paths for human in human_paths]\n",
    "    \n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        results = list(executor.map(compare_single, comparisons))\n",
    "    \n",
    "    # Filter matches\n",
    "    for is_match, orig_path, human_path in results:\n",
    "        if is_match:\n",
    "            matches.append((orig_path, human_path))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Choose your comparison function:\n",
    "# For exact matches: compare_images = compare_images_hash\n",
    "# For similar images: compare_images = compare_images_phash  \n",
    "# For flexible similarity: compare_images = compare_images_fast\n",
    "\n",
    "compare_images = compare_images_fast  # Default choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "count_found = 0\n",
    "original_image_path_len = len(original_image_path)\n",
    "print(f\"Total original images to find: {original_image_path_len}\")\n",
    "all_img_paths_len = len(all_img_paths)\n",
    "print(f\"Total images in human annotate directory: {all_img_paths_len}\")\n",
    "\n",
    "for img_path in tqdm(original_image_path, desc=\"Processing original images\"):\n",
    "    copy_img_path = os.path.join(human_annotate_dir, Path(img_path).parent.name)\n",
    "    copy_img_name = Path(img_path).name\n",
    "    for img_human in all_img_paths:\n",
    "        if compare_images(img_path, img_human):\n",
    "            found = True\n",
    "            # Copy and rename the image\n",
    "            shutil.copy(img_human, os.path.join(copy_img_path, copy_img_name))\n",
    "            # Copy and rename the XML if it exists\n",
    "            xml_human = os.path.splitext(img_human)[0] + \".xml\"\n",
    "            if os.path.exists(xml_human):\n",
    "                shutil.copy(xml_human, os.path.join(copy_img_path, os.path.splitext(copy_img_name)[0] + \".xml\"))\n",
    "                os.remove(xml_human)  # Remove the xml file after copying\n",
    "            # Remove img_human from all_img_paths and delete the file\n",
    "            all_img_paths.remove(img_human)\n",
    "            os.remove(img_human)  # Remove the image file after copying\n",
    "            count_found += 1\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
