{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "%cd ../..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "END_WITH_LOCAL = 'put-your-folder-ending-here'\n",
    "\n",
    "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (BASE_DIR.endswith('/content') or BASE_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {BASE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a2473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T05:37:11.860677Z",
     "iopub.status.busy": "2025-10-06T05:37:11.860356Z",
     "iopub.status.idle": "2025-10-06T05:37:11.871064Z",
     "shell.execute_reply": "2025-10-06T05:37:11.870388Z",
     "shell.execute_reply.started": "2025-10-06T05:37:11.860642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Import Required Libraries ---\n",
    "\n",
    "# File and data handling\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing and visualization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd15b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T05:37:11.871982Z",
     "iopub.status.busy": "2025-10-06T05:37:11.871795Z",
     "iopub.status.idle": "2025-10-06T05:37:11.889870Z",
     "shell.execute_reply": "2025-10-06T05:37:11.889117Z",
     "shell.execute_reply.started": "2025-10-06T05:37:11.871968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Configuration Section ---\n",
    "\n",
    "# Paths to your data and model files\n",
    "JSON_DIR = os.path.join(BASE_DIR,'data','MangaSegmentation/jsons_processed')\n",
    "IMAGE_ROOT_DIR = os.path.join(BASE_DIR,'data','Manga109_released_2023_12_07/images')\n",
    "DATASET_DIR = os.path.join(BASE_DIR,'data','YOLOv8_data')\n",
    "\n",
    "# Validate paths\n",
    "print(\"\\nValidating directories...\")\n",
    "for path in [JSON_DIR, IMAGE_ROOT_DIR]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {path}\")\n",
    "    else:\n",
    "        print(f\"Found directory: {path}\")\n",
    "        # List some contents\n",
    "        contents = os.listdir(path)[:5]\n",
    "        print(f\"Sample contents: {contents}\")\n",
    "\n",
    "# Create dataset directories\n",
    "print(\"\\nCreating dataset directories...\")\n",
    "for split in ['train', 'val']:\n",
    "    for subdir in ['images', 'labels']:  \n",
    "        dir_path = os.path.join(DATASET_DIR, f'{subdir}/{split}')\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Created: {dir_path}\")\n",
    "\n",
    "# Set category information directly\n",
    "TARGET_CATEGORY_ID = 5  # Fixed category ID for balloon\n",
    "TARGET_CATEGORY_NAME = \"balloon\"  # Fixed category name\n",
    "\n",
    "print(f\"\\nTarget Category Configuration:\")\n",
    "print(f\"Category ID: {TARGET_CATEGORY_ID}\")\n",
    "print(f\"Category Name: {TARGET_CATEGORY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34a61a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T05:37:11.891319Z",
     "iopub.status.busy": "2025-10-06T05:37:11.890758Z",
     "iopub.status.idle": "2025-10-06T05:37:11.912417Z",
     "shell.execute_reply": "2025-10-06T05:37:11.911776Z",
     "shell.execute_reply.started": "2025-10-06T05:37:11.891295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "\n",
    "print(\"\\n--- 2. Preparing Data from Processed JSONs ---\")\n",
    "\n",
    "def prepare_manga_balloon_data(json_dir, image_root):\n",
    "    \"\"\"\n",
    "    Loads pre-processed JSON files (with polygons), filters for the target \n",
    "    category, and returns a list of image records. This logic is adapted \n",
    "    from your working 'train_v3 copy.ipynb'.\n",
    "    \"\"\"\n",
    "    all_images = {}\n",
    "    all_annotations = defaultdict(list)\n",
    "\n",
    "    print(\"Loading and parsing PRE-PROCESSED JSON files...\")\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Processing JSONs\"):\n",
    "        with open(os.path.join(json_dir, json_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for img_info in data.get('images', []):\n",
    "                all_images[img_info['id']] = img_info\n",
    "            for ann_info in data.get('annotations', []):\n",
    "                all_annotations[ann_info['image_id']].append(ann_info)\n",
    "\n",
    "    print(f\"Loaded data for {len(all_images)} total images.\")\n",
    "\n",
    "    dataset_records = []\n",
    "    for img_id, img_info in all_images.items():\n",
    "        # Create a base record for the image\n",
    "        record = {\n",
    "            \"file_name\": os.path.join(image_root, img_info['file_name']),\n",
    "            \"image_id\": img_id,\n",
    "            \"height\": img_info['height'],\n",
    "            \"width\": img_info['width'],\n",
    "        }\n",
    "        \n",
    "        # Filter for balloon annotations\n",
    "        balloon_annotations = []\n",
    "        for ann in all_annotations.get(img_id, []):\n",
    "            if ann.get('category_id') == TARGET_CATEGORY_ID:\n",
    "                # Ensure segmentation data is present and not empty\n",
    "                if ann.get('segmentation'):\n",
    "                    balloon_annotations.append({\n",
    "                        \"segmentation\": ann['segmentation'],\n",
    "                        \"category_id\": 0,  # All balloons will be class 0\n",
    "                    })\n",
    "        \n",
    "        # Only add images that contain at least one balloon\n",
    "        if balloon_annotations:\n",
    "            record[\"annotations\"] = balloon_annotations\n",
    "            dataset_records.append(record)\n",
    "            \n",
    "    print(f\"Data preparation complete. Found {len(dataset_records)} images containing '{TARGET_CATEGORY_NAME}'.\")\n",
    "    return dataset_records\n",
    "\n",
    "# Run the data preparation\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac6330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T05:37:11.913444Z",
     "iopub.status.busy": "2025-10-06T05:37:11.913197Z",
     "iopub.status.idle": "2025-10-06T05:37:31.622014Z",
     "shell.execute_reply": "2025-10-06T05:37:31.621064Z",
     "shell.execute_reply.started": "2025-10-06T05:37:11.913417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. Split and Prepare YOLO Dataset ---\n",
    "\n",
    "# Prepare the data\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)\n",
    "\n",
    "# --- Group data by manga title ---\n",
    "print(\"\\nGrouping data by manga series for a robust train/val split...\")\n",
    "grouped_data = defaultdict(list)\n",
    "for record in all_data:\n",
    "    manga_name = Path(record['file_name']).parts[-2]\n",
    "    grouped_data[manga_name].append(record)\n",
    "print(f\"Found {len(grouped_data)} unique manga series.\")\n",
    "\n",
    "# Split manga titles to prevent data leakage\n",
    "manga_titles = list(grouped_data.keys())\n",
    "train_titles, val_titles = train_test_split(manga_titles, test_size=0.2, random_state=42)\n",
    "print(f\"Splitting into {len(train_titles)} training series and {len(val_titles)} validation series.\")\n",
    "\n",
    "# Reconstruct train/val lists based on the title split\n",
    "train_data = [record for title in train_titles for record in grouped_data[title]]\n",
    "val_data = [record for title in val_titles for record in grouped_data[title]]\n",
    "random.Random(42).shuffle(train_data)\n",
    "random.Random(42).shuffle(val_data)\n",
    "print(f\"Final training set size: {len(train_data)} images\")\n",
    "print(f\"Final validation set size: {len(val_data)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_split_segmentation(data_split, split_type):\n",
    "    \"\"\"\n",
    "    Xử lý một tập dữ liệu để tạo bộ dữ liệu định dạng YOLOv8 INSTANCE SEGMENTATION.\n",
    "    Hàm này sẽ ghi tọa độ đa giác (polygons) đã được chuẩn hóa vào file .txt.\n",
    "    \"\"\"\n",
    "    total_annotations = 0\n",
    "    \n",
    "    for record in tqdm(data_split, desc=f\"Processing {split_type} split\"):\n",
    "        original_img_path = record['file_name']\n",
    "        img_height = record['height']\n",
    "        img_width = record['width']\n",
    "        \n",
    "        # Kiểm tra xem ảnh có tồn tại không\n",
    "        if not os.path.exists(original_img_path):\n",
    "            print(f\"Warning: Image not found at {original_img_path}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Tạo định danh duy nhất cho ảnh để tránh trùng lặp tên\n",
    "        manga_title = Path(original_img_path).parts[-2]\n",
    "        img_stem = Path(original_img_path).stem\n",
    "        img_identifier = f\"{manga_title}_{img_stem}\"\n",
    "        \n",
    "        # 1. Sao chép ảnh vào đúng thư mục train/val\n",
    "        dest_img_path = os.path.join(DATASET_DIR, f'images/{split_type}', f\"{img_identifier}.jpg\")\n",
    "        shutil.copy2(original_img_path, dest_img_path)\n",
    "        \n",
    "        # 2. Tạo file label .txt tương ứng\n",
    "        label_path = os.path.join(DATASET_DIR, f'labels/{split_type}', f\"{img_identifier}.txt\")\n",
    "        \n",
    "        # 3. Ghi tọa độ polygon đã được chuẩn hóa vào file label\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in record.get('annotations', []):\n",
    "                # Mỗi 'ann' tương ứng với một balloon (một object)\n",
    "                segmentation = ann.get('segmentation')\n",
    "                if not segmentation:\n",
    "                    continue\n",
    "                \n",
    "                # Mỗi object có thể có nhiều đa giác (trường hợp phức tạp)\n",
    "                for poly in segmentation:\n",
    "                    # Chuẩn hóa tọa độ của đa giác\n",
    "                    # poly là một list các số [x1, y1, x2, y2, ...]\n",
    "                    normalized_poly = []\n",
    "                    for i in range(0, len(poly), 2):\n",
    "                        x = poly[i] / img_width\n",
    "                        y = poly[i+1] / img_height\n",
    "                        normalized_poly.extend([x, y])\n",
    "                    \n",
    "                    # Ghi vào file theo định dạng: class_id x1 y1 x2 y2 ...\n",
    "                    # Class ID luôn là 0 vì chúng ta chỉ có 1 lớp là \"balloon\"\n",
    "                    if normalized_poly:\n",
    "                        f.write(f\"0 {' '.join(map(str, normalized_poly))}\\n\")\n",
    "                        total_annotations += 1\n",
    "    \n",
    "    return len(data_split), total_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246aa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Thực thi việc chuyển đổi dữ liệu với hàm đã sửa lỗi ---\n",
    "print(\"\\nProcessing training split...\")\n",
    "train_images_count, train_annotations_count = process_dataset_split_segmentation(train_data, 'train')\n",
    "print(\"Processing validation split...\")\n",
    "val_images_count, val_annotations_count = process_dataset_split_segmentation(val_data, 'val')\n",
    "\n",
    "# --- Kiểm tra và xác minh ---\n",
    "print(f\"\\nDataset created successfully:\")\n",
    "print(f\"Training images: {train_images_count}\")\n",
    "print(f\"Training annotations (polygons): {train_annotations_count}\")\n",
    "print(f\"Validation images: {val_images_count}\")\n",
    "print(f\"Validation annotations (polygons): {val_annotations_count}\")\n",
    "\n",
    "final_train_images = len(os.listdir(os.path.join(DATASET_DIR, 'images/train')))\n",
    "final_val_images = len(os.listdir(os.path.join(DATASET_DIR, 'images/val')))\n",
    "\n",
    "print(f\"\\nFinal verification from disk:\")\n",
    "print(f\"Total training images in folder: {final_train_images}\")\n",
    "print(f\"Total validation images in folder: {final_val_images}\")\n",
    "\n",
    "if final_train_images == len(train_data) and final_val_images == len(val_data):\n",
    "    print(\"\\nVerification successful: All images were copied correctly.\")\n",
    "else:\n",
    "    print(\"\\nVerification WARNING: Mismatch in image counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afe908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T05:37:31.635273Z",
     "iopub.status.busy": "2025-10-06T05:37:31.635061Z",
     "iopub.status.idle": "2025-10-06T05:37:34.863020Z",
     "shell.execute_reply": "2025-10-06T05:37:34.862385Z",
     "shell.execute_reply.started": "2025-10-06T05:37:31.635257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create YAML Configuration\n",
    "print(\"\\n--- 4. Creating dataset.yaml Configuration File ---\")\n",
    "\n",
    "dataset_config = {\n",
    "    'path': os.path.abspath(DATASET_DIR),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': {\n",
    "        0: TARGET_CATEGORY_NAME\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_path = Path(DATASET_DIR) / 'dataset.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"YAML configuration saved to: {yaml_path}\")\n",
    "print(\"\\nYAML Content:\")\n",
    "print(yaml.dump(dataset_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  Model Training \n",
    "# ===================================================================\n",
    "print(\"\\n--- 5. Initializing and Training YOLOv8 Model ---\")\n",
    "\n",
    "# Check for GPU and clear cache for a clean start\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU is available. Using: {device_name}\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"WARNING: No GPU found. Training will be very slow on a CPU.\")\n",
    "\n",
    "# 1. Load a pretrained YOLOv8 segmentation model\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "# 2. Train the model with essential parameters\n",
    "print(\"\\nStarting model training...\")\n",
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=5,\n",
    "    imgsz=1280,\n",
    "    batch=4,\n",
    "    project='YOLOv8_Training_Results',\n",
    "    name='balloon_segmentation_run1',\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "print(f\"All results, logs, and plots have been saved to: {model.trainer.save_dir}\")\n",
    "print(f\"The best performing model is saved as: {model.trainer.best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7903cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Automatic and Comprehensive Evaluation\n",
    "# ===================================================================\n",
    "print(\"\\n--- 6. Evaluating Final Model Performance ---\")\n",
    "\n",
    "# 1. Load the best model that was saved during training\n",
    "path_to_best_model = model.trainer.best\n",
    "if not os.path.exists(path_to_best_model):\n",
    "    raise FileNotFoundError(f\"Could not find the best model at: {path_to_best_model}\")\n",
    "\n",
    "print(f\"Loading best model from: {path_to_best_model}\")\n",
    "best_model = YOLO(path_to_best_model)\n",
    "\n",
    "# 2. Run validation on the 'val' split to get the metrics object\n",
    "print(\"\\nRunning final validation on the test set...\")\n",
    "metrics = best_model.val(\n",
    "    split='val',\n",
    "    project='YOLOv8_Training_Results',\n",
    "    name='balloon_segmentation_run1',\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "# 3. Automatically discover, group, and print all available metrics\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"--- Final Comprehensive Evaluation Report (All Metrics) ---\")\n",
    "print(\"#\"*60)\n",
    "print(f\"\\nValidation results saved to: {metrics.save_dir}\\n\")\n",
    "\n",
    "# Dictionaries to hold the grouped metrics\n",
    "box_metrics = {}\n",
    "mask_metrics = {}\n",
    "other_metrics = {}\n",
    "\n",
    "# Iterate through all key-value pairs in the results dictionary\n",
    "for key, value in metrics.results_dict.items():\n",
    "    # Clean the key by removing the 'metrics/' prefix\n",
    "    clean_key = key.replace('metrics/', '').strip()\n",
    "    \n",
    "    # Sort keys into their respective groups\n",
    "    if '(B)' in clean_key:\n",
    "        final_key = clean_key.replace('(B)', '').strip()\n",
    "        box_metrics[final_key] = value\n",
    "    elif '(M)' in clean_key:\n",
    "        final_key = clean_key.replace('(M)', '').strip()\n",
    "        mask_metrics[final_key] = value\n",
    "    else:\n",
    "        other_metrics[clean_key] = value\n",
    "\n",
    "# --- Function to print a dictionary of metrics neatly ---\n",
    "def print_metric_group(title, metric_dict):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    if not metric_dict:\n",
    "        print(\"     (No metrics found for this group)\")\n",
    "        return\n",
    "    # Sort keys for consistent ordering\n",
    "    for key in sorted(metric_dict.keys()):\n",
    "        value = metric_dict[key]\n",
    "        # Use a fixed width for the key for nice alignment\n",
    "        print(f\"     - {key:<15}: {value:.4f}\")\n",
    "\n",
    "# --- Print each group of metrics ---\n",
    "print_metric_group(\"Bounding Box Detection Performance\", box_metrics)\n",
    "print_metric_group(\"Instance Segmentation Performance\", mask_metrics)\n",
    "print_metric_group(\"Other Metrics (e.g., Losses)\", other_metrics)\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8407158,
     "sourceId": 13266819,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8408218,
     "sourceId": 13268335,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
