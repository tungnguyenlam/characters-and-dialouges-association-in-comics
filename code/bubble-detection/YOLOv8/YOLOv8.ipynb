{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae08cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Uncomment and run this cell if you haven't installed these packages\n",
    "# !pip install --quiet ultralytics opencv-python matplotlib torch torchvision tqdm\n",
    "# Note: For CUDA support, you might need to install specific torch versions\n",
    "# Visit https://pytorch.org/get-started/locally/ for installation instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a2473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Import Required Libraries ---\n",
    "\n",
    "# File and data handling\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm  # For progress bars\n",
    "\n",
    "# Print pytorch version and cuda availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd15b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration Section ---\n",
    "\n",
    "# Paths to your data and model files\n",
    "JSON_DIR = 'MangaSegmentation/jsons_processed'\n",
    "IMAGE_ROOT_DIR = 'Manga109_released_2023_12_07/Manga109_released_2023_12_07/images'\n",
    "DATASET_DIR = 'balloon_dataset'  # Directory to store YOLO format dataset\n",
    "PRE_TRAINED_MODEL_DIR = 'pre-trained_model'\n",
    "\n",
    "# Validate paths\n",
    "for path in [JSON_DIR, IMAGE_ROOT_DIR]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {path}\")\n",
    "\n",
    "# Create dataset directories\n",
    "print(\"Creating dataset directories...\")\n",
    "for split in ['train', 'val']:\n",
    "    for subdir in ['images', 'labels']:\n",
    "        dir_path = os.path.join(DATASET_DIR, f'{subdir}/{split}')\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Created: {dir_path}\")\n",
    "\n",
    "# The category we want to train on\n",
    "TARGET_CATEGORY_ID = 5\n",
    "TARGET_CATEGORY_NAME = \"balloon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "\n",
    "def xywh_to_yolo(bbox, img_width, img_height):\n",
    "    \"\"\"Convert XYWH bbox to YOLO format (x_center, y_center, width, height) normalized\"\"\"\n",
    "    # Validate input\n",
    "    if any(not isinstance(x, (int, float)) for x in bbox):\n",
    "        raise ValueError(\"Bbox coordinates must be numeric\")\n",
    "    if img_width <= 0 or img_height <= 0:\n",
    "        raise ValueError(\"Image dimensions must be positive\")\n",
    "    \n",
    "    x, y, w, h = bbox\n",
    "    # Validate bbox dimensions\n",
    "    if w <= 0 or h <= 0:\n",
    "        raise ValueError(\"Bbox width and height must be positive\")\n",
    "    if x < 0 or y < 0 or x + w > img_width or y + h > img_height:\n",
    "        raise ValueError(\"Bbox coordinates out of image bounds\")\n",
    "    \n",
    "    return [\n",
    "        (x + w/2) / img_width,  # x_center\n",
    "        (y + h/2) / img_height, # y_center\n",
    "        w / img_width,          # width\n",
    "        h / img_height          # height\n",
    "    ]\n",
    "\n",
    "def prepare_manga_balloon_data(json_dir, image_root):\n",
    "    \"\"\"\n",
    "    Loads pre-processed JSON files and filters for the target category.\n",
    "    Returns a dictionary of image paths and their corresponding annotations.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(json_dir):\n",
    "        raise FileNotFoundError(f\"JSON directory not found: {json_dir}\")\n",
    "    if not os.path.exists(image_root):\n",
    "        raise FileNotFoundError(f\"Image directory not found: {image_root}\")\n",
    "    \n",
    "    dataset_dicts = {}\n",
    "    all_images = {}\n",
    "    all_annotations = defaultdict(list)\n",
    "    \n",
    "    print(\"Loading and parsing PRE-PROCESSED JSON files...\")\n",
    "    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No JSON files found in {json_dir}\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(os.path.join(json_dir, json_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                for img_info in data['images']:\n",
    "                    all_images[img_info['id']] = img_info\n",
    "                for ann_info in data['annotations']:\n",
    "                    if ann_info['category_id'] == TARGET_CATEGORY_ID:\n",
    "                        all_annotations[ann_info['image_id']].append(ann_info)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Failed to parse {json_file}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Loaded data for {len(all_images)} total images.\")\n",
    "    \n",
    "    for img_id, img_info in all_images.items():\n",
    "        if img_id in all_annotations:  # Only include images that have balloon annotations\n",
    "            img_path = os.path.join(image_root, img_info['file_name'])\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Warning: Image not found: {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            width = img_info['width']\n",
    "            height = img_info['height']\n",
    "            \n",
    "            # Convert annotations to YOLO format\n",
    "            yolo_bboxes = []\n",
    "            for ann in all_annotations[img_id]:\n",
    "                try:\n",
    "                    yolo_bbox = xywh_to_yolo(ann['bbox'], width, height)\n",
    "                    yolo_bboxes.append(yolo_bbox)\n",
    "                except (ValueError, KeyError) as e:\n",
    "                    print(f\"Warning: Invalid bbox in {img_path}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if yolo_bboxes:  # Only include if valid annotations exist\n",
    "                dataset_dicts[img_path] = {\n",
    "                    'image_id': img_id,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'bboxes': yolo_bboxes\n",
    "                }\n",
    "            \n",
    "    if not dataset_dicts:\n",
    "        raise ValueError(\"No valid data found after processing\")\n",
    "            \n",
    "    print(f\"Finished data preparation. Found {len(dataset_dicts)} images containing '{TARGET_CATEGORY_NAME}'.\")\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing PRE-PROCESSED JSON files...\n",
      "Loaded data for 10619 total images.\n",
      "Finished data preparation. Found 9916 images containing 'balloon'.\n",
      "\n",
      "Grouping data by manga series for a robust train/val split...\n",
      "Found 109 unique manga series.\n",
      "Splitting into 87 series for training and 22 for validation.\n",
      "\n",
      "Final training set size: 8007 images\n",
      "Final validation set size: 1909 images\n",
      "Split verified: No data leakage between train and validation sets.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Split and Prepare YOLO Dataset ---\n",
    "\n",
    "# Prepare the data\n",
    "all_data = prepare_manga_balloon_data(JSON_DIR, IMAGE_ROOT_DIR)\n",
    "\n",
    "# --- Group data by manga title ---\n",
    "print(\"\\nGrouping data by manga series for a robust train/val split...\")\n",
    "grouped_data = defaultdict(dict)\n",
    "for img_path, data in all_data.items():\n",
    "    # Extract manga name from the file path\n",
    "    manga_name = Path(img_path).parent.name\n",
    "    grouped_data[manga_name][img_path] = data\n",
    "\n",
    "print(f\"Found {len(grouped_data)} unique manga series.\")\n",
    "\n",
    "# --- Split manga titles, not individual pages ---\n",
    "manga_titles = list(grouped_data.keys())\n",
    "train_titles, val_titles = train_test_split(manga_titles, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Splitting into {len(train_titles)} series for training and {len(val_titles)} for validation.\")\n",
    "\n",
    "# Function to copy images and create label files\n",
    "def process_dataset_split(titles, split_type):\n",
    "    for manga_title in titles:\n",
    "        for img_path, data in grouped_data[manga_title].items():\n",
    "            # Copy image\n",
    "            dest_img_path = os.path.join(DATASET_DIR, f'images/{split_type}', \n",
    "                                       f\"{manga_title}_{Path(img_path).name}\")\n",
    "            shutil.copy2(img_path, dest_img_path)\n",
    "            \n",
    "            # Create label file\n",
    "            label_filename = Path(dest_img_path).stem + '.txt'\n",
    "            label_path = os.path.join(DATASET_DIR, f'labels/{split_type}', label_filename)\n",
    "            \n",
    "            # Write YOLO format labels\n",
    "            with open(label_path, 'w') as f:\n",
    "                for bbox in data['bboxes']:\n",
    "                    # Class index (0 for balloon) followed by bbox coordinates\n",
    "                    f.write(f\"0 {' '.join(map(str, bbox))}\\n\")\n",
    "\n",
    "# Process train and validation splits\n",
    "print(\"\\nProcessing training split...\")\n",
    "process_dataset_split(train_titles, 'train')\n",
    "print(\"Processing validation split...\")\n",
    "process_dataset_split(val_titles, 'val')\n",
    "\n",
    "# Verify split\n",
    "train_images = len(list(Path(DATASET_DIR).glob('images/train/*.jpg')))\n",
    "val_images = len(list(Path(DATASET_DIR).glob('images/val/*.jpg')))\n",
    "print(f\"\\nDataset created successfully:\")\n",
    "print(f\"Training images: {train_images}\")\n",
    "print(f\"Validation images: {val_images}\")\n",
    "\n",
    "# Save split information\n",
    "split_info = pd.DataFrame([\n",
    "    {'manga_title': title, 'dataset_split': 'train'} for title in train_titles\n",
    "] + [\n",
    "    {'manga_title': title, 'dataset_split': 'validation'} for title in val_titles\n",
    "])\n",
    "split_info.sort_values('manga_title').to_csv('manga_split_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff75758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Train/Validation Split Summary ---\n",
      "Manga Series Split Distribution:\n",
      "                          manga_title dataset_split\n",
      "0                                ARMS    validation\n",
      "1                  AisazuNihaIrarenai         train\n",
      "2                    AkkeraKanjinchou         train\n",
      "3                             Akuhamu         train\n",
      "4                        AosugiruHaru    validation\n",
      "5                       AppareKappore         train\n",
      "6                               Arisa         train\n",
      "7                           BEMADER_P         train\n",
      "8                 BakuretsuKungFuGirl         train\n",
      "9                            Belmondo         train\n",
      "10                  BokuHaSitatakaKun    validation\n",
      "11            BurariTessenTorimonocho    validation\n",
      "12                        ByebyeC-BOY    validation\n",
      "13                Count3DeKimeteAgeru         train\n",
      "14                            DollGun         train\n",
      "15                       Donburakokko         train\n",
      "16                        DualJustice         train\n",
      "17                         EienNoWith         train\n",
      "18                            EvaLady    validation\n",
      "19                EverydayOsakanaChan         train\n",
      "20                     GOOD_KISS_Ver2         train\n",
      "21                        GakuenNoise         train\n",
      "22                    GarakutayaManta         train\n",
      "23                       GinNoChimera         train\n",
      "24                             Hamlet         train\n",
      "25   HanzaiKousyouninMinegishiEitarou         train\n",
      "26              HaruichibanNoFukukoro         train\n",
      "27                      HarukaRefrain         train\n",
      "28                      HealingPlanet         train\n",
      "29                        HeiseiJimen         train\n",
      "30          HighschoolKimengumi_vol01    validation\n",
      "31          HighschoolKimengumi_vol20         train\n",
      "32                     HinagikuKenzan         train\n",
      "33                      HisokaReturns         train\n",
      "34                      JangiriPonpon         train\n",
      "35                      JijiBabaFight         train\n",
      "36                            Joouari    validation\n",
      "37                          Jyovolley         train\n",
      "38                  KarappoHighschool         train\n",
      "39               KimiHaBokuNoTaiyouDa         train\n",
      "40                  KoukouNoHitotachi         train\n",
      "41                       KuroidoGanka         train\n",
      "42                    KyokugenCyclone    validation\n",
      "43               LancelotFullThrottle         train\n",
      "44                     LoveHina_vol01         train\n",
      "45                     LoveHina_vol14    validation\n",
      "46                          MAD_STONE         train\n",
      "47                         MadouTaiga         train\n",
      "48                    MagicStarGakuin         train\n",
      "49                       MagicianLoad         train\n",
      "50                MariaSamaNihaNaisyo         train\n",
      "51                    MayaNoAkaiKutsu         train\n",
      "52                       MemorySeijin         train\n",
      "53                 MeteoSanStrikeDesu         train\n",
      "54                           MiraiSan         train\n",
      "55                   MisutenaideDaisy         train\n",
      "56                  MoeruOnisan_vol01    validation\n",
      "57                  MoeruOnisan_vol19         train\n",
      "58                  MomoyamaHaikagura         train\n",
      "59                  MukoukizuNoChonbo         train\n",
      "60                MutekiBoukenSyakuma         train\n",
      "61                           Nekodama         train\n",
      "62                       NichijouSoup         train\n",
      "63                         Ningyoushi         train\n",
      "64                           OL_Lunch    validation\n",
      "65             OhWareraRettouSeitokai         train\n",
      "66                            PLANET7         train\n",
      "67                        ParaisoRoad         train\n",
      "68                    PikaruGenkiDesu    validation\n",
      "69                     PlatinumJungle         train\n",
      "70                  PrayerHaNemurenai    validation\n",
      "71                         PrismHeart         train\n",
      "72                        PsychoStaff    validation\n",
      "73                            Raphael         train\n",
      "74                        ReveryEarth         train\n",
      "75               RinToSiteSippuNoNaka         train\n",
      "76                         RisingGirl         train\n",
      "77                            Saisoku         train\n",
      "78                    SaladDays_vol01    validation\n",
      "79                    SaladDays_vol18    validation\n",
      "80           SamayoeruSyonenNiJunaiWo    validation\n",
      "81                     SeisinkiVulnus    validation\n",
      "82               ShimatteIkouze_vol01         train\n",
      "83               ShimatteIkouze_vol26         train\n",
      "84                        SonokiDeABC    validation\n",
      "85                    SyabondamaKieta         train\n",
      "86                      TaiyouNiSmash         train\n",
      "87                TapkunNoTanteisitsu         train\n",
      "88                    TasogareTsushin         train\n",
      "89                      TennenSenshiG         train\n",
      "90         TensiNoHaneToAkumaNoShippo         train\n",
      "91                           TetsuSan         train\n",
      "92                      That'sIzumiko         train\n",
      "93                      TotteokiNoABC         train\n",
      "94                     ToutaMairimasu         train\n",
      "95                        TouyouKidan         train\n",
      "96                     TsubasaNoKioku    validation\n",
      "97                  UchiNoNyan'sDiary         train\n",
      "98                     UchuKigekiM774         train\n",
      "99                        UltraEleven         train\n",
      "100                    UnbalanceTokyo         train\n",
      "101                WarewareHaOniDearu         train\n",
      "102                      YamatoNoHane         train\n",
      "103                      YasasiiAkuma         train\n",
      "104                 YouchienBoueigumi         train\n",
      "105                       YoumaKourin         train\n",
      "106                   YukiNoFuruMachi         train\n",
      "107                     YumeNoKayoiji    validation\n",
      "108                    YumeiroCooking         train\n",
      "\n",
      "Split summary has been saved to 'manga_split_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# --- Create, Display, and Save Split Summary ---\n",
    "# ===================================================================\n",
    "print(\"\\n--- Generating Train/Validation Split Summary ---\")\n",
    "\n",
    "# Create a list of dictionaries for the DataFrame\n",
    "train_split_info = [{'manga_title': title, 'dataset_split': 'train'} for title in train_titles]\n",
    "val_split_info = [{'manga_title': title, 'dataset_split': 'validation'} for title in val_titles]\n",
    "\n",
    "# Combine and create the DataFrame\n",
    "split_summary_df = pd.DataFrame(train_split_info + val_split_info)\n",
    "split_summary_df = split_summary_df.sort_values(by='manga_title').reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame in the notebook output\n",
    "print(\"Manga Series Split Distribution:\")\n",
    "print(split_summary_df.to_string()) # .to_string() ensures all rows are printed\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"manga_split_summary.csv\"\n",
    "split_summary_df.to_csv(csv_filename, index=False)\n",
    "print(f\"\\nSplit summary has been saved to '{csv_filename}'\")\n",
    "# ==================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afe908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuring the model for training...\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Create YAML Configuration ---\n",
    "\n",
    "# Define dataset configuration\n",
    "dataset_config = {\n",
    "    # Đường dẫn dataset\n",
    "    'path': os.path.abspath(DATASET_DIR),  # Đường dẫn tuyệt đối đến thư mục dataset\n",
    "    'train': 'images/train',               # Thư mục ảnh training\n",
    "    'val': 'images/val',                   # Thư mục ảnh validation\n",
    "    'test': 'images/val',                  # Sử dụng validation set làm test set\n",
    "    \n",
    "    # Thông tin classes\n",
    "    'names': {\n",
    "        0: TARGET_CATEGORY_NAME  # Class 0: balloon\n",
    "    },\n",
    "    \n",
    "    # Thông số task\n",
    "    'task': 'detect',           # Task: object detection\n",
    "    'nc': 1,                    # Số lượng class: 1 (balloon)\n",
    "    \n",
    "    # Thông tin thêm\n",
    "    'width': 1280,              # Kích thước ảnh đầu vào\n",
    "    'height': 1280,             # Giữ tỷ lệ 1:1 để tối ưu\n",
    "    'batch': 8,                 # Batch size khuyến nghị\n",
    "    'epochs': 100,              # Số epochs khuyến nghị\n",
    "    'device': 0,                # GPU device index\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "yaml_path = os.path.join(DATASET_DIR, 'dataset.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Dataset configuration saved to {yaml_path}\")\n",
    "print(\"\\nDataset configuration:\")\n",
    "print(yaml.dump(dataset_config, default_flow_style=False, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/04 19:03:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): CascadeROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): ModuleList(\n",
      "      (0-2): 3 x FastRCNNConvFCHead(\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc_relu1): ReLU()\n",
      "        (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (fc_relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): ModuleList(\n",
      "      (0-2): 3 x FastRCNNOutputLayers(\n",
      "        (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/04 19:03:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(1170, 1280, 1400), max_size=2000, sample_style='choice'), RandomCrop(crop_type='relative_range', crop_size=[0.8, 0.8]), RandomFlip(prob=0.5), RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomSaturation(intensity_min=0.9, intensity_max=1.1)]\n",
      "\u001b[32m[10/04 19:03:57 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 8007 images left.\n",
      "\u001b[32m[10/04 19:03:57 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  balloon   | 104137       |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/04 19:03:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/04 19:03:57 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:03:57 d2.data.common]: \u001b[0mSerializing 8007 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:03:58 d2.data.common]: \u001b[0mSerialized dataset takes 91.19 MiB\n",
      "\u001b[32m[10/04 19:03:58 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[10/04 19:03:58 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from pre-trained_model/model_final_480dd8.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.0.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.1.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.2.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.0.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.1.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.2.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Initialize and Train YOLOv8 Model ---\n",
    "\n",
    "# Kiểm tra GPU\n",
    "print(\"Checking GPU availability...\")\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Found {torch.cuda.device_count()} GPU(s)\")\n",
    "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU found. Training on CPU will be very slow!\")\n",
    "\n",
    "# Initialize YOLOv8 model\n",
    "print(\"\\nInitializing YOLOv8x model...\")\n",
    "model = YOLO('yolov8x.pt')  # Phiên bản lớn nhất và chính xác nhất\n",
    "\n",
    "# Cấu hình training cơ bản\n",
    "train_args = {\n",
    "    # [1] Cấu hình dataset\n",
    "    'data': yaml_path,         # File cấu hình dataset\n",
    "    \n",
    "    # [2] Các tham số training chính\n",
    "    'epochs': 100,            # Số epochs training\n",
    "    'imgsz': 1280,           # Kích thước ảnh đầu vào\n",
    "    'batch': 8,              # Batch size (giảm nếu GPU yếu)\n",
    "    'patience': 15,          # Early stopping nếu không cải thiện\n",
    "    \n",
    "    # [3] Tối ưu hóa\n",
    "    'lr0': 0.001,           # Learning rate ban đầu\n",
    "    'lrf': 0.01,            # Learning rate cuối\n",
    "    'weight_decay': 0.0005, # Chống overfitting\n",
    "    \n",
    "    # [4] Data augmentation cơ bản\n",
    "    'fliplr': 0.5,          # Lật ngang (balloon ở cả 2 bên)\n",
    "    'scale': 0.3,           # Thay đổi kích thước (±30%)\n",
    "    \n",
    "    # [5] Thư mục và checkpoint\n",
    "    'project': 'runs/detect',     # Thư mục gốc\n",
    "    'name': 'balloon_yolov8',     # Tên experiment\n",
    "    'exist_ok': True,             # Ghi đè thư mục cũ\n",
    "    'pretrained': True,           # Dùng pretrained weights\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',  # Tự chọn device\n",
    "}\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "for section, params in {\n",
    "    'Dataset': ['data'],\n",
    "    'Training': ['epochs', 'imgsz', 'batch', 'patience'],\n",
    "    'Optimization': ['lr0', 'lrf', 'weight_decay'],\n",
    "    'Augmentation': ['fliplr', 'scale'],\n",
    "    'Output': ['project', 'name']\n",
    "}.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for p in params:\n",
    "        print(f\"  {p}: {train_args[p]}\")\n",
    "\n",
    "# Cảnh báo và lưu ý\n",
    "print(\"\\nNOTES:\")\n",
    "print(\"- Nếu GPU yếu, hãy giảm batch_size và imgsz\")\n",
    "print(\"- Có thể thêm augmentation nếu độ chính xác thấp\")\n",
    "print(\"- Early stopping sẽ dừng sau 15 epochs không cải thiện\")\n",
    "print(\"- Model sẽ tự lưu checkpoint tốt nhất\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\u001b[32m[10/04 19:03:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zendragonxxx/.local/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/04 19:04:14 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 19  total_loss: 4.139  loss_cls_stage0: 0.8045  loss_box_reg_stage0: 0.08362  loss_cls_stage1: 0.5796  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.5901  loss_box_reg_stage2: 0.2377  loss_mask: 0.6914  loss_rpn_cls: 0.7742  loss_rpn_loc: 0.07407    time: 0.6910  last_time: 0.7113  data_time: 0.0733  last_data_time: 0.0011   lr: 1.6395e-05  max_mem: 5019M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 19:04:14.489470: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-04 19:04:14.499120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-04 19:04:14.512056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-04 19:04:14.515557: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-04 19:04:14.525054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/04 19:04:30 d2.utils.events]: \u001b[0m eta: 0:46:55  iter: 39  total_loss: 3.027  loss_cls_stage0: 0.3488  loss_box_reg_stage0: 0.08062  loss_cls_stage1: 0.3217  loss_box_reg_stage1: 0.2104  loss_cls_stage2: 0.3016  loss_box_reg_stage2: 0.2516  loss_mask: 0.6384  loss_rpn_cls: 0.7239  loss_rpn_loc: 0.07615    time: 0.7051  last_time: 0.7760  data_time: 0.0030  last_data_time: 0.0010   lr: 3.2776e-05  max_mem: 5315M\n",
      "\u001b[32m[10/04 19:04:44 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 59  total_loss: 2.333  loss_cls_stage0: 0.1922  loss_box_reg_stage0: 0.06893  loss_cls_stage1: 0.1968  loss_box_reg_stage1: 0.1719  loss_cls_stage2: 0.1817  loss_box_reg_stage2: 0.1766  loss_mask: 0.5392  loss_rpn_cls: 0.6142  loss_rpn_loc: 0.09681    time: 0.7152  last_time: 0.7727  data_time: 0.0030  last_data_time: 0.0010   lr: 4.9157e-05  max_mem: 5429M\n",
      "\u001b[32m[10/04 19:04:59 d2.utils.events]: \u001b[0m eta: 0:47:21  iter: 79  total_loss: 2.098  loss_cls_stage0: 0.1864  loss_box_reg_stage0: 0.06934  loss_cls_stage1: 0.187  loss_box_reg_stage1: 0.1762  loss_cls_stage2: 0.1747  loss_box_reg_stage2: 0.1752  loss_mask: 0.4444  loss_rpn_cls: 0.495  loss_rpn_loc: 0.1099    time: 0.7181  last_time: 0.7983  data_time: 0.0029  last_data_time: 0.0011   lr: 6.5538e-05  max_mem: 5429M\n",
      "\u001b[32m[10/04 19:05:13 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 99  total_loss: 1.947  loss_cls_stage0: 0.198  loss_box_reg_stage0: 0.06886  loss_cls_stage1: 0.2068  loss_box_reg_stage1: 0.1866  loss_cls_stage2: 0.1996  loss_box_reg_stage2: 0.2225  loss_mask: 0.376  loss_rpn_cls: 0.358  loss_rpn_loc: 0.07061    time: 0.7179  last_time: 0.6680  data_time: 0.0028  last_data_time: 0.0009   lr: 8.1919e-05  max_mem: 5429M\n",
      "\u001b[32m[10/04 19:05:28 d2.utils.events]: \u001b[0m eta: 0:46:52  iter: 119  total_loss: 1.893  loss_cls_stage0: 0.1907  loss_box_reg_stage0: 0.09132  loss_cls_stage1: 0.1933  loss_box_reg_stage1: 0.1978  loss_cls_stage2: 0.202  loss_box_reg_stage2: 0.2329  loss_mask: 0.3236  loss_rpn_cls: 0.2575  loss_rpn_loc: 0.08157    time: 0.7251  last_time: 0.8349  data_time: 0.0032  last_data_time: 0.0029   lr: 9.8299e-05  max_mem: 5536M\n",
      "\u001b[32m[10/04 19:05:43 d2.utils.events]: \u001b[0m eta: 0:46:48  iter: 139  total_loss: 1.294  loss_cls_stage0: 0.1422  loss_box_reg_stage0: 0.0558  loss_cls_stage1: 0.149  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.1657  loss_box_reg_stage2: 0.1978  loss_mask: 0.275  loss_rpn_cls: 0.1846  loss_rpn_loc: 0.09723    time: 0.7278  last_time: 0.7991  data_time: 0.0037  last_data_time: 0.0083   lr: 0.00011468  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:05:58 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 159  total_loss: 1.503  loss_cls_stage0: 0.146  loss_box_reg_stage0: 0.07395  loss_cls_stage1: 0.1514  loss_box_reg_stage1: 0.1832  loss_cls_stage2: 0.1667  loss_box_reg_stage2: 0.2594  loss_mask: 0.2743  loss_rpn_cls: 0.1408  loss_rpn_loc: 0.08834    time: 0.7278  last_time: 0.6414  data_time: 0.0030  last_data_time: 0.0094   lr: 0.00013106  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:06:13 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 179  total_loss: 1.443  loss_cls_stage0: 0.1299  loss_box_reg_stage0: 0.07251  loss_cls_stage1: 0.138  loss_box_reg_stage1: 0.1862  loss_cls_stage2: 0.1582  loss_box_reg_stage2: 0.2933  loss_mask: 0.2271  loss_rpn_cls: 0.1462  loss_rpn_loc: 0.09644    time: 0.7310  last_time: 0.6645  data_time: 0.0032  last_data_time: 0.0066   lr: 0.00014744  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:06:28 d2.utils.events]: \u001b[0m eta: 0:46:28  iter: 199  total_loss: 1.324  loss_cls_stage0: 0.1038  loss_box_reg_stage0: 0.08258  loss_cls_stage1: 0.1126  loss_box_reg_stage1: 0.1863  loss_cls_stage2: 0.1244  loss_box_reg_stage2: 0.2849  loss_mask: 0.1746  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.1044    time: 0.7346  last_time: 0.6929  data_time: 0.0033  last_data_time: 0.0092   lr: 0.00016382  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:06:43 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 219  total_loss: 1.495  loss_cls_stage0: 0.1102  loss_box_reg_stage0: 0.1122  loss_cls_stage1: 0.116  loss_box_reg_stage1: 0.2168  loss_cls_stage2: 0.1321  loss_box_reg_stage2: 0.3251  loss_mask: 0.1738  loss_rpn_cls: 0.09815  loss_rpn_loc: 0.06129    time: 0.7371  last_time: 0.7999  data_time: 0.0030  last_data_time: 0.0076   lr: 0.0001802  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:06:59 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 239  total_loss: 1.405  loss_cls_stage0: 0.1028  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.09768  loss_box_reg_stage1: 0.2261  loss_cls_stage2: 0.1144  loss_box_reg_stage2: 0.3283  loss_mask: 0.1459  loss_rpn_cls: 0.09858  loss_rpn_loc: 0.07961    time: 0.7393  last_time: 0.8884  data_time: 0.0029  last_data_time: 0.0094   lr: 0.00019658  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:07:14 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 259  total_loss: 1.436  loss_cls_stage0: 0.08829  loss_box_reg_stage0: 0.1483  loss_cls_stage1: 0.09392  loss_box_reg_stage1: 0.3043  loss_cls_stage2: 0.1195  loss_box_reg_stage2: 0.3785  loss_mask: 0.1407  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.06849    time: 0.7412  last_time: 0.8230  data_time: 0.0030  last_data_time: 0.0054   lr: 0.00021297  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:07:29 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 279  total_loss: 1.331  loss_cls_stage0: 0.09185  loss_box_reg_stage0: 0.1172  loss_cls_stage1: 0.08665  loss_box_reg_stage1: 0.2491  loss_cls_stage2: 0.1047  loss_box_reg_stage2: 0.363  loss_mask: 0.1178  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.06871    time: 0.7408  last_time: 0.6810  data_time: 0.0029  last_data_time: 0.0074   lr: 0.00022935  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:07:44 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 299  total_loss: 1.24  loss_cls_stage0: 0.06854  loss_box_reg_stage0: 0.1158  loss_cls_stage1: 0.07376  loss_box_reg_stage1: 0.2397  loss_cls_stage2: 0.08372  loss_box_reg_stage2: 0.3636  loss_mask: 0.0935  loss_rpn_cls: 0.06673  loss_rpn_loc: 0.05323    time: 0.7418  last_time: 0.7723  data_time: 0.0029  last_data_time: 0.0079   lr: 0.00024573  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:07:59 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 319  total_loss: 1.226  loss_cls_stage0: 0.07146  loss_box_reg_stage0: 0.1235  loss_cls_stage1: 0.06301  loss_box_reg_stage1: 0.2534  loss_cls_stage2: 0.06934  loss_box_reg_stage2: 0.3719  loss_mask: 0.09887  loss_rpn_cls: 0.07023  loss_rpn_loc: 0.06297    time: 0.7412  last_time: 0.7122  data_time: 0.0032  last_data_time: 0.0076   lr: 0.0002461  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:08:13 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 339  total_loss: 1.321  loss_cls_stage0: 0.07511  loss_box_reg_stage0: 0.1337  loss_cls_stage1: 0.0607  loss_box_reg_stage1: 0.2569  loss_cls_stage2: 0.07793  loss_box_reg_stage2: 0.4142  loss_mask: 0.08881  loss_rpn_cls: 0.07496  loss_rpn_loc: 0.07936    time: 0.7417  last_time: 0.8545  data_time: 0.0030  last_data_time: 0.0082   lr: 0.0002456  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:08:29 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 359  total_loss: 1.34  loss_cls_stage0: 0.0709  loss_box_reg_stage0: 0.1349  loss_cls_stage1: 0.06621  loss_box_reg_stage1: 0.2797  loss_cls_stage2: 0.06616  loss_box_reg_stage2: 0.4094  loss_mask: 0.08686  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.08095    time: 0.7424  last_time: 0.6103  data_time: 0.0030  last_data_time: 0.0082   lr: 0.00024506  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:08:44 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 379  total_loss: 1.304  loss_cls_stage0: 0.06302  loss_box_reg_stage0: 0.1538  loss_cls_stage1: 0.05658  loss_box_reg_stage1: 0.2724  loss_cls_stage2: 0.07484  loss_box_reg_stage2: 0.4113  loss_mask: 0.08319  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.07534    time: 0.7431  last_time: 0.6776  data_time: 0.0030  last_data_time: 0.0080   lr: 0.0002445  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:08:59 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  balloon   | 26039        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[10/04 19:08:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 19:08:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:08:59 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:09:00 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 19:09:00 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'manga_balloon_val' to COCO format ...\n",
      "\u001b[32m[10/04 19:09:00 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'manga_balloon_val' to COCO format ...)\n",
      "\u001b[32m[10/04 19:09:00 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[10/04 19:09:01 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 1909, #annotations: 26039\n",
      "\u001b[32m[10/04 19:09:01 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output_balloon_segmentation_v2/inference/manga_balloon_val_coco_format.json' ...\n",
      "\u001b[32m[10/04 19:09:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 19:09:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0006 s/iter. Inference: 0.1180 s/iter. Eval: 0.1025 s/iter. Total: 0.2211 s/iter. ETA=0:06:59\n",
      "\u001b[32m[10/04 19:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 33/1909. Dataloading: 0.0007 s/iter. Inference: 0.1198 s/iter. Eval: 0.1113 s/iter. Total: 0.2319 s/iter. ETA=0:07:15\n",
      "\u001b[32m[10/04 19:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 55/1909. Dataloading: 0.0008 s/iter. Inference: 0.1202 s/iter. Eval: 0.1116 s/iter. Total: 0.2327 s/iter. ETA=0:07:11\n",
      "\u001b[32m[10/04 19:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 77/1909. Dataloading: 0.0008 s/iter. Inference: 0.1201 s/iter. Eval: 0.1104 s/iter. Total: 0.2314 s/iter. ETA=0:07:04\n",
      "\u001b[32m[10/04 19:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 101/1909. Dataloading: 0.0008 s/iter. Inference: 0.1195 s/iter. Eval: 0.1074 s/iter. Total: 0.2278 s/iter. ETA=0:06:51\n",
      "\u001b[32m[10/04 19:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 120/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1127 s/iter. Total: 0.2350 s/iter. ETA=0:07:00\n",
      "\u001b[32m[10/04 19:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 144/1909. Dataloading: 0.0009 s/iter. Inference: 0.1205 s/iter. Eval: 0.1100 s/iter. Total: 0.2314 s/iter. ETA=0:06:48\n",
      "\u001b[32m[10/04 19:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 165/1909. Dataloading: 0.0009 s/iter. Inference: 0.1204 s/iter. Eval: 0.1119 s/iter. Total: 0.2332 s/iter. ETA=0:06:46\n",
      "\u001b[32m[10/04 19:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 187/1909. Dataloading: 0.0009 s/iter. Inference: 0.1203 s/iter. Eval: 0.1121 s/iter. Total: 0.2333 s/iter. ETA=0:06:41\n",
      "\u001b[32m[10/04 19:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 209/1909. Dataloading: 0.0009 s/iter. Inference: 0.1202 s/iter. Eval: 0.1123 s/iter. Total: 0.2334 s/iter. ETA=0:06:36\n",
      "\u001b[32m[10/04 19:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 232/1909. Dataloading: 0.0009 s/iter. Inference: 0.1199 s/iter. Eval: 0.1113 s/iter. Total: 0.2321 s/iter. ETA=0:06:29\n",
      "\u001b[32m[10/04 19:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 250/1909. Dataloading: 0.0009 s/iter. Inference: 0.1203 s/iter. Eval: 0.1146 s/iter. Total: 0.2358 s/iter. ETA=0:06:31\n",
      "\u001b[32m[10/04 19:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 277/1909. Dataloading: 0.0009 s/iter. Inference: 0.1196 s/iter. Eval: 0.1112 s/iter. Total: 0.2318 s/iter. ETA=0:06:18\n",
      "\u001b[32m[10/04 19:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 301/1909. Dataloading: 0.0009 s/iter. Inference: 0.1194 s/iter. Eval: 0.1101 s/iter. Total: 0.2305 s/iter. ETA=0:06:10\n",
      "\u001b[32m[10/04 19:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 322/1909. Dataloading: 0.0009 s/iter. Inference: 0.1196 s/iter. Eval: 0.1106 s/iter. Total: 0.2311 s/iter. ETA=0:06:06\n",
      "\u001b[32m[10/04 19:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 345/1909. Dataloading: 0.0009 s/iter. Inference: 0.1195 s/iter. Eval: 0.1104 s/iter. Total: 0.2309 s/iter. ETA=0:06:01\n",
      "\u001b[32m[10/04 19:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 365/1909. Dataloading: 0.0009 s/iter. Inference: 0.1197 s/iter. Eval: 0.1116 s/iter. Total: 0.2322 s/iter. ETA=0:05:58\n",
      "\u001b[32m[10/04 19:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 387/1909. Dataloading: 0.0009 s/iter. Inference: 0.1197 s/iter. Eval: 0.1115 s/iter. Total: 0.2321 s/iter. ETA=0:05:53\n",
      "\u001b[32m[10/04 19:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 408/1909. Dataloading: 0.0009 s/iter. Inference: 0.1198 s/iter. Eval: 0.1122 s/iter. Total: 0.2329 s/iter. ETA=0:05:49\n",
      "\u001b[32m[10/04 19:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 430/1909. Dataloading: 0.0009 s/iter. Inference: 0.1198 s/iter. Eval: 0.1120 s/iter. Total: 0.2327 s/iter. ETA=0:05:44\n",
      "\u001b[32m[10/04 19:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 453/1909. Dataloading: 0.0009 s/iter. Inference: 0.1198 s/iter. Eval: 0.1115 s/iter. Total: 0.2322 s/iter. ETA=0:05:38\n",
      "\u001b[32m[10/04 19:10:56 d2.evaluation.evaluator]: \u001b[0mInference done 476/1909. Dataloading: 0.0009 s/iter. Inference: 0.1198 s/iter. Eval: 0.1110 s/iter. Total: 0.2317 s/iter. ETA=0:05:32\n",
      "\u001b[32m[10/04 19:11:01 d2.evaluation.evaluator]: \u001b[0mInference done 497/1909. Dataloading: 0.0009 s/iter. Inference: 0.1199 s/iter. Eval: 0.1116 s/iter. Total: 0.2324 s/iter. ETA=0:05:28\n",
      "\u001b[32m[10/04 19:11:06 d2.evaluation.evaluator]: \u001b[0mInference done 516/1909. Dataloading: 0.0009 s/iter. Inference: 0.1201 s/iter. Eval: 0.1127 s/iter. Total: 0.2338 s/iter. ETA=0:05:25\n",
      "\u001b[32m[10/04 19:11:11 d2.evaluation.evaluator]: \u001b[0mInference done 534/1909. Dataloading: 0.0009 s/iter. Inference: 0.1204 s/iter. Eval: 0.1141 s/iter. Total: 0.2354 s/iter. ETA=0:05:23\n",
      "\u001b[32m[10/04 19:11:17 d2.evaluation.evaluator]: \u001b[0mInference done 556/1909. Dataloading: 0.0009 s/iter. Inference: 0.1205 s/iter. Eval: 0.1145 s/iter. Total: 0.2360 s/iter. ETA=0:05:19\n",
      "\u001b[32m[10/04 19:11:22 d2.evaluation.evaluator]: \u001b[0mInference done 578/1909. Dataloading: 0.0009 s/iter. Inference: 0.1206 s/iter. Eval: 0.1152 s/iter. Total: 0.2367 s/iter. ETA=0:05:15\n",
      "\u001b[32m[10/04 19:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 599/1909. Dataloading: 0.0009 s/iter. Inference: 0.1207 s/iter. Eval: 0.1153 s/iter. Total: 0.2369 s/iter. ETA=0:05:10\n",
      "\u001b[32m[10/04 19:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 620/1909. Dataloading: 0.0009 s/iter. Inference: 0.1207 s/iter. Eval: 0.1156 s/iter. Total: 0.2373 s/iter. ETA=0:05:05\n",
      "\u001b[32m[10/04 19:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 641/1909. Dataloading: 0.0009 s/iter. Inference: 0.1208 s/iter. Eval: 0.1158 s/iter. Total: 0.2375 s/iter. ETA=0:05:01\n",
      "\u001b[32m[10/04 19:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 662/1909. Dataloading: 0.0009 s/iter. Inference: 0.1208 s/iter. Eval: 0.1159 s/iter. Total: 0.2376 s/iter. ETA=0:04:56\n",
      "\u001b[32m[10/04 19:11:48 d2.evaluation.evaluator]: \u001b[0mInference done 683/1909. Dataloading: 0.0009 s/iter. Inference: 0.1208 s/iter. Eval: 0.1160 s/iter. Total: 0.2378 s/iter. ETA=0:04:51\n",
      "\u001b[32m[10/04 19:11:53 d2.evaluation.evaluator]: \u001b[0mInference done 705/1909. Dataloading: 0.0009 s/iter. Inference: 0.1207 s/iter. Eval: 0.1159 s/iter. Total: 0.2376 s/iter. ETA=0:04:46\n",
      "\u001b[32m[10/04 19:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 725/1909. Dataloading: 0.0009 s/iter. Inference: 0.1208 s/iter. Eval: 0.1164 s/iter. Total: 0.2382 s/iter. ETA=0:04:41\n",
      "\u001b[32m[10/04 19:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 744/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1177 s/iter. Total: 0.2397 s/iter. ETA=0:04:39\n",
      "\u001b[32m[10/04 19:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 765/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1177 s/iter. Total: 0.2397 s/iter. ETA=0:04:34\n",
      "\u001b[32m[10/04 19:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 786/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1178 s/iter. Total: 0.2399 s/iter. ETA=0:04:29\n",
      "\u001b[32m[10/04 19:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 810/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1174 s/iter. Total: 0.2393 s/iter. ETA=0:04:23\n",
      "\u001b[32m[10/04 19:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 833/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1171 s/iter. Total: 0.2390 s/iter. ETA=0:04:17\n",
      "\u001b[32m[10/04 19:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 853/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1175 s/iter. Total: 0.2395 s/iter. ETA=0:04:12\n",
      "\u001b[32m[10/04 19:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 877/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1170 s/iter. Total: 0.2390 s/iter. ETA=0:04:06\n",
      "\u001b[32m[10/04 19:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 899/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1169 s/iter. Total: 0.2389 s/iter. ETA=0:04:01\n",
      "\u001b[32m[10/04 19:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 920/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1171 s/iter. Total: 0.2390 s/iter. ETA=0:03:56\n",
      "\u001b[32m[10/04 19:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 944/1909. Dataloading: 0.0009 s/iter. Inference: 0.1209 s/iter. Eval: 0.1164 s/iter. Total: 0.2383 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/04 19:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 965/1909. Dataloading: 0.0009 s/iter. Inference: 0.1209 s/iter. Eval: 0.1165 s/iter. Total: 0.2384 s/iter. ETA=0:03:45\n",
      "\u001b[32m[10/04 19:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 985/1909. Dataloading: 0.0009 s/iter. Inference: 0.1209 s/iter. Eval: 0.1170 s/iter. Total: 0.2389 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 19:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 1005/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1171 s/iter. Total: 0.2391 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 19:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 1027/1909. Dataloading: 0.0009 s/iter. Inference: 0.1210 s/iter. Eval: 0.1171 s/iter. Total: 0.2390 s/iter. ETA=0:03:30\n",
      "\u001b[32m[10/04 19:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 1046/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1175 s/iter. Total: 0.2396 s/iter. ETA=0:03:26\n",
      "\u001b[32m[10/04 19:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 1068/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1174 s/iter. Total: 0.2394 s/iter. ETA=0:03:21\n",
      "\u001b[32m[10/04 19:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 1087/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1178 s/iter. Total: 0.2399 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/04 19:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 1108/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1178 s/iter. Total: 0.2400 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/04 19:13:37 d2.evaluation.evaluator]: \u001b[0mInference done 1131/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1175 s/iter. Total: 0.2396 s/iter. ETA=0:03:06\n",
      "\u001b[32m[10/04 19:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 1153/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1174 s/iter. Total: 0.2395 s/iter. ETA=0:03:01\n",
      "\u001b[32m[10/04 19:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 1174/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1175 s/iter. Total: 0.2396 s/iter. ETA=0:02:56\n",
      "\u001b[32m[10/04 19:13:52 d2.evaluation.evaluator]: \u001b[0mInference done 1196/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1174 s/iter. Total: 0.2395 s/iter. ETA=0:02:50\n",
      "\u001b[32m[10/04 19:13:57 d2.evaluation.evaluator]: \u001b[0mInference done 1218/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1173 s/iter. Total: 0.2395 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 19:14:02 d2.evaluation.evaluator]: \u001b[0mInference done 1240/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1172 s/iter. Total: 0.2394 s/iter. ETA=0:02:40\n",
      "\u001b[32m[10/04 19:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 1265/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1166 s/iter. Total: 0.2387 s/iter. ETA=0:02:33\n",
      "\u001b[32m[10/04 19:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 1285/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1169 s/iter. Total: 0.2390 s/iter. ETA=0:02:29\n",
      "\u001b[32m[10/04 19:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 1305/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1170 s/iter. Total: 0.2392 s/iter. ETA=0:02:24\n",
      "\u001b[32m[10/04 19:14:23 d2.evaluation.evaluator]: \u001b[0mInference done 1329/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1166 s/iter. Total: 0.2388 s/iter. ETA=0:02:18\n",
      "\u001b[32m[10/04 19:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 1347/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1172 s/iter. Total: 0.2394 s/iter. ETA=0:02:14\n",
      "\u001b[32m[10/04 19:14:33 d2.evaluation.evaluator]: \u001b[0mInference done 1368/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1171 s/iter. Total: 0.2394 s/iter. ETA=0:02:09\n",
      "\u001b[32m[10/04 19:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1167 s/iter. Total: 0.2389 s/iter. ETA=0:02:03\n",
      "\u001b[32m[10/04 19:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 1414/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1166 s/iter. Total: 0.2388 s/iter. ETA=0:01:58\n",
      "\u001b[32m[10/04 19:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 1436/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1165 s/iter. Total: 0.2388 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/04 19:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 1457/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1166 s/iter. Total: 0.2388 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/04 19:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 1476/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1170 s/iter. Total: 0.2392 s/iter. ETA=0:01:43\n",
      "\u001b[32m[10/04 19:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 1500/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1169 s/iter. Total: 0.2391 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/04 19:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 1520/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1171 s/iter. Total: 0.2394 s/iter. ETA=0:01:33\n",
      "\u001b[32m[10/04 19:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 1543/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1169 s/iter. Total: 0.2391 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/04 19:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 1566/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1167 s/iter. Total: 0.2388 s/iter. ETA=0:01:21\n",
      "\u001b[32m[10/04 19:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 1587/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1167 s/iter. Total: 0.2389 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/04 19:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 1604/1909. Dataloading: 0.0009 s/iter. Inference: 0.1213 s/iter. Eval: 0.1174 s/iter. Total: 0.2396 s/iter. ETA=0:01:13\n",
      "\u001b[32m[10/04 19:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 1626/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1172 s/iter. Total: 0.2395 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/04 19:15:40 d2.evaluation.evaluator]: \u001b[0mInference done 1650/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1171 s/iter. Total: 0.2393 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/04 19:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 1670/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1172 s/iter. Total: 0.2394 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/04 19:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 1694/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1169 s/iter. Total: 0.2390 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/04 19:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 1717/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1168 s/iter. Total: 0.2389 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/04 19:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 1738/1909. Dataloading: 0.0009 s/iter. Inference: 0.1212 s/iter. Eval: 0.1169 s/iter. Total: 0.2390 s/iter. ETA=0:00:40\n",
      "\u001b[32m[10/04 19:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 1761/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1167 s/iter. Total: 0.2388 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/04 19:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 1782/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1167 s/iter. Total: 0.2388 s/iter. ETA=0:00:30\n",
      "\u001b[32m[10/04 19:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 1806/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1166 s/iter. Total: 0.2387 s/iter. ETA=0:00:24\n",
      "\u001b[32m[10/04 19:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 1825/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1169 s/iter. Total: 0.2390 s/iter. ETA=0:00:20\n",
      "\u001b[32m[10/04 19:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 1846/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1169 s/iter. Total: 0.2391 s/iter. ETA=0:00:15\n",
      "\u001b[32m[10/04 19:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 1870/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1167 s/iter. Total: 0.2387 s/iter. ETA=0:00:09\n",
      "\u001b[32m[10/04 19:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 1893/1909. Dataloading: 0.0009 s/iter. Inference: 0.1211 s/iter. Eval: 0.1165 s/iter. Total: 0.2386 s/iter. ETA=0:00:03\n",
      "\u001b[32m[10/04 19:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:07:34.098509 (0.238497 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:50 (0.121035 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:16:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 19:16:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
      "\u001b[32m[10/04 19:16:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 63.894 | 75.690 | 69.461 | 0.000 | 47.162 | 73.740 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:16:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 19:16:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.81 seconds.\n",
      "\u001b[32m[10/04 19:16:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.773\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.872\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 67.946 | 77.092 | 72.291 | 0.000 | 47.575 | 78.397 |\n",
      "\u001b[32m[10/04 19:16:46 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: 63.8940,75.6900,69.4610,0.0000,47.1620,73.7398\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:16:46 d2.evaluation.testing]: \u001b[0mcopypaste: 67.9463,77.0916,72.2910,0.0000,47.5753,78.3965\n",
      "\u001b[32m[10/04 19:16:46 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 399  total_loss: 1.089  loss_cls_stage0: 0.05696  loss_box_reg_stage0: 0.1273  loss_cls_stage1: 0.05276  loss_box_reg_stage1: 0.2379  loss_cls_stage2: 0.06309  loss_box_reg_stage2: 0.369  loss_mask: 0.0784  loss_rpn_cls: 0.0578  loss_rpn_loc: 0.05768    time: 0.7441  last_time: 0.7661  data_time: 0.0030  last_data_time: 0.0076   lr: 0.00024391  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:17:01 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 419  total_loss: 1.291  loss_cls_stage0: 0.06772  loss_box_reg_stage0: 0.1473  loss_cls_stage1: 0.07715  loss_box_reg_stage1: 0.2555  loss_cls_stage2: 0.07959  loss_box_reg_stage2: 0.3605  loss_mask: 0.08335  loss_rpn_cls: 0.06086  loss_rpn_loc: 0.07391    time: 0.7453  last_time: 0.6154  data_time: 0.0029  last_data_time: 0.0039   lr: 0.00024329  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:17:17 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 439  total_loss: 1.253  loss_cls_stage0: 0.06497  loss_box_reg_stage0: 0.1277  loss_cls_stage1: 0.06011  loss_box_reg_stage1: 0.2327  loss_cls_stage2: 0.06532  loss_box_reg_stage2: 0.3447  loss_mask: 0.07995  loss_rpn_cls: 0.05206  loss_rpn_loc: 0.06989    time: 0.7475  last_time: 0.8729  data_time: 0.0035  last_data_time: 0.0059   lr: 0.00024264  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:17:33 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 459  total_loss: 1.253  loss_cls_stage0: 0.05999  loss_box_reg_stage0: 0.1274  loss_cls_stage1: 0.05883  loss_box_reg_stage1: 0.2503  loss_cls_stage2: 0.06078  loss_box_reg_stage2: 0.3422  loss_mask: 0.07895  loss_rpn_cls: 0.06098  loss_rpn_loc: 0.08976    time: 0.7498  last_time: 0.9238  data_time: 0.0032  last_data_time: 0.0063   lr: 0.00024197  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:17:48 d2.utils.events]: \u001b[0m eta: 0:44:02  iter: 479  total_loss: 1.051  loss_cls_stage0: 0.05413  loss_box_reg_stage0: 0.1199  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.2333  loss_cls_stage2: 0.06487  loss_box_reg_stage2: 0.3226  loss_mask: 0.079  loss_rpn_cls: 0.04762  loss_rpn_loc: 0.05619    time: 0.7496  last_time: 0.6750  data_time: 0.0030  last_data_time: 0.0085   lr: 0.00024126  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:18:03 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 499  total_loss: 1.063  loss_cls_stage0: 0.05517  loss_box_reg_stage0: 0.1251  loss_cls_stage1: 0.06302  loss_box_reg_stage1: 0.2317  loss_cls_stage2: 0.06783  loss_box_reg_stage2: 0.3103  loss_mask: 0.07746  loss_rpn_cls: 0.04789  loss_rpn_loc: 0.06555    time: 0.7508  last_time: 0.8498  data_time: 0.0032  last_data_time: 0.0093   lr: 0.00024052  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:18:19 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 519  total_loss: 0.9855  loss_cls_stage0: 0.0604  loss_box_reg_stage0: 0.1246  loss_cls_stage1: 0.05089  loss_box_reg_stage1: 0.2105  loss_cls_stage2: 0.06196  loss_box_reg_stage2: 0.3186  loss_mask: 0.07592  loss_rpn_cls: 0.04514  loss_rpn_loc: 0.05581    time: 0.7517  last_time: 0.6528  data_time: 0.0032  last_data_time: 0.0082   lr: 0.00023976  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:18:34 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 539  total_loss: 1.049  loss_cls_stage0: 0.0424  loss_box_reg_stage0: 0.1185  loss_cls_stage1: 0.04429  loss_box_reg_stage1: 0.2096  loss_cls_stage2: 0.05275  loss_box_reg_stage2: 0.3067  loss_mask: 0.07736  loss_rpn_cls: 0.04044  loss_rpn_loc: 0.04603    time: 0.7525  last_time: 0.7956  data_time: 0.0029  last_data_time: 0.0076   lr: 0.00023897  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:18:49 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 559  total_loss: 1.186  loss_cls_stage0: 0.05751  loss_box_reg_stage0: 0.1474  loss_cls_stage1: 0.04885  loss_box_reg_stage1: 0.2794  loss_cls_stage2: 0.06726  loss_box_reg_stage2: 0.3894  loss_mask: 0.08645  loss_rpn_cls: 0.04202  loss_rpn_loc: 0.04942    time: 0.7526  last_time: 0.7953  data_time: 0.0030  last_data_time: 0.0076   lr: 0.00023815  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:19:05 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 579  total_loss: 0.8757  loss_cls_stage0: 0.04766  loss_box_reg_stage0: 0.1035  loss_cls_stage1: 0.04284  loss_box_reg_stage1: 0.1814  loss_cls_stage2: 0.04021  loss_box_reg_stage2: 0.2699  loss_mask: 0.06683  loss_rpn_cls: 0.03706  loss_rpn_loc: 0.04848    time: 0.7528  last_time: 0.7640  data_time: 0.0031  last_data_time: 0.0084   lr: 0.0002373  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:19:19 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 599  total_loss: 0.9682  loss_cls_stage0: 0.04387  loss_box_reg_stage0: 0.1267  loss_cls_stage1: 0.04041  loss_box_reg_stage1: 0.2257  loss_cls_stage2: 0.0549  loss_box_reg_stage2: 0.3157  loss_mask: 0.07764  loss_rpn_cls: 0.04248  loss_rpn_loc: 0.07116    time: 0.7522  last_time: 0.7907  data_time: 0.0028  last_data_time: 0.0081   lr: 0.00023642  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:19:34 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 619  total_loss: 0.9554  loss_cls_stage0: 0.04913  loss_box_reg_stage0: 0.115  loss_cls_stage1: 0.03383  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.03925  loss_box_reg_stage2: 0.3254  loss_mask: 0.0707  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.04426    time: 0.7517  last_time: 0.6724  data_time: 0.0029  last_data_time: 0.0075   lr: 0.00023552  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:19:49 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 639  total_loss: 1.085  loss_cls_stage0: 0.04968  loss_box_reg_stage0: 0.1208  loss_cls_stage1: 0.03769  loss_box_reg_stage1: 0.2464  loss_cls_stage2: 0.04879  loss_box_reg_stage2: 0.356  loss_mask: 0.07316  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.04863    time: 0.7514  last_time: 0.7564  data_time: 0.0029  last_data_time: 0.0083   lr: 0.00023459  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:20:04 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 659  total_loss: 0.9988  loss_cls_stage0: 0.0532  loss_box_reg_stage0: 0.1264  loss_cls_stage1: 0.0584  loss_box_reg_stage1: 0.2199  loss_cls_stage2: 0.05707  loss_box_reg_stage2: 0.2927  loss_mask: 0.07192  loss_rpn_cls: 0.04262  loss_rpn_loc: 0.06544    time: 0.7514  last_time: 0.8590  data_time: 0.0032  last_data_time: 0.0075   lr: 0.00023363  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:20:18 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 679  total_loss: 1.198  loss_cls_stage0: 0.0574  loss_box_reg_stage0: 0.1391  loss_cls_stage1: 0.05169  loss_box_reg_stage1: 0.2533  loss_cls_stage2: 0.07915  loss_box_reg_stage2: 0.3326  loss_mask: 0.08373  loss_rpn_cls: 0.03638  loss_rpn_loc: 0.04907    time: 0.7500  last_time: 0.6444  data_time: 0.0032  last_data_time: 0.0081   lr: 0.00023264  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:20:33 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 699  total_loss: 0.9306  loss_cls_stage0: 0.03699  loss_box_reg_stage0: 0.1158  loss_cls_stage1: 0.03725  loss_box_reg_stage1: 0.2346  loss_cls_stage2: 0.03848  loss_box_reg_stage2: 0.3003  loss_mask: 0.07622  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.04301    time: 0.7494  last_time: 0.7352  data_time: 0.0030  last_data_time: 0.0089   lr: 0.00023163  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:20:48 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 719  total_loss: 0.8916  loss_cls_stage0: 0.04364  loss_box_reg_stage0: 0.1093  loss_cls_stage1: 0.04041  loss_box_reg_stage1: 0.1959  loss_cls_stage2: 0.04398  loss_box_reg_stage2: 0.2956  loss_mask: 0.06668  loss_rpn_cls: 0.03171  loss_rpn_loc: 0.04987    time: 0.7502  last_time: 0.7233  data_time: 0.0030  last_data_time: 0.0096   lr: 0.00023059  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:21:04 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 739  total_loss: 1.156  loss_cls_stage0: 0.0585  loss_box_reg_stage0: 0.1318  loss_cls_stage1: 0.05143  loss_box_reg_stage1: 0.2533  loss_cls_stage2: 0.05979  loss_box_reg_stage2: 0.3891  loss_mask: 0.0712  loss_rpn_cls: 0.04114  loss_rpn_loc: 0.05115    time: 0.7506  last_time: 0.7843  data_time: 0.0030  last_data_time: 0.0083   lr: 0.00022953  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:21:19 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 759  total_loss: 0.9165  loss_cls_stage0: 0.04615  loss_box_reg_stage0: 0.1199  loss_cls_stage1: 0.0375  loss_box_reg_stage1: 0.2103  loss_cls_stage2: 0.04209  loss_box_reg_stage2: 0.2768  loss_mask: 0.07012  loss_rpn_cls: 0.03071  loss_rpn_loc: 0.04432    time: 0.7511  last_time: 0.7228  data_time: 0.0031  last_data_time: 0.0074   lr: 0.00022844  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:21:35 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 779  total_loss: 1.029  loss_cls_stage0: 0.04261  loss_box_reg_stage0: 0.1199  loss_cls_stage1: 0.04105  loss_box_reg_stage1: 0.2354  loss_cls_stage2: 0.0366  loss_box_reg_stage2: 0.3126  loss_mask: 0.07043  loss_rpn_cls: 0.02914  loss_rpn_loc: 0.04242    time: 0.7521  last_time: 0.7241  data_time: 0.0032  last_data_time: 0.0085   lr: 0.00022733  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:21:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 19:21:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:21:50 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:21:51 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 19:21:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 19:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0006 s/iter. Inference: 0.1256 s/iter. Eval: 0.0791 s/iter. Total: 0.2054 s/iter. ETA=0:06:29\n",
      "\u001b[32m[10/04 19:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 36/1909. Dataloading: 0.0008 s/iter. Inference: 0.1168 s/iter. Eval: 0.0859 s/iter. Total: 0.2035 s/iter. ETA=0:06:21\n",
      "\u001b[32m[10/04 19:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 60/1909. Dataloading: 0.0008 s/iter. Inference: 0.1170 s/iter. Eval: 0.0911 s/iter. Total: 0.2090 s/iter. ETA=0:06:26\n",
      "\u001b[32m[10/04 19:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 88/1909. Dataloading: 0.0008 s/iter. Inference: 0.1152 s/iter. Eval: 0.0839 s/iter. Total: 0.2000 s/iter. ETA=0:06:04\n",
      "\u001b[32m[10/04 19:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 112/1909. Dataloading: 0.0009 s/iter. Inference: 0.1155 s/iter. Eval: 0.0867 s/iter. Total: 0.2031 s/iter. ETA=0:06:05\n",
      "\u001b[32m[10/04 19:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 138/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0856 s/iter. Total: 0.2017 s/iter. ETA=0:05:57\n",
      "\u001b[32m[10/04 19:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 163/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0863 s/iter. Total: 0.2023 s/iter. ETA=0:05:53\n",
      "\u001b[32m[10/04 19:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 189/1909. Dataloading: 0.0009 s/iter. Inference: 0.1149 s/iter. Eval: 0.0860 s/iter. Total: 0.2019 s/iter. ETA=0:05:47\n",
      "\u001b[32m[10/04 19:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 214/1909. Dataloading: 0.0009 s/iter. Inference: 0.1149 s/iter. Eval: 0.0864 s/iter. Total: 0.2022 s/iter. ETA=0:05:42\n",
      "\u001b[32m[10/04 19:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 241/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0850 s/iter. Total: 0.2006 s/iter. ETA=0:05:34\n",
      "\u001b[32m[10/04 19:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 266/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0851 s/iter. Total: 0.2007 s/iter. ETA=0:05:29\n",
      "\u001b[32m[10/04 19:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 292/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0848 s/iter. Total: 0.2004 s/iter. ETA=0:05:24\n",
      "\u001b[32m[10/04 19:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 318/1909. Dataloading: 0.0009 s/iter. Inference: 0.1146 s/iter. Eval: 0.0844 s/iter. Total: 0.2000 s/iter. ETA=0:05:18\n",
      "\u001b[32m[10/04 19:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 343/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0844 s/iter. Total: 0.2000 s/iter. ETA=0:05:13\n",
      "\u001b[32m[10/04 19:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 366/1909. Dataloading: 0.0009 s/iter. Inference: 0.1148 s/iter. Eval: 0.0854 s/iter. Total: 0.2012 s/iter. ETA=0:05:10\n",
      "\u001b[32m[10/04 19:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 392/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0852 s/iter. Total: 0.2009 s/iter. ETA=0:05:04\n",
      "\u001b[32m[10/04 19:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 415/1909. Dataloading: 0.0009 s/iter. Inference: 0.1148 s/iter. Eval: 0.0862 s/iter. Total: 0.2020 s/iter. ETA=0:05:01\n",
      "\u001b[32m[10/04 19:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 441/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0858 s/iter. Total: 0.2015 s/iter. ETA=0:04:55\n",
      "\u001b[32m[10/04 19:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 467/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0854 s/iter. Total: 0.2010 s/iter. ETA=0:04:49\n",
      "\u001b[32m[10/04 19:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 492/1909. Dataloading: 0.0009 s/iter. Inference: 0.1147 s/iter. Eval: 0.0856 s/iter. Total: 0.2012 s/iter. ETA=0:04:45\n",
      "\u001b[32m[10/04 19:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 515/1909. Dataloading: 0.0009 s/iter. Inference: 0.1148 s/iter. Eval: 0.0864 s/iter. Total: 0.2022 s/iter. ETA=0:04:41\n",
      "\u001b[32m[10/04 19:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 537/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0875 s/iter. Total: 0.2034 s/iter. ETA=0:04:39\n",
      "\u001b[32m[10/04 19:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 563/1909. Dataloading: 0.0009 s/iter. Inference: 0.1149 s/iter. Eval: 0.0872 s/iter. Total: 0.2031 s/iter. ETA=0:04:33\n",
      "\u001b[32m[10/04 19:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 585/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0880 s/iter. Total: 0.2040 s/iter. ETA=0:04:30\n",
      "\u001b[32m[10/04 19:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 609/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0884 s/iter. Total: 0.2044 s/iter. ETA=0:04:25\n",
      "\u001b[32m[10/04 19:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 635/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0883 s/iter. Total: 0.2043 s/iter. ETA=0:04:20\n",
      "\u001b[32m[10/04 19:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 660/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0883 s/iter. Total: 0.2043 s/iter. ETA=0:04:15\n",
      "\u001b[32m[10/04 19:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 684/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0885 s/iter. Total: 0.2045 s/iter. ETA=0:04:10\n",
      "\u001b[32m[10/04 19:24:17 d2.evaluation.evaluator]: \u001b[0mInference done 710/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0882 s/iter. Total: 0.2042 s/iter. ETA=0:04:04\n",
      "\u001b[32m[10/04 19:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 733/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0888 s/iter. Total: 0.2048 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/04 19:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 756/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0892 s/iter. Total: 0.2054 s/iter. ETA=0:03:56\n",
      "\u001b[32m[10/04 19:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 780/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0896 s/iter. Total: 0.2059 s/iter. ETA=0:03:52\n",
      "\u001b[32m[10/04 19:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 806/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0893 s/iter. Total: 0.2055 s/iter. ETA=0:03:46\n",
      "\u001b[32m[10/04 19:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 832/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0889 s/iter. Total: 0.2051 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 19:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 856/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0891 s/iter. Total: 0.2053 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 19:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 881/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0891 s/iter. Total: 0.2054 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/04 19:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 907/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0889 s/iter. Total: 0.2050 s/iter. ETA=0:03:25\n",
      "\u001b[32m[10/04 19:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 932/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0888 s/iter. Total: 0.2049 s/iter. ETA=0:03:20\n",
      "\u001b[32m[10/04 19:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 959/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0886 s/iter. Total: 0.2046 s/iter. ETA=0:03:14\n",
      "\u001b[32m[10/04 19:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 982/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0889 s/iter. Total: 0.2051 s/iter. ETA=0:03:10\n",
      "\u001b[32m[10/04 19:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 1006/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0890 s/iter. Total: 0.2052 s/iter. ETA=0:03:05\n",
      "\u001b[32m[10/04 19:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 1031/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0890 s/iter. Total: 0.2052 s/iter. ETA=0:03:00\n",
      "\u001b[32m[10/04 19:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 1054/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0894 s/iter. Total: 0.2056 s/iter. ETA=0:02:55\n",
      "\u001b[32m[10/04 19:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 1079/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0895 s/iter. Total: 0.2057 s/iter. ETA=0:02:50\n",
      "\u001b[32m[10/04 19:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 1103/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0896 s/iter. Total: 0.2058 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 19:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 1130/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0892 s/iter. Total: 0.2054 s/iter. ETA=0:02:40\n",
      "\u001b[32m[10/04 19:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 1156/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0890 s/iter. Total: 0.2052 s/iter. ETA=0:02:34\n",
      "\u001b[32m[10/04 19:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 1179/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0893 s/iter. Total: 0.2055 s/iter. ETA=0:02:30\n",
      "\u001b[32m[10/04 19:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 1206/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0890 s/iter. Total: 0.2051 s/iter. ETA=0:02:24\n",
      "\u001b[32m[10/04 19:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 1231/1909. Dataloading: 0.0009 s/iter. Inference: 0.1152 s/iter. Eval: 0.0890 s/iter. Total: 0.2052 s/iter. ETA=0:02:19\n",
      "\u001b[32m[10/04 19:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 1259/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0885 s/iter. Total: 0.2046 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/04 19:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 1283/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0886 s/iter. Total: 0.2047 s/iter. ETA=0:02:08\n",
      "\u001b[32m[10/04 19:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 1308/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0887 s/iter. Total: 0.2047 s/iter. ETA=0:02:03\n",
      "\u001b[32m[10/04 19:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 1335/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0884 s/iter. Total: 0.2044 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/04 19:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 1359/1909. Dataloading: 0.0009 s/iter. Inference: 0.1151 s/iter. Eval: 0.0886 s/iter. Total: 0.2046 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/04 19:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 1386/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0883 s/iter. Total: 0.2042 s/iter. ETA=0:01:46\n",
      "\u001b[32m[10/04 19:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 1411/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0882 s/iter. Total: 0.2042 s/iter. ETA=0:01:41\n",
      "\u001b[32m[10/04 19:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 1436/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0882 s/iter. Total: 0.2041 s/iter. ETA=0:01:36\n",
      "\u001b[32m[10/04 19:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 1459/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0885 s/iter. Total: 0.2045 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/04 19:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 1484/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0885 s/iter. Total: 0.2045 s/iter. ETA=0:01:26\n",
      "\u001b[32m[10/04 19:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 1507/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0887 s/iter. Total: 0.2047 s/iter. ETA=0:01:22\n",
      "\u001b[32m[10/04 19:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 1533/1909. Dataloading: 0.0009 s/iter. Inference: 0.1150 s/iter. Eval: 0.0887 s/iter. Total: 0.2046 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/04 19:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 1555/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0886 s/iter. Total: 0.2049 s/iter. ETA=0:01:12\n",
      "\u001b[32m[10/04 19:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 1581/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0885 s/iter. Total: 0.2048 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/04 19:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 1604/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0890 s/iter. Total: 0.2053 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/04 19:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 1629/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0889 s/iter. Total: 0.2052 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/04 19:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 1654/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0890 s/iter. Total: 0.2053 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/04 19:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 1680/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0889 s/iter. Total: 0.2052 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/04 19:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 1708/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0886 s/iter. Total: 0.2048 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/04 19:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 1731/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0887 s/iter. Total: 0.2050 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/04 19:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 1758/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0885 s/iter. Total: 0.2048 s/iter. ETA=0:00:30\n",
      "\u001b[32m[10/04 19:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 1782/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0886 s/iter. Total: 0.2048 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/04 19:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 1807/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0886 s/iter. Total: 0.2048 s/iter. ETA=0:00:20\n",
      "\u001b[32m[10/04 19:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 1831/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0887 s/iter. Total: 0.2049 s/iter. ETA=0:00:15\n",
      "\u001b[32m[10/04 19:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 1856/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0886 s/iter. Total: 0.2049 s/iter. ETA=0:00:10\n",
      "\u001b[32m[10/04 19:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 1883/1909. Dataloading: 0.0009 s/iter. Inference: 0.1153 s/iter. Eval: 0.0884 s/iter. Total: 0.2047 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:29.582557 (0.204613 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:39 (0.115263 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:28:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 19:28:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/04 19:28:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:28:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.830\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.784\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.811\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.785\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.874\n",
      "\u001b[32m[10/04 19:28:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 72.290 | 82.994 | 78.421 | 0.396 | 56.191 | 81.058 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:28:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.18 seconds.\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.839\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.812\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.902\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 76.259 | 83.889 | 81.178 | 0.074 | 58.390 | 85.222 |\n",
      "\u001b[32m[10/04 19:28:27 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: 72.2904,82.9944,78.4211,0.3960,56.1914,81.0580\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:28:27 d2.evaluation.testing]: \u001b[0mcopypaste: 76.2590,83.8886,81.1781,0.0744,58.3896,85.2223\n",
      "\u001b[32m[10/04 19:28:27 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 799  total_loss: 0.9116  loss_cls_stage0: 0.04984  loss_box_reg_stage0: 0.1021  loss_cls_stage1: 0.03803  loss_box_reg_stage1: 0.1899  loss_cls_stage2: 0.04001  loss_box_reg_stage2: 0.3047  loss_mask: 0.06564  loss_rpn_cls: 0.03546  loss_rpn_loc: 0.0439    time: 0.7523  last_time: 0.6989  data_time: 0.0028  last_data_time: 0.0075   lr: 0.00022618  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:28:43 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 819  total_loss: 0.9659  loss_cls_stage0: 0.05023  loss_box_reg_stage0: 0.1221  loss_cls_stage1: 0.0456  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.05187  loss_box_reg_stage2: 0.3401  loss_mask: 0.06208  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.03737    time: 0.7525  last_time: 0.6103  data_time: 0.0032  last_data_time: 0.0080   lr: 0.00022502  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:28:57 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 839  total_loss: 1.124  loss_cls_stage0: 0.04061  loss_box_reg_stage0: 0.1266  loss_cls_stage1: 0.04405  loss_box_reg_stage1: 0.2427  loss_cls_stage2: 0.05004  loss_box_reg_stage2: 0.3145  loss_mask: 0.07345  loss_rpn_cls: 0.03875  loss_rpn_loc: 0.05134    time: 0.7523  last_time: 0.7771  data_time: 0.0031  last_data_time: 0.0079   lr: 0.00022383  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:29:12 d2.utils.events]: \u001b[0m eta: 0:39:21  iter: 859  total_loss: 0.9799  loss_cls_stage0: 0.0542  loss_box_reg_stage0: 0.1125  loss_cls_stage1: 0.04833  loss_box_reg_stage1: 0.2165  loss_cls_stage2: 0.0482  loss_box_reg_stage2: 0.2931  loss_mask: 0.06861  loss_rpn_cls: 0.02739  loss_rpn_loc: 0.04131    time: 0.7519  last_time: 0.6653  data_time: 0.0031  last_data_time: 0.0091   lr: 0.00022262  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:29:28 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 879  total_loss: 0.8191  loss_cls_stage0: 0.04316  loss_box_reg_stage0: 0.1158  loss_cls_stage1: 0.03146  loss_box_reg_stage1: 0.1914  loss_cls_stage2: 0.03082  loss_box_reg_stage2: 0.2923  loss_mask: 0.06027  loss_rpn_cls: 0.02736  loss_rpn_loc: 0.03951    time: 0.7524  last_time: 0.7149  data_time: 0.0033  last_data_time: 0.0061   lr: 0.00022138  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:29:43 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 899  total_loss: 0.9643  loss_cls_stage0: 0.04739  loss_box_reg_stage0: 0.1179  loss_cls_stage1: 0.03823  loss_box_reg_stage1: 0.2286  loss_cls_stage2: 0.04404  loss_box_reg_stage2: 0.3456  loss_mask: 0.06648  loss_rpn_cls: 0.02788  loss_rpn_loc: 0.05129    time: 0.7533  last_time: 0.8262  data_time: 0.0033  last_data_time: 0.0080   lr: 0.00022011  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:29:59 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 919  total_loss: 0.9303  loss_cls_stage0: 0.05009  loss_box_reg_stage0: 0.1091  loss_cls_stage1: 0.04072  loss_box_reg_stage1: 0.2155  loss_cls_stage2: 0.03852  loss_box_reg_stage2: 0.2956  loss_mask: 0.06423  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.04826    time: 0.7538  last_time: 0.6117  data_time: 0.0031  last_data_time: 0.0082   lr: 0.00021883  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:30:14 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 939  total_loss: 0.9894  loss_cls_stage0: 0.04713  loss_box_reg_stage0: 0.138  loss_cls_stage1: 0.03729  loss_box_reg_stage1: 0.2279  loss_cls_stage2: 0.05576  loss_box_reg_stage2: 0.3005  loss_mask: 0.06725  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.0443    time: 0.7542  last_time: 0.9017  data_time: 0.0031  last_data_time: 0.0090   lr: 0.00021752  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:30:30 d2.utils.events]: \u001b[0m eta: 0:38:15  iter: 959  total_loss: 0.9355  loss_cls_stage0: 0.05206  loss_box_reg_stage0: 0.1173  loss_cls_stage1: 0.03875  loss_box_reg_stage1: 0.2344  loss_cls_stage2: 0.04315  loss_box_reg_stage2: 0.3416  loss_mask: 0.06528  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.04185    time: 0.7546  last_time: 0.8033  data_time: 0.0031  last_data_time: 0.0095   lr: 0.00021619  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:30:45 d2.utils.events]: \u001b[0m eta: 0:38:00  iter: 979  total_loss: 0.9809  loss_cls_stage0: 0.05211  loss_box_reg_stage0: 0.1217  loss_cls_stage1: 0.04151  loss_box_reg_stage1: 0.2199  loss_cls_stage2: 0.05459  loss_box_reg_stage2: 0.3022  loss_mask: 0.05974  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.0525    time: 0.7547  last_time: 0.6936  data_time: 0.0031  last_data_time: 0.0082   lr: 0.00021483  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:30:59 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 999  total_loss: 0.9217  loss_cls_stage0: 0.05235  loss_box_reg_stage0: 0.1175  loss_cls_stage1: 0.03501  loss_box_reg_stage1: 0.2072  loss_cls_stage2: 0.0366  loss_box_reg_stage2: 0.3117  loss_mask: 0.05415  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.04765    time: 0.7535  last_time: 0.5817  data_time: 0.0029  last_data_time: 0.0077   lr: 0.00021346  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:31:14 d2.utils.events]: \u001b[0m eta: 0:37:28  iter: 1019  total_loss: 1.091  loss_cls_stage0: 0.05746  loss_box_reg_stage0: 0.1259  loss_cls_stage1: 0.04918  loss_box_reg_stage1: 0.2288  loss_cls_stage2: 0.05601  loss_box_reg_stage2: 0.3212  loss_mask: 0.06932  loss_rpn_cls: 0.03507  loss_rpn_loc: 0.05559    time: 0.7530  last_time: 0.8856  data_time: 0.0030  last_data_time: 0.0089   lr: 0.00021206  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:31:29 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 1039  total_loss: 1.131  loss_cls_stage0: 0.05869  loss_box_reg_stage0: 0.1362  loss_cls_stage1: 0.0567  loss_box_reg_stage1: 0.2418  loss_cls_stage2: 0.04917  loss_box_reg_stage2: 0.3344  loss_mask: 0.07069  loss_rpn_cls: 0.02837  loss_rpn_loc: 0.05183    time: 0.7536  last_time: 0.8805  data_time: 0.0031  last_data_time: 0.0094   lr: 0.00021064  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:31:44 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 1059  total_loss: 0.8911  loss_cls_stage0: 0.04729  loss_box_reg_stage0: 0.1148  loss_cls_stage1: 0.03952  loss_box_reg_stage1: 0.2062  loss_cls_stage2: 0.04819  loss_box_reg_stage2: 0.2908  loss_mask: 0.06359  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.0387    time: 0.7531  last_time: 0.7017  data_time: 0.0032  last_data_time: 0.0088   lr: 0.0002092  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:31:59 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 1079  total_loss: 0.8116  loss_cls_stage0: 0.04358  loss_box_reg_stage0: 0.09625  loss_cls_stage1: 0.03545  loss_box_reg_stage1: 0.1839  loss_cls_stage2: 0.02823  loss_box_reg_stage2: 0.2734  loss_mask: 0.05199  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.04617    time: 0.7534  last_time: 0.6427  data_time: 0.0033  last_data_time: 0.0085   lr: 0.00020774  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:32:15 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 1099  total_loss: 0.9365  loss_cls_stage0: 0.04932  loss_box_reg_stage0: 0.1049  loss_cls_stage1: 0.04311  loss_box_reg_stage1: 0.2084  loss_cls_stage2: 0.04296  loss_box_reg_stage2: 0.319  loss_mask: 0.05721  loss_rpn_cls: 0.02922  loss_rpn_loc: 0.04753    time: 0.7537  last_time: 0.7498  data_time: 0.0029  last_data_time: 0.0084   lr: 0.00020626  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:32:29 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 1119  total_loss: 1.02  loss_cls_stage0: 0.05151  loss_box_reg_stage0: 0.1241  loss_cls_stage1: 0.04308  loss_box_reg_stage1: 0.2664  loss_cls_stage2: 0.03835  loss_box_reg_stage2: 0.333  loss_mask: 0.06225  loss_rpn_cls: 0.02524  loss_rpn_loc: 0.03756    time: 0.7535  last_time: 0.8667  data_time: 0.0031  last_data_time: 0.0077   lr: 0.00020475  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:32:45 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 1139  total_loss: 0.9298  loss_cls_stage0: 0.05392  loss_box_reg_stage0: 0.1149  loss_cls_stage1: 0.03067  loss_box_reg_stage1: 0.2034  loss_cls_stage2: 0.0418  loss_box_reg_stage2: 0.3184  loss_mask: 0.05562  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.06596    time: 0.7540  last_time: 0.6902  data_time: 0.0030  last_data_time: 0.0077   lr: 0.00020323  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:33:01 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 1159  total_loss: 1.055  loss_cls_stage0: 0.05069  loss_box_reg_stage0: 0.1181  loss_cls_stage1: 0.04983  loss_box_reg_stage1: 0.2316  loss_cls_stage2: 0.05187  loss_box_reg_stage2: 0.3251  loss_mask: 0.06493  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.04231    time: 0.7546  last_time: 0.7516  data_time: 0.0032  last_data_time: 0.0089   lr: 0.00020169  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:33:16 d2.utils.events]: \u001b[0m eta: 0:35:33  iter: 1179  total_loss: 0.9956  loss_cls_stage0: 0.0585  loss_box_reg_stage0: 0.12  loss_cls_stage1: 0.05188  loss_box_reg_stage1: 0.2297  loss_cls_stage2: 0.05287  loss_box_reg_stage2: 0.296  loss_mask: 0.06329  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.0473    time: 0.7548  last_time: 0.6391  data_time: 0.0031  last_data_time: 0.0092   lr: 0.00020013  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:33:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 19:33:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:33:32 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:33:32 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 19:33:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 19:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0008 s/iter. Inference: 0.1102 s/iter. Eval: 0.0547 s/iter. Total: 0.1657 s/iter. ETA=0:05:14\n",
      "\u001b[32m[10/04 19:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 40/1909. Dataloading: 0.0008 s/iter. Inference: 0.1135 s/iter. Eval: 0.0583 s/iter. Total: 0.1727 s/iter. ETA=0:05:22\n",
      "\u001b[32m[10/04 19:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 69/1909. Dataloading: 0.0008 s/iter. Inference: 0.1131 s/iter. Eval: 0.0599 s/iter. Total: 0.1739 s/iter. ETA=0:05:19\n",
      "\u001b[32m[10/04 19:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 101/1909. Dataloading: 0.0008 s/iter. Inference: 0.1120 s/iter. Eval: 0.0560 s/iter. Total: 0.1689 s/iter. ETA=0:05:05\n",
      "\u001b[32m[10/04 19:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 130/1909. Dataloading: 0.0009 s/iter. Inference: 0.1119 s/iter. Eval: 0.0577 s/iter. Total: 0.1705 s/iter. ETA=0:05:03\n",
      "\u001b[32m[10/04 19:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 160/1909. Dataloading: 0.0009 s/iter. Inference: 0.1116 s/iter. Eval: 0.0581 s/iter. Total: 0.1706 s/iter. ETA=0:04:58\n",
      "\u001b[32m[10/04 19:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 191/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0573 s/iter. Total: 0.1696 s/iter. ETA=0:04:51\n",
      "\u001b[32m[10/04 19:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 221/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0573 s/iter. Total: 0.1695 s/iter. ETA=0:04:46\n",
      "\u001b[32m[10/04 19:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 249/1909. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 0.0587 s/iter. Total: 0.1711 s/iter. ETA=0:04:44\n",
      "\u001b[32m[10/04 19:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 282/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0569 s/iter. Total: 0.1689 s/iter. ETA=0:04:34\n",
      "\u001b[32m[10/04 19:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 313/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0564 s/iter. Total: 0.1683 s/iter. ETA=0:04:28\n",
      "\u001b[32m[10/04 19:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 343/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0565 s/iter. Total: 0.1685 s/iter. ETA=0:04:23\n",
      "\u001b[32m[10/04 19:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 373/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0565 s/iter. Total: 0.1683 s/iter. ETA=0:04:18\n",
      "\u001b[32m[10/04 19:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 403/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0568 s/iter. Total: 0.1686 s/iter. ETA=0:04:13\n",
      "\u001b[32m[10/04 19:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 433/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0569 s/iter. Total: 0.1686 s/iter. ETA=0:04:08\n",
      "\u001b[32m[10/04 19:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 465/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0564 s/iter. Total: 0.1681 s/iter. ETA=0:04:02\n",
      "\u001b[32m[10/04 19:34:57 d2.evaluation.evaluator]: \u001b[0mInference done 495/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0564 s/iter. Total: 0.1681 s/iter. ETA=0:03:57\n",
      "\u001b[32m[10/04 19:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 523/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0570 s/iter. Total: 0.1688 s/iter. ETA=0:03:53\n",
      "\u001b[32m[10/04 19:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 552/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0574 s/iter. Total: 0.1692 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/04 19:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 578/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:03:46\n",
      "\u001b[32m[10/04 19:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 608/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:03:41\n",
      "\u001b[32m[10/04 19:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 638/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 19:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 668/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/04 19:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 698/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:03:26\n",
      "\u001b[32m[10/04 19:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 727/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1705 s/iter. ETA=0:03:21\n",
      "\u001b[32m[10/04 19:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 755/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0590 s/iter. Total: 0.1710 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/04 19:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 784/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0592 s/iter. Total: 0.1712 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/04 19:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 815/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0589 s/iter. Total: 0.1708 s/iter. ETA=0:03:06\n",
      "\u001b[32m[10/04 19:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 844/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0589 s/iter. Total: 0.1709 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/04 19:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 876/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0586 s/iter. Total: 0.1705 s/iter. ETA=0:02:56\n",
      "\u001b[32m[10/04 19:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 906/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1705 s/iter. ETA=0:02:50\n",
      "\u001b[32m[10/04 19:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 937/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 19:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 967/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0583 s/iter. Total: 0.1702 s/iter. ETA=0:02:40\n",
      "\u001b[32m[10/04 19:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 994/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0588 s/iter. Total: 0.1707 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/04 19:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 1024/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1707 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/04 19:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 1052/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0589 s/iter. Total: 0.1709 s/iter. ETA=0:02:26\n",
      "\u001b[32m[10/04 19:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 1081/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0590 s/iter. Total: 0.1710 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/04 19:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 1111/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0590 s/iter. Total: 0.1710 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/04 19:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 1143/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1707 s/iter. ETA=0:02:10\n",
      "\u001b[32m[10/04 19:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 1172/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1707 s/iter. ETA=0:02:05\n",
      "\u001b[32m[10/04 19:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 1201/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0588 s/iter. Total: 0.1708 s/iter. ETA=0:02:00\n",
      "\u001b[32m[10/04 19:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 1231/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1707 s/iter. ETA=0:01:55\n",
      "\u001b[32m[10/04 19:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 1265/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0583 s/iter. Total: 0.1702 s/iter. ETA=0:01:49\n",
      "\u001b[32m[10/04 19:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 1294/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:01:44\n",
      "\u001b[32m[10/04 19:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 1324/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0583 s/iter. Total: 0.1703 s/iter. ETA=0:01:39\n",
      "\u001b[32m[10/04 19:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 1353/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:01:34\n",
      "\u001b[32m[10/04 19:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 1385/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0582 s/iter. Total: 0.1701 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/04 19:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 1416/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0581 s/iter. Total: 0.1700 s/iter. ETA=0:01:23\n",
      "\u001b[32m[10/04 19:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 1445/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0582 s/iter. Total: 0.1702 s/iter. ETA=0:01:18\n",
      "\u001b[32m[10/04 19:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 1472/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1705 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/04 19:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 1503/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1704 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/04 19:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 1533/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1704 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/04 19:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 1564/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0583 s/iter. Total: 0.1702 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/04 19:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 1595/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0584 s/iter. Total: 0.1703 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/04 19:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 1622/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1706 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/04 19:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 1651/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0588 s/iter. Total: 0.1707 s/iter. ETA=0:00:44\n",
      "\u001b[32m[10/04 19:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 1681/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0588 s/iter. Total: 0.1708 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/04 19:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 1713/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0586 s/iter. Total: 0.1705 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/04 19:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 1742/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1706 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/04 19:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 1774/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1704 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/04 19:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 1806/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1704 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/04 19:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 1833/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0587 s/iter. Total: 0.1706 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/04 19:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 1865/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0585 s/iter. Total: 0.1704 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/04 19:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 1897/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0583 s/iter. Total: 0.1702 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:24.273476 (0.170312 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:31 (0.110941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.863\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.825\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.847\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.898\n",
      "\u001b[32m[10/04 19:38:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 76.440 | 86.280 | 82.465 | 0.396 | 61.819 | 84.657 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:39:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.51 seconds.\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.794\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.841\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.838\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.697\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.916\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 79.434 | 87.143 | 84.107 | 0.026 | 62.942 | 87.860 |\n",
      "\u001b[32m[10/04 19:39:02 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: 76.4397,86.2802,82.4646,0.3960,61.8187,84.6575\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:39:02 d2.evaluation.testing]: \u001b[0mcopypaste: 79.4341,87.1431,84.1072,0.0264,62.9417,87.8602\n",
      "\u001b[32m[10/04 19:39:02 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 1199  total_loss: 0.8574  loss_cls_stage0: 0.03978  loss_box_reg_stage0: 0.09939  loss_cls_stage1: 0.03709  loss_box_reg_stage1: 0.1968  loss_cls_stage2: 0.03428  loss_box_reg_stage2: 0.2868  loss_mask: 0.05711  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.03848    time: 0.7547  last_time: 0.7340  data_time: 0.0029  last_data_time: 0.0083   lr: 0.00019855  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:39:17 d2.utils.events]: \u001b[0m eta: 0:35:00  iter: 1219  total_loss: 0.9916  loss_cls_stage0: 0.05202  loss_box_reg_stage0: 0.1057  loss_cls_stage1: 0.03296  loss_box_reg_stage1: 0.2274  loss_cls_stage2: 0.03995  loss_box_reg_stage2: 0.3162  loss_mask: 0.06332  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.03319    time: 0.7546  last_time: 0.6625  data_time: 0.0034  last_data_time: 0.0100   lr: 0.00019696  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:39:33 d2.utils.events]: \u001b[0m eta: 0:34:45  iter: 1239  total_loss: 0.9655  loss_cls_stage0: 0.04442  loss_box_reg_stage0: 0.1175  loss_cls_stage1: 0.03694  loss_box_reg_stage1: 0.2175  loss_cls_stage2: 0.03576  loss_box_reg_stage2: 0.35  loss_mask: 0.05746  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.04245    time: 0.7548  last_time: 0.8002  data_time: 0.0031  last_data_time: 0.0072   lr: 0.00019534  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:39:48 d2.utils.events]: \u001b[0m eta: 0:34:30  iter: 1259  total_loss: 0.9848  loss_cls_stage0: 0.03989  loss_box_reg_stage0: 0.1209  loss_cls_stage1: 0.02805  loss_box_reg_stage1: 0.2212  loss_cls_stage2: 0.0421  loss_box_reg_stage2: 0.3146  loss_mask: 0.05686  loss_rpn_cls: 0.02729  loss_rpn_loc: 0.03686    time: 0.7549  last_time: 0.6847  data_time: 0.0031  last_data_time: 0.0081   lr: 0.00019371  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:40:03 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 1279  total_loss: 1.06  loss_cls_stage0: 0.05758  loss_box_reg_stage0: 0.1074  loss_cls_stage1: 0.03934  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.04312  loss_box_reg_stage2: 0.3191  loss_mask: 0.06133  loss_rpn_cls: 0.03106  loss_rpn_loc: 0.03442    time: 0.7545  last_time: 0.7189  data_time: 0.0031  last_data_time: 0.0092   lr: 0.00019206  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:40:18 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 1299  total_loss: 1.022  loss_cls_stage0: 0.05437  loss_box_reg_stage0: 0.1349  loss_cls_stage1: 0.03754  loss_box_reg_stage1: 0.2429  loss_cls_stage2: 0.04453  loss_box_reg_stage2: 0.3439  loss_mask: 0.06212  loss_rpn_cls: 0.02571  loss_rpn_loc: 0.03954    time: 0.7552  last_time: 0.7615  data_time: 0.0031  last_data_time: 0.0082   lr: 0.0001904  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:40:34 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 1319  total_loss: 1.024  loss_cls_stage0: 0.05559  loss_box_reg_stage0: 0.1191  loss_cls_stage1: 0.05475  loss_box_reg_stage1: 0.2017  loss_cls_stage2: 0.05478  loss_box_reg_stage2: 0.3207  loss_mask: 0.06595  loss_rpn_cls: 0.03488  loss_rpn_loc: 0.05537    time: 0.7555  last_time: 0.8588  data_time: 0.0032  last_data_time: 0.0081   lr: 0.00018871  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:40:49 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 1339  total_loss: 0.8975  loss_cls_stage0: 0.06268  loss_box_reg_stage0: 0.1116  loss_cls_stage1: 0.0489  loss_box_reg_stage1: 0.2187  loss_cls_stage2: 0.05133  loss_box_reg_stage2: 0.3164  loss_mask: 0.06201  loss_rpn_cls: 0.03237  loss_rpn_loc: 0.04679    time: 0.7555  last_time: 0.8722  data_time: 0.0033  last_data_time: 0.0079   lr: 0.00018702  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:41:04 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 1359  total_loss: 1.007  loss_cls_stage0: 0.05352  loss_box_reg_stage0: 0.1333  loss_cls_stage1: 0.04893  loss_box_reg_stage1: 0.2368  loss_cls_stage2: 0.05937  loss_box_reg_stage2: 0.3143  loss_mask: 0.05967  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.03409    time: 0.7554  last_time: 0.8324  data_time: 0.0031  last_data_time: 0.0044   lr: 0.00018531  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:41:20 d2.utils.events]: \u001b[0m eta: 0:33:06  iter: 1379  total_loss: 0.9533  loss_cls_stage0: 0.05235  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.04804  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.04063  loss_box_reg_stage2: 0.3167  loss_mask: 0.05919  loss_rpn_cls: 0.02732  loss_rpn_loc: 0.04101    time: 0.7556  last_time: 0.7101  data_time: 0.0032  last_data_time: 0.0081   lr: 0.00018358  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:41:35 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 1399  total_loss: 0.9569  loss_cls_stage0: 0.05082  loss_box_reg_stage0: 0.1078  loss_cls_stage1: 0.04585  loss_box_reg_stage1: 0.2225  loss_cls_stage2: 0.04325  loss_box_reg_stage2: 0.372  loss_mask: 0.05811  loss_rpn_cls: 0.02512  loss_rpn_loc: 0.04144    time: 0.7558  last_time: 0.7207  data_time: 0.0031  last_data_time: 0.0081   lr: 0.00018184  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:41:50 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 1419  total_loss: 0.8268  loss_cls_stage0: 0.05155  loss_box_reg_stage0: 0.1035  loss_cls_stage1: 0.03574  loss_box_reg_stage1: 0.1718  loss_cls_stage2: 0.04456  loss_box_reg_stage2: 0.2769  loss_mask: 0.05284  loss_rpn_cls: 0.02875  loss_rpn_loc: 0.0416    time: 0.7560  last_time: 0.8317  data_time: 0.0031  last_data_time: 0.0093   lr: 0.00018008  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:42:05 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 1439  total_loss: 1.078  loss_cls_stage0: 0.05899  loss_box_reg_stage0: 0.1174  loss_cls_stage1: 0.05509  loss_box_reg_stage1: 0.2501  loss_cls_stage2: 0.0689  loss_box_reg_stage2: 0.3674  loss_mask: 0.07119  loss_rpn_cls: 0.02585  loss_rpn_loc: 0.04061    time: 0.7558  last_time: 0.6339  data_time: 0.0031  last_data_time: 0.0012   lr: 0.00017831  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:42:21 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 1459  total_loss: 0.8648  loss_cls_stage0: 0.04791  loss_box_reg_stage0: 0.09973  loss_cls_stage1: 0.03607  loss_box_reg_stage1: 0.2016  loss_cls_stage2: 0.04047  loss_box_reg_stage2: 0.301  loss_mask: 0.05401  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.037    time: 0.7564  last_time: 0.6541  data_time: 0.0033  last_data_time: 0.0012   lr: 0.00017653  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:42:37 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 1479  total_loss: 1.046  loss_cls_stage0: 0.04997  loss_box_reg_stage0: 0.1138  loss_cls_stage1: 0.03977  loss_box_reg_stage1: 0.2208  loss_cls_stage2: 0.0503  loss_box_reg_stage2: 0.3306  loss_mask: 0.05796  loss_rpn_cls: 0.0275  loss_rpn_loc: 0.04628    time: 0.7567  last_time: 0.6998  data_time: 0.0032  last_data_time: 0.0014   lr: 0.00017473  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:42:52 d2.utils.events]: \u001b[0m eta: 0:31:37  iter: 1499  total_loss: 0.9606  loss_cls_stage0: 0.05563  loss_box_reg_stage0: 0.1208  loss_cls_stage1: 0.03233  loss_box_reg_stage1: 0.2327  loss_cls_stage2: 0.0383  loss_box_reg_stage2: 0.3394  loss_mask: 0.05835  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.03872    time: 0.7567  last_time: 0.8093  data_time: 0.0032  last_data_time: 0.0012   lr: 0.00017293  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:43:08 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 1519  total_loss: 1.151  loss_cls_stage0: 0.05694  loss_box_reg_stage0: 0.1189  loss_cls_stage1: 0.04266  loss_box_reg_stage1: 0.256  loss_cls_stage2: 0.05231  loss_box_reg_stage2: 0.3457  loss_mask: 0.05804  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.03976    time: 0.7570  last_time: 0.7033  data_time: 0.0032  last_data_time: 0.0009   lr: 0.00017111  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:43:23 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 1539  total_loss: 0.9821  loss_cls_stage0: 0.05473  loss_box_reg_stage0: 0.1063  loss_cls_stage1: 0.04327  loss_box_reg_stage1: 0.2253  loss_cls_stage2: 0.04839  loss_box_reg_stage2: 0.3337  loss_mask: 0.05993  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.04209    time: 0.7573  last_time: 0.6991  data_time: 0.0034  last_data_time: 0.0010   lr: 0.00016928  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:43:39 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 1559  total_loss: 0.9336  loss_cls_stage0: 0.05042  loss_box_reg_stage0: 0.1225  loss_cls_stage1: 0.05197  loss_box_reg_stage1: 0.2113  loss_cls_stage2: 0.05303  loss_box_reg_stage2: 0.3063  loss_mask: 0.0568  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.03745    time: 0.7576  last_time: 0.7105  data_time: 0.0030  last_data_time: 0.0010   lr: 0.00016743  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:43:54 d2.utils.events]: \u001b[0m eta: 0:30:38  iter: 1579  total_loss: 0.9799  loss_cls_stage0: 0.05573  loss_box_reg_stage0: 0.1134  loss_cls_stage1: 0.03986  loss_box_reg_stage1: 0.2403  loss_cls_stage2: 0.04053  loss_box_reg_stage2: 0.3648  loss_mask: 0.0559  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.04939    time: 0.7578  last_time: 0.8608  data_time: 0.0030  last_data_time: 0.0027   lr: 0.00016558  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:44:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 19:44:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:44:10 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:44:10 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 19:44:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 19:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0006 s/iter. Inference: 0.1084 s/iter. Eval: 0.0485 s/iter. Total: 0.1575 s/iter. ETA=0:04:58\n",
      "\u001b[32m[10/04 19:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 41/1909. Dataloading: 0.0008 s/iter. Inference: 0.1099 s/iter. Eval: 0.0598 s/iter. Total: 0.1706 s/iter. ETA=0:05:18\n",
      "\u001b[32m[10/04 19:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 70/1909. Dataloading: 0.0008 s/iter. Inference: 0.1104 s/iter. Eval: 0.0611 s/iter. Total: 0.1724 s/iter. ETA=0:05:17\n",
      "\u001b[32m[10/04 19:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 102/1909. Dataloading: 0.0008 s/iter. Inference: 0.1100 s/iter. Eval: 0.0577 s/iter. Total: 0.1685 s/iter. ETA=0:05:04\n",
      "\u001b[32m[10/04 19:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 131/1909. Dataloading: 0.0008 s/iter. Inference: 0.1101 s/iter. Eval: 0.0591 s/iter. Total: 0.1701 s/iter. ETA=0:05:02\n",
      "\u001b[32m[10/04 19:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 161/1909. Dataloading: 0.0008 s/iter. Inference: 0.1100 s/iter. Eval: 0.0595 s/iter. Total: 0.1703 s/iter. ETA=0:04:57\n",
      "\u001b[32m[10/04 19:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 192/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0584 s/iter. Total: 0.1691 s/iter. ETA=0:04:50\n",
      "\u001b[32m[10/04 19:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 222/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0583 s/iter. Total: 0.1689 s/iter. ETA=0:04:45\n",
      "\u001b[32m[10/04 19:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 249/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0600 s/iter. Total: 0.1709 s/iter. ETA=0:04:43\n",
      "\u001b[32m[10/04 19:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 282/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0581 s/iter. Total: 0.1687 s/iter. ETA=0:04:34\n",
      "\u001b[32m[10/04 19:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 314/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0574 s/iter. Total: 0.1679 s/iter. ETA=0:04:27\n",
      "\u001b[32m[10/04 19:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 343/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0580 s/iter. Total: 0.1686 s/iter. ETA=0:04:24\n",
      "\u001b[32m[10/04 19:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 373/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0582 s/iter. Total: 0.1688 s/iter. ETA=0:04:19\n",
      "\u001b[32m[10/04 19:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 402/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0584 s/iter. Total: 0.1691 s/iter. ETA=0:04:14\n",
      "\u001b[32m[10/04 19:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 432/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0585 s/iter. Total: 0.1693 s/iter. ETA=0:04:10\n",
      "\u001b[32m[10/04 19:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 463/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0582 s/iter. Total: 0.1689 s/iter. ETA=0:04:04\n",
      "\u001b[32m[10/04 19:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 492/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0584 s/iter. Total: 0.1692 s/iter. ETA=0:03:59\n",
      "\u001b[32m[10/04 19:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 520/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0590 s/iter. Total: 0.1699 s/iter. ETA=0:03:55\n",
      "\u001b[32m[10/04 19:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 547/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0597 s/iter. Total: 0.1708 s/iter. ETA=0:03:52\n",
      "\u001b[32m[10/04 19:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 576/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0600 s/iter. Total: 0.1711 s/iter. ETA=0:03:48\n",
      "\u001b[32m[10/04 19:45:55 d2.evaluation.evaluator]: \u001b[0mInference done 602/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0609 s/iter. Total: 0.1722 s/iter. ETA=0:03:45\n",
      "\u001b[32m[10/04 19:46:00 d2.evaluation.evaluator]: \u001b[0mInference done 631/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0608 s/iter. Total: 0.1722 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 19:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 660/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0609 s/iter. Total: 0.1724 s/iter. ETA=0:03:35\n",
      "\u001b[32m[10/04 19:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 688/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0611 s/iter. Total: 0.1727 s/iter. ETA=0:03:30\n",
      "\u001b[32m[10/04 19:46:15 d2.evaluation.evaluator]: \u001b[0mInference done 717/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0611 s/iter. Total: 0.1727 s/iter. ETA=0:03:25\n",
      "\u001b[32m[10/04 19:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 744/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0618 s/iter. Total: 0.1736 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/04 19:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 773/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0620 s/iter. Total: 0.1739 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/04 19:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 803/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0618 s/iter. Total: 0.1737 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/04 19:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 834/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0614 s/iter. Total: 0.1734 s/iter. ETA=0:03:06\n",
      "\u001b[32m[10/04 19:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 863/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0615 s/iter. Total: 0.1735 s/iter. ETA=0:03:01\n",
      "\u001b[32m[10/04 19:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 893/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0613 s/iter. Total: 0.1734 s/iter. ETA=0:02:56\n",
      "\u001b[32m[10/04 19:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 922/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0613 s/iter. Total: 0.1734 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/04 19:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 954/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0609 s/iter. Total: 0.1729 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 19:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 980/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0614 s/iter. Total: 0.1735 s/iter. ETA=0:02:41\n",
      "\u001b[32m[10/04 19:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 1008/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0615 s/iter. Total: 0.1737 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/04 19:47:12 d2.evaluation.evaluator]: \u001b[0mInference done 1037/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0616 s/iter. Total: 0.1738 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/04 19:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 1066/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0616 s/iter. Total: 0.1738 s/iter. ETA=0:02:26\n",
      "\u001b[32m[10/04 19:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 1094/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0618 s/iter. Total: 0.1741 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/04 19:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 1124/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0616 s/iter. Total: 0.1739 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/04 19:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 1153/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0616 s/iter. Total: 0.1739 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/04 19:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 1181/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0618 s/iter. Total: 0.1741 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/04 19:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 1212/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0616 s/iter. Total: 0.1740 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/04 19:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 1242/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0616 s/iter. Total: 0.1739 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/04 19:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 1274/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0612 s/iter. Total: 0.1735 s/iter. ETA=0:01:50\n",
      "\u001b[32m[10/04 19:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 1301/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0611 s/iter. Total: 0.1738 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/04 19:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 1331/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0611 s/iter. Total: 0.1737 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/04 19:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 1359/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0613 s/iter. Total: 0.1740 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/04 19:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 1391/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0609 s/iter. Total: 0.1736 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/04 19:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 1421/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0609 s/iter. Total: 0.1735 s/iter. ETA=0:01:24\n",
      "\u001b[32m[10/04 19:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 1449/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0610 s/iter. Total: 0.1736 s/iter. ETA=0:01:19\n",
      "\u001b[32m[10/04 19:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 1476/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0613 s/iter. Total: 0.1739 s/iter. ETA=0:01:15\n",
      "\u001b[32m[10/04 19:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 1506/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0612 s/iter. Total: 0.1739 s/iter. ETA=0:01:10\n",
      "\u001b[32m[10/04 19:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 1535/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0613 s/iter. Total: 0.1739 s/iter. ETA=0:01:05\n",
      "\u001b[32m[10/04 19:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 1566/1909. Dataloading: 0.0009 s/iter. Inference: 0.1116 s/iter. Eval: 0.0611 s/iter. Total: 0.1737 s/iter. ETA=0:00:59\n",
      "\u001b[32m[10/04 19:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 1595/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0612 s/iter. Total: 0.1738 s/iter. ETA=0:00:54\n",
      "\u001b[32m[10/04 19:48:54 d2.evaluation.evaluator]: \u001b[0mInference done 1621/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0615 s/iter. Total: 0.1742 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/04 19:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 1650/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0615 s/iter. Total: 0.1742 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/04 19:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 1678/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0615 s/iter. Total: 0.1742 s/iter. ETA=0:00:40\n",
      "\u001b[32m[10/04 19:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 1711/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0613 s/iter. Total: 0.1739 s/iter. ETA=0:00:34\n",
      "\u001b[32m[10/04 19:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 1740/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0613 s/iter. Total: 0.1740 s/iter. ETA=0:00:29\n",
      "\u001b[32m[10/04 19:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 1771/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0612 s/iter. Total: 0.1739 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/04 19:49:24 d2.evaluation.evaluator]: \u001b[0mInference done 1802/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0610 s/iter. Total: 0.1737 s/iter. ETA=0:00:18\n",
      "\u001b[32m[10/04 19:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 1829/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0612 s/iter. Total: 0.1739 s/iter. ETA=0:00:13\n",
      "\u001b[32m[10/04 19:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 1858/1909. Dataloading: 0.0009 s/iter. Inference: 0.1118 s/iter. Eval: 0.0612 s/iter. Total: 0.1739 s/iter. ETA=0:00:08\n",
      "\u001b[32m[10/04 19:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 1889/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0610 s/iter. Total: 0.1737 s/iter. ETA=0:00:03\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:30.713552 (0.173694 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:32 (0.111733 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:49:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/04 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.886\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.846\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918\n",
      "\u001b[32m[10/04 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 79.764 | 88.642 | 85.107 | 0.248 | 67.362 | 87.235 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 19:49:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.54 seconds.\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.872\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.934\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 82.551 | 89.452 | 87.169 | 0.000 | 68.831 | 89.960 |\n",
      "\u001b[32m[10/04 19:49:46 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: 79.7641,88.6418,85.1073,0.2475,67.3618,87.2351\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 19:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: 82.5511,89.4516,87.1686,0.0000,68.8312,89.9599\n",
      "\u001b[32m[10/04 19:49:46 d2.utils.events]: \u001b[0m eta: 0:30:22  iter: 1599  total_loss: 0.9523  loss_cls_stage0: 0.05956  loss_box_reg_stage0: 0.1156  loss_cls_stage1: 0.04193  loss_box_reg_stage1: 0.2116  loss_cls_stage2: 0.04646  loss_box_reg_stage2: 0.3316  loss_mask: 0.05637  loss_rpn_cls: 0.02869  loss_rpn_loc: 0.03287    time: 0.7578  last_time: 0.9162  data_time: 0.0028  last_data_time: 0.0010   lr: 0.00016372  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:50:02 d2.utils.events]: \u001b[0m eta: 0:30:09  iter: 1619  total_loss: 0.9986  loss_cls_stage0: 0.05444  loss_box_reg_stage0: 0.1129  loss_cls_stage1: 0.03934  loss_box_reg_stage1: 0.2349  loss_cls_stage2: 0.0355  loss_box_reg_stage2: 0.3423  loss_mask: 0.05762  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.04904    time: 0.7579  last_time: 0.6251  data_time: 0.0038  last_data_time: 0.0100   lr: 0.00016185  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:50:18 d2.utils.events]: \u001b[0m eta: 0:29:57  iter: 1639  total_loss: 0.8931  loss_cls_stage0: 0.04641  loss_box_reg_stage0: 0.1075  loss_cls_stage1: 0.03269  loss_box_reg_stage1: 0.2042  loss_cls_stage2: 0.03619  loss_box_reg_stage2: 0.2928  loss_mask: 0.05235  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.03864    time: 0.7585  last_time: 0.7452  data_time: 0.0034  last_data_time: 0.0085   lr: 0.00015997  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:50:34 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 1659  total_loss: 0.8902  loss_cls_stage0: 0.05772  loss_box_reg_stage0: 0.1136  loss_cls_stage1: 0.04241  loss_box_reg_stage1: 0.1938  loss_cls_stage2: 0.04717  loss_box_reg_stage2: 0.3114  loss_mask: 0.05835  loss_rpn_cls: 0.02496  loss_rpn_loc: 0.03594    time: 0.7590  last_time: 0.7342  data_time: 0.0031  last_data_time: 0.0043   lr: 0.00015808  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:50:49 d2.utils.events]: \u001b[0m eta: 0:29:30  iter: 1679  total_loss: 0.9436  loss_cls_stage0: 0.06064  loss_box_reg_stage0: 0.111  loss_cls_stage1: 0.04733  loss_box_reg_stage1: 0.2139  loss_cls_stage2: 0.04322  loss_box_reg_stage2: 0.3158  loss_mask: 0.05053  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.03557    time: 0.7590  last_time: 0.8241  data_time: 0.0031  last_data_time: 0.0014   lr: 0.00015618  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:51:04 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 1699  total_loss: 0.8581  loss_cls_stage0: 0.05873  loss_box_reg_stage0: 0.1157  loss_cls_stage1: 0.03873  loss_box_reg_stage1: 0.2101  loss_cls_stage2: 0.04407  loss_box_reg_stage2: 0.2873  loss_mask: 0.0564  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.03789    time: 0.7591  last_time: 0.8493  data_time: 0.0034  last_data_time: 0.0017   lr: 0.00015428  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:51:19 d2.utils.events]: \u001b[0m eta: 0:28:59  iter: 1719  total_loss: 0.9751  loss_cls_stage0: 0.05328  loss_box_reg_stage0: 0.1167  loss_cls_stage1: 0.03264  loss_box_reg_stage1: 0.2323  loss_cls_stage2: 0.03649  loss_box_reg_stage2: 0.3325  loss_mask: 0.0547  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.03361    time: 0.7590  last_time: 0.8788  data_time: 0.0033  last_data_time: 0.0013   lr: 0.00015236  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:51:34 d2.utils.events]: \u001b[0m eta: 0:28:44  iter: 1739  total_loss: 0.9614  loss_cls_stage0: 0.06402  loss_box_reg_stage0: 0.1135  loss_cls_stage1: 0.04241  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.04445  loss_box_reg_stage2: 0.3392  loss_mask: 0.0638  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.04617    time: 0.7589  last_time: 0.6531  data_time: 0.0033  last_data_time: 0.0011   lr: 0.00015044  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:51:50 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 1759  total_loss: 0.9758  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.1196  loss_cls_stage1: 0.03818  loss_box_reg_stage1: 0.2176  loss_cls_stage2: 0.04317  loss_box_reg_stage2: 0.3272  loss_mask: 0.05549  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.03406    time: 0.7592  last_time: 0.8086  data_time: 0.0033  last_data_time: 0.0011   lr: 0.00014852  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:52:05 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 1779  total_loss: 0.9095  loss_cls_stage0: 0.05215  loss_box_reg_stage0: 0.1078  loss_cls_stage1: 0.04463  loss_box_reg_stage1: 0.2106  loss_cls_stage2: 0.04219  loss_box_reg_stage2: 0.3009  loss_mask: 0.05419  loss_rpn_cls: 0.02614  loss_rpn_loc: 0.04125    time: 0.7591  last_time: 0.7504  data_time: 0.0033  last_data_time: 0.0013   lr: 0.00014659  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:52:20 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 1799  total_loss: 0.9888  loss_cls_stage0: 0.05079  loss_box_reg_stage0: 0.1066  loss_cls_stage1: 0.04256  loss_box_reg_stage1: 0.2272  loss_cls_stage2: 0.04224  loss_box_reg_stage2: 0.3154  loss_mask: 0.04846  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.04146    time: 0.7590  last_time: 0.7320  data_time: 0.0033  last_data_time: 0.0012   lr: 0.00014465  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:52:36 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 1819  total_loss: 1.053  loss_cls_stage0: 0.06012  loss_box_reg_stage0: 0.1244  loss_cls_stage1: 0.04256  loss_box_reg_stage1: 0.2295  loss_cls_stage2: 0.04665  loss_box_reg_stage2: 0.3416  loss_mask: 0.06935  loss_rpn_cls: 0.02146  loss_rpn_loc: 0.03033    time: 0.7593  last_time: 0.6824  data_time: 0.0034  last_data_time: 0.0013   lr: 0.00014271  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:52:52 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 1839  total_loss: 0.9576  loss_cls_stage0: 0.06288  loss_box_reg_stage0: 0.1135  loss_cls_stage1: 0.05161  loss_box_reg_stage1: 0.2323  loss_cls_stage2: 0.04714  loss_box_reg_stage2: 0.3303  loss_mask: 0.06059  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.03599    time: 0.7596  last_time: 0.7946  data_time: 0.0032  last_data_time: 0.0011   lr: 0.00014076  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:53:07 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 1859  total_loss: 1.021  loss_cls_stage0: 0.05701  loss_box_reg_stage0: 0.1381  loss_cls_stage1: 0.05237  loss_box_reg_stage1: 0.2474  loss_cls_stage2: 0.04348  loss_box_reg_stage2: 0.3588  loss_mask: 0.05532  loss_rpn_cls: 0.02451  loss_rpn_loc: 0.03279    time: 0.7595  last_time: 0.6987  data_time: 0.0032  last_data_time: 0.0011   lr: 0.00013881  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:53:23 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 1879  total_loss: 0.9877  loss_cls_stage0: 0.05953  loss_box_reg_stage0: 0.1221  loss_cls_stage1: 0.03849  loss_box_reg_stage1: 0.2401  loss_cls_stage2: 0.03396  loss_box_reg_stage2: 0.3766  loss_mask: 0.06537  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.03537    time: 0.7599  last_time: 0.6260  data_time: 0.0033  last_data_time: 0.0014   lr: 0.00013686  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:53:38 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 1899  total_loss: 1.062  loss_cls_stage0: 0.06142  loss_box_reg_stage0: 0.1139  loss_cls_stage1: 0.04581  loss_box_reg_stage1: 0.2276  loss_cls_stage2: 0.05014  loss_box_reg_stage2: 0.3623  loss_mask: 0.05906  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.03453    time: 0.7600  last_time: 0.7334  data_time: 0.0032  last_data_time: 0.0011   lr: 0.00013491  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:53:53 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 1919  total_loss: 0.9117  loss_cls_stage0: 0.05209  loss_box_reg_stage0: 0.1059  loss_cls_stage1: 0.03968  loss_box_reg_stage1: 0.2057  loss_cls_stage2: 0.03927  loss_box_reg_stage2: 0.3243  loss_mask: 0.05369  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.0294    time: 0.7601  last_time: 0.8394  data_time: 0.0029  last_data_time: 0.0013   lr: 0.00013295  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:54:08 d2.utils.events]: \u001b[0m eta: 0:26:11  iter: 1939  total_loss: 1.017  loss_cls_stage0: 0.06478  loss_box_reg_stage0: 0.1295  loss_cls_stage1: 0.05412  loss_box_reg_stage1: 0.2373  loss_cls_stage2: 0.05299  loss_box_reg_stage2: 0.3499  loss_mask: 0.05958  loss_rpn_cls: 0.01985  loss_rpn_loc: 0.04067    time: 0.7600  last_time: 0.6302  data_time: 0.0031  last_data_time: 0.0010   lr: 0.00013099  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:54:24 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 1959  total_loss: 0.9018  loss_cls_stage0: 0.0577  loss_box_reg_stage0: 0.1077  loss_cls_stage1: 0.03195  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.03271  loss_box_reg_stage2: 0.3269  loss_mask: 0.05405  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.0306    time: 0.7601  last_time: 0.7501  data_time: 0.0031  last_data_time: 0.0013   lr: 0.00012902  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:54:39 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 1979  total_loss: 0.9934  loss_cls_stage0: 0.05594  loss_box_reg_stage0: 0.1226  loss_cls_stage1: 0.05108  loss_box_reg_stage1: 0.2032  loss_cls_stage2: 0.04306  loss_box_reg_stage2: 0.317  loss_mask: 0.05567  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.04565    time: 0.7603  last_time: 0.9466  data_time: 0.0031  last_data_time: 0.0010   lr: 0.00012706  max_mem: 5695M\n",
      "\u001b[32m[10/04 19:54:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 19:54:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 19:54:55 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 19:54:55 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 19:54:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 19:54:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0011 s/iter. Inference: 0.1209 s/iter. Eval: 0.0423 s/iter. Total: 0.1642 s/iter. ETA=0:05:11\n",
      "\u001b[32m[10/04 19:55:04 d2.evaluation.evaluator]: \u001b[0mInference done 40/1909. Dataloading: 0.0008 s/iter. Inference: 0.1259 s/iter. Eval: 0.0448 s/iter. Total: 0.1716 s/iter. ETA=0:05:20\n",
      "\u001b[32m[10/04 19:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 70/1909. Dataloading: 0.0009 s/iter. Inference: 0.1188 s/iter. Eval: 0.0498 s/iter. Total: 0.1695 s/iter. ETA=0:05:11\n",
      "\u001b[32m[10/04 19:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 103/1909. Dataloading: 0.0009 s/iter. Inference: 0.1156 s/iter. Eval: 0.0477 s/iter. Total: 0.1642 s/iter. ETA=0:04:56\n",
      "\u001b[32m[10/04 19:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 133/1909. Dataloading: 0.0009 s/iter. Inference: 0.1146 s/iter. Eval: 0.0494 s/iter. Total: 0.1649 s/iter. ETA=0:04:52\n",
      "\u001b[32m[10/04 19:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 165/1909. Dataloading: 0.0009 s/iter. Inference: 0.1136 s/iter. Eval: 0.0492 s/iter. Total: 0.1638 s/iter. ETA=0:04:45\n",
      "\u001b[32m[10/04 19:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 197/1909. Dataloading: 0.0009 s/iter. Inference: 0.1131 s/iter. Eval: 0.0488 s/iter. Total: 0.1628 s/iter. ETA=0:04:38\n",
      "\u001b[32m[10/04 19:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 229/1909. Dataloading: 0.0009 s/iter. Inference: 0.1126 s/iter. Eval: 0.0487 s/iter. Total: 0.1622 s/iter. ETA=0:04:32\n",
      "\u001b[32m[10/04 19:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 260/1909. Dataloading: 0.0009 s/iter. Inference: 0.1123 s/iter. Eval: 0.0493 s/iter. Total: 0.1625 s/iter. ETA=0:04:27\n",
      "\u001b[32m[10/04 19:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 293/1909. Dataloading: 0.0009 s/iter. Inference: 0.1120 s/iter. Eval: 0.0486 s/iter. Total: 0.1616 s/iter. ETA=0:04:21\n",
      "\u001b[32m[10/04 19:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 325/1909. Dataloading: 0.0009 s/iter. Inference: 0.1118 s/iter. Eval: 0.0483 s/iter. Total: 0.1611 s/iter. ETA=0:04:15\n",
      "\u001b[32m[10/04 19:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 356/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0488 s/iter. Total: 0.1615 s/iter. ETA=0:04:10\n",
      "\u001b[32m[10/04 19:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 389/1909. Dataloading: 0.0009 s/iter. Inference: 0.1116 s/iter. Eval: 0.0484 s/iter. Total: 0.1609 s/iter. ETA=0:04:04\n",
      "\u001b[32m[10/04 19:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 421/1909. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 0.0486 s/iter. Total: 0.1611 s/iter. ETA=0:03:59\n",
      "\u001b[32m[10/04 19:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 454/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0483 s/iter. Total: 0.1606 s/iter. ETA=0:03:53\n",
      "\u001b[32m[10/04 19:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 486/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0483 s/iter. Total: 0.1605 s/iter. ETA=0:03:48\n",
      "\u001b[32m[10/04 19:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 516/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0488 s/iter. Total: 0.1610 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/04 19:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 545/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0494 s/iter. Total: 0.1617 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 19:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 575/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0498 s/iter. Total: 0.1621 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 19:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 603/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0506 s/iter. Total: 0.1629 s/iter. ETA=0:03:32\n",
      "\u001b[32m[10/04 19:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 634/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0505 s/iter. Total: 0.1629 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/04 19:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 665/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0507 s/iter. Total: 0.1631 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/04 19:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 695/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0510 s/iter. Total: 0.1633 s/iter. ETA=0:03:18\n",
      "\u001b[32m[10/04 19:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 726/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0511 s/iter. Total: 0.1634 s/iter. ETA=0:03:13\n",
      "\u001b[32m[10/04 19:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 756/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0513 s/iter. Total: 0.1637 s/iter. ETA=0:03:08\n",
      "\u001b[32m[10/04 19:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 787/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0514 s/iter. Total: 0.1638 s/iter. ETA=0:03:03\n",
      "\u001b[32m[10/04 19:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 820/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0511 s/iter. Total: 0.1634 s/iter. ETA=0:02:57\n",
      "\u001b[32m[10/04 19:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 850/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0513 s/iter. Total: 0.1636 s/iter. ETA=0:02:53\n",
      "\u001b[32m[10/04 19:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 882/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0511 s/iter. Total: 0.1634 s/iter. ETA=0:02:47\n",
      "\u001b[32m[10/04 19:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 914/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0510 s/iter. Total: 0.1632 s/iter. ETA=0:02:42\n",
      "\u001b[32m[10/04 19:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 947/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0506 s/iter. Total: 0.1628 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/04 19:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 977/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0509 s/iter. Total: 0.1631 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/04 19:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 1007/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0510 s/iter. Total: 0.1632 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/04 19:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 1038/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0510 s/iter. Total: 0.1632 s/iter. ETA=0:02:22\n",
      "\u001b[32m[10/04 19:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 1070/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0510 s/iter. Total: 0.1632 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/04 19:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 1099/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0514 s/iter. Total: 0.1636 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/04 19:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 1133/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0511 s/iter. Total: 0.1632 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/04 19:58:07 d2.evaluation.evaluator]: \u001b[0mInference done 1166/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0510 s/iter. Total: 0.1630 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/04 19:58:12 d2.evaluation.evaluator]: \u001b[0mInference done 1196/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0511 s/iter. Total: 0.1631 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/04 19:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 1227/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0511 s/iter. Total: 0.1630 s/iter. ETA=0:01:51\n",
      "\u001b[32m[10/04 19:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 1262/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0507 s/iter. Total: 0.1626 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/04 19:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 1292/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0509 s/iter. Total: 0.1628 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/04 19:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 1325/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0508 s/iter. Total: 0.1625 s/iter. ETA=0:01:34\n",
      "\u001b[32m[10/04 19:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 1356/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0508 s/iter. Total: 0.1625 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/04 19:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 1390/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0506 s/iter. Total: 0.1622 s/iter. ETA=0:01:24\n",
      "\u001b[32m[10/04 19:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1423/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0505 s/iter. Total: 0.1621 s/iter. ETA=0:01:18\n",
      "\u001b[32m[10/04 19:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1453/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0507 s/iter. Total: 0.1622 s/iter. ETA=0:01:13\n",
      "\u001b[32m[10/04 19:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 1482/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0509 s/iter. Total: 0.1625 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/04 19:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 1513/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0510 s/iter. Total: 0.1625 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/04 19:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 1546/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0509 s/iter. Total: 0.1624 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/04 19:59:13 d2.evaluation.evaluator]: \u001b[0mInference done 1579/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0508 s/iter. Total: 0.1622 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/04 19:59:18 d2.evaluation.evaluator]: \u001b[0mInference done 1607/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0511 s/iter. Total: 0.1626 s/iter. ETA=0:00:49\n",
      "\u001b[32m[10/04 19:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 1639/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0511 s/iter. Total: 0.1625 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/04 19:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 1669/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0512 s/iter. Total: 0.1627 s/iter. ETA=0:00:39\n",
      "\u001b[32m[10/04 19:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 1703/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/04 19:59:38 d2.evaluation.evaluator]: \u001b[0mInference done 1734/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/04 19:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 1767/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0508 s/iter. Total: 0.1622 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/04 19:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 1799/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0507 s/iter. Total: 0.1621 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/04 19:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 1828/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1623 s/iter. ETA=0:00:13\n",
      "\u001b[32m[10/04 19:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 1860/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1622 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/04 20:00:04 d2.evaluation.evaluator]: \u001b[0mInference done 1893/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0508 s/iter. Total: 0.1621 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/04 20:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:08.707338 (0.162136 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:00:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:30 (0.110357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.890\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.855\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.878\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.847\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.920\n",
      "\u001b[32m[10/04 20:00:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 80.393 | 88.981 | 85.509 | 0.000 | 67.760 | 87.767 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:00:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.47 seconds.\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.832\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.892\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.876\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.868\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.162 | 89.236 | 87.641 | 0.000 | 69.628 | 90.598 |\n",
      "\u001b[32m[10/04 20:00:10 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: 80.3931,88.9815,85.5090,0.0000,67.7600,87.7668\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:00:10 d2.evaluation.testing]: \u001b[0mcopypaste: 83.1617,89.2364,87.6411,0.0000,69.6275,90.5982\n",
      "\u001b[32m[10/04 20:00:10 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 1999  total_loss: 1.059  loss_cls_stage0: 0.0591  loss_box_reg_stage0: 0.1151  loss_cls_stage1: 0.06296  loss_box_reg_stage1: 0.2394  loss_cls_stage2: 0.06578  loss_box_reg_stage2: 0.3551  loss_mask: 0.05941  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.03958    time: 0.7604  last_time: 0.8161  data_time: 0.0030  last_data_time: 0.0011   lr: 0.0001251  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:00:26 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 2019  total_loss: 1.072  loss_cls_stage0: 0.05703  loss_box_reg_stage0: 0.1153  loss_cls_stage1: 0.0336  loss_box_reg_stage1: 0.2446  loss_cls_stage2: 0.03822  loss_box_reg_stage2: 0.3711  loss_mask: 0.0571  loss_rpn_cls: 0.02948  loss_rpn_loc: 0.04054    time: 0.7606  last_time: 0.7913  data_time: 0.0034  last_data_time: 0.0015   lr: 0.00012313  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:00:41 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 2039  total_loss: 0.8503  loss_cls_stage0: 0.05389  loss_box_reg_stage0: 0.09683  loss_cls_stage1: 0.03177  loss_box_reg_stage1: 0.1879  loss_cls_stage2: 0.03003  loss_box_reg_stage2: 0.2848  loss_mask: 0.04583  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.0387    time: 0.7607  last_time: 0.6414  data_time: 0.0031  last_data_time: 0.0012   lr: 0.00012117  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:00:56 d2.utils.events]: \u001b[0m eta: 0:24:50  iter: 2059  total_loss: 0.9279  loss_cls_stage0: 0.0685  loss_box_reg_stage0: 0.1091  loss_cls_stage1: 0.04706  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.04602  loss_box_reg_stage2: 0.3451  loss_mask: 0.05642  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.03441    time: 0.7606  last_time: 0.7853  data_time: 0.0034  last_data_time: 0.0011   lr: 0.00011921  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:01:12 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 2079  total_loss: 0.9119  loss_cls_stage0: 0.05896  loss_box_reg_stage0: 0.1088  loss_cls_stage1: 0.04013  loss_box_reg_stage1: 0.2035  loss_cls_stage2: 0.03883  loss_box_reg_stage2: 0.308  loss_mask: 0.0478  loss_rpn_cls: 0.02158  loss_rpn_loc: 0.04185    time: 0.7610  last_time: 0.7225  data_time: 0.0031  last_data_time: 0.0014   lr: 0.00011725  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:01:27 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 2099  total_loss: 0.9712  loss_cls_stage0: 0.06001  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.03785  loss_box_reg_stage1: 0.2304  loss_cls_stage2: 0.0382  loss_box_reg_stage2: 0.3489  loss_mask: 0.05202  loss_rpn_cls: 0.02163  loss_rpn_loc: 0.03202    time: 0.7609  last_time: 0.6948  data_time: 0.0033  last_data_time: 0.0053   lr: 0.00011529  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:01:43 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 2119  total_loss: 0.9383  loss_cls_stage0: 0.06803  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.03862  loss_box_reg_stage1: 0.2172  loss_cls_stage2: 0.0458  loss_box_reg_stage2: 0.33  loss_mask: 0.04958  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.03759    time: 0.7610  last_time: 0.6297  data_time: 0.0034  last_data_time: 0.0080   lr: 0.00011333  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:01:57 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 2139  total_loss: 0.9906  loss_cls_stage0: 0.06029  loss_box_reg_stage0: 0.1247  loss_cls_stage1: 0.03304  loss_box_reg_stage1: 0.2316  loss_cls_stage2: 0.04044  loss_box_reg_stage2: 0.3682  loss_mask: 0.04855  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.02961    time: 0.7609  last_time: 0.8198  data_time: 0.0034  last_data_time: 0.0077   lr: 0.00011138  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:02:12 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 2159  total_loss: 1.067  loss_cls_stage0: 0.0668  loss_box_reg_stage0: 0.1281  loss_cls_stage1: 0.05113  loss_box_reg_stage1: 0.2522  loss_cls_stage2: 0.04977  loss_box_reg_stage2: 0.3961  loss_mask: 0.0615  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.04004    time: 0.7607  last_time: 0.6491  data_time: 0.0032  last_data_time: 0.0073   lr: 0.00010943  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:02:27 d2.utils.events]: \u001b[0m eta: 0:23:15  iter: 2179  total_loss: 0.9147  loss_cls_stage0: 0.05472  loss_box_reg_stage0: 0.1044  loss_cls_stage1: 0.03696  loss_box_reg_stage1: 0.1938  loss_cls_stage2: 0.03689  loss_box_reg_stage2: 0.2804  loss_mask: 0.05039  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.03175    time: 0.7606  last_time: 0.9043  data_time: 0.0036  last_data_time: 0.0089   lr: 0.00010748  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:02:43 d2.utils.events]: \u001b[0m eta: 0:23:02  iter: 2199  total_loss: 1.07  loss_cls_stage0: 0.06098  loss_box_reg_stage0: 0.1261  loss_cls_stage1: 0.03775  loss_box_reg_stage1: 0.2666  loss_cls_stage2: 0.03901  loss_box_reg_stage2: 0.3719  loss_mask: 0.05899  loss_rpn_cls: 0.02299  loss_rpn_loc: 0.03274    time: 0.7607  last_time: 0.7333  data_time: 0.0031  last_data_time: 0.0079   lr: 0.00010554  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:02:58 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 2219  total_loss: 1.007  loss_cls_stage0: 0.0629  loss_box_reg_stage0: 0.1132  loss_cls_stage1: 0.04163  loss_box_reg_stage1: 0.2388  loss_cls_stage2: 0.03831  loss_box_reg_stage2: 0.3306  loss_mask: 0.05054  loss_rpn_cls: 0.02027  loss_rpn_loc: 0.03128    time: 0.7607  last_time: 0.6874  data_time: 0.0032  last_data_time: 0.0011   lr: 0.00010361  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:03:13 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 2239  total_loss: 1.054  loss_cls_stage0: 0.0631  loss_box_reg_stage0: 0.1281  loss_cls_stage1: 0.04903  loss_box_reg_stage1: 0.2457  loss_cls_stage2: 0.03987  loss_box_reg_stage2: 0.3401  loss_mask: 0.05809  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.03666    time: 0.7605  last_time: 0.7396  data_time: 0.0030  last_data_time: 0.0010   lr: 0.00010167  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:03:28 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 2259  total_loss: 1.086  loss_cls_stage0: 0.0722  loss_box_reg_stage0: 0.1301  loss_cls_stage1: 0.04876  loss_box_reg_stage1: 0.2645  loss_cls_stage2: 0.06155  loss_box_reg_stage2: 0.3809  loss_mask: 0.06078  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.03253    time: 0.7603  last_time: 0.6014  data_time: 0.0027  last_data_time: 0.0011   lr: 9.9748e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:03:43 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 2279  total_loss: 0.9848  loss_cls_stage0: 0.06396  loss_box_reg_stage0: 0.1114  loss_cls_stage1: 0.04678  loss_box_reg_stage1: 0.2275  loss_cls_stage2: 0.05496  loss_box_reg_stage2: 0.3623  loss_mask: 0.05442  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.03387    time: 0.7603  last_time: 0.7462  data_time: 0.0031  last_data_time: 0.0032   lr: 9.7828e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:03:58 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 2299  total_loss: 0.8813  loss_cls_stage0: 0.05445  loss_box_reg_stage0: 0.1062  loss_cls_stage1: 0.0362  loss_box_reg_stage1: 0.2093  loss_cls_stage2: 0.04187  loss_box_reg_stage2: 0.3046  loss_mask: 0.05446  loss_rpn_cls: 0.02006  loss_rpn_loc: 0.04081    time: 0.7604  last_time: 0.7715  data_time: 0.0033  last_data_time: 0.0012   lr: 9.5915e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:04:14 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 2319  total_loss: 0.9179  loss_cls_stage0: 0.05283  loss_box_reg_stage0: 0.1114  loss_cls_stage1: 0.04062  loss_box_reg_stage1: 0.2213  loss_cls_stage2: 0.03368  loss_box_reg_stage2: 0.3379  loss_mask: 0.05589  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.02824    time: 0.7605  last_time: 0.8606  data_time: 0.0031  last_data_time: 0.0012   lr: 9.4009e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:04:30 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 2339  total_loss: 1.04  loss_cls_stage0: 0.06724  loss_box_reg_stage0: 0.1192  loss_cls_stage1: 0.04675  loss_box_reg_stage1: 0.2252  loss_cls_stage2: 0.04338  loss_box_reg_stage2: 0.3594  loss_mask: 0.05612  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.03233    time: 0.7608  last_time: 0.7612  data_time: 0.0031  last_data_time: 0.0013   lr: 9.2111e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:04:45 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 2359  total_loss: 1.13  loss_cls_stage0: 0.05586  loss_box_reg_stage0: 0.1337  loss_cls_stage1: 0.0441  loss_box_reg_stage1: 0.2387  loss_cls_stage2: 0.04587  loss_box_reg_stage2: 0.372  loss_mask: 0.06576  loss_rpn_cls: 0.02106  loss_rpn_loc: 0.0352    time: 0.7610  last_time: 0.6650  data_time: 0.0031  last_data_time: 0.0011   lr: 9.022e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:05:00 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 2379  total_loss: 1.039  loss_cls_stage0: 0.06529  loss_box_reg_stage0: 0.1107  loss_cls_stage1: 0.05306  loss_box_reg_stage1: 0.2497  loss_cls_stage2: 0.04252  loss_box_reg_stage2: 0.3596  loss_mask: 0.05578  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.03722    time: 0.7608  last_time: 0.7585  data_time: 0.0029  last_data_time: 0.0011   lr: 8.8339e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:05:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:05:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:05:16 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:05:16 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 20:05:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 20:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0007 s/iter. Inference: 0.1077 s/iter. Eval: 0.0426 s/iter. Total: 0.1510 s/iter. ETA=0:04:46\n",
      "\u001b[32m[10/04 20:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 42/1909. Dataloading: 0.0008 s/iter. Inference: 0.1114 s/iter. Eval: 0.0501 s/iter. Total: 0.1623 s/iter. ETA=0:05:02\n",
      "\u001b[32m[10/04 20:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 74/1909. Dataloading: 0.0008 s/iter. Inference: 0.1105 s/iter. Eval: 0.0492 s/iter. Total: 0.1606 s/iter. ETA=0:04:54\n",
      "\u001b[32m[10/04 20:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 106/1909. Dataloading: 0.0008 s/iter. Inference: 0.1102 s/iter. Eval: 0.0491 s/iter. Total: 0.1602 s/iter. ETA=0:04:48\n",
      "\u001b[32m[10/04 20:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 139/1909. Dataloading: 0.0008 s/iter. Inference: 0.1098 s/iter. Eval: 0.0484 s/iter. Total: 0.1592 s/iter. ETA=0:04:41\n",
      "\u001b[32m[10/04 20:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 171/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0486 s/iter. Total: 0.1593 s/iter. ETA=0:04:36\n",
      "\u001b[32m[10/04 20:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 203/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0488 s/iter. Total: 0.1595 s/iter. ETA=0:04:32\n",
      "\u001b[32m[10/04 20:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 236/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0480 s/iter. Total: 0.1585 s/iter. ETA=0:04:25\n",
      "\u001b[32m[10/04 20:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 268/1909. Dataloading: 0.0009 s/iter. Inference: 0.1095 s/iter. Eval: 0.0484 s/iter. Total: 0.1588 s/iter. ETA=0:04:20\n",
      "\u001b[32m[10/04 20:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 301/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0478 s/iter. Total: 0.1581 s/iter. ETA=0:04:14\n",
      "\u001b[32m[10/04 20:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 333/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0477 s/iter. Total: 0.1580 s/iter. ETA=0:04:09\n",
      "\u001b[32m[10/04 20:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 363/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0483 s/iter. Total: 0.1588 s/iter. ETA=0:04:05\n",
      "\u001b[32m[10/04 20:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 396/1909. Dataloading: 0.0009 s/iter. Inference: 0.1095 s/iter. Eval: 0.0482 s/iter. Total: 0.1586 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/04 20:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 428/1909. Dataloading: 0.0009 s/iter. Inference: 0.1095 s/iter. Eval: 0.0483 s/iter. Total: 0.1587 s/iter. ETA=0:03:55\n",
      "\u001b[32m[10/04 20:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 461/1909. Dataloading: 0.0009 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/04 20:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 493/1909. Dataloading: 0.0009 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/04 20:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 523/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0485 s/iter. Total: 0.1590 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 20:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 553/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0490 s/iter. Total: 0.1596 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 20:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 580/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0501 s/iter. Total: 0.1609 s/iter. ETA=0:03:33\n",
      "\u001b[32m[10/04 20:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 611/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0502 s/iter. Total: 0.1610 s/iter. ETA=0:03:28\n",
      "\u001b[32m[10/04 20:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 643/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0501 s/iter. Total: 0.1608 s/iter. ETA=0:03:23\n",
      "\u001b[32m[10/04 20:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 672/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0506 s/iter. Total: 0.1614 s/iter. ETA=0:03:19\n",
      "\u001b[32m[10/04 20:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 703/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0507 s/iter. Total: 0.1616 s/iter. ETA=0:03:14\n",
      "\u001b[32m[10/04 20:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 733/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0508 s/iter. Total: 0.1618 s/iter. ETA=0:03:10\n",
      "\u001b[32m[10/04 20:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 763/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0511 s/iter. Total: 0.1622 s/iter. ETA=0:03:05\n",
      "\u001b[32m[10/04 20:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 794/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0511 s/iter. Total: 0.1622 s/iter. ETA=0:03:00\n",
      "\u001b[32m[10/04 20:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 827/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0508 s/iter. Total: 0.1619 s/iter. ETA=0:02:55\n",
      "\u001b[32m[10/04 20:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 857/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0510 s/iter. Total: 0.1622 s/iter. ETA=0:02:50\n",
      "\u001b[32m[10/04 20:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 889/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0510 s/iter. Total: 0.1622 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 20:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 921/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0508 s/iter. Total: 0.1621 s/iter. ETA=0:02:40\n",
      "\u001b[32m[10/04 20:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 954/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0506 s/iter. Total: 0.1618 s/iter. ETA=0:02:34\n",
      "\u001b[32m[10/04 20:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 983/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1622 s/iter. ETA=0:02:30\n",
      "\u001b[32m[10/04 20:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 1014/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1623 s/iter. ETA=0:02:25\n",
      "\u001b[32m[10/04 20:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 1044/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0511 s/iter. Total: 0.1625 s/iter. ETA=0:02:20\n",
      "\u001b[32m[10/04 20:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 1074/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0512 s/iter. Total: 0.1627 s/iter. ETA=0:02:15\n",
      "\u001b[32m[10/04 20:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 1104/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0514 s/iter. Total: 0.1629 s/iter. ETA=0:02:11\n",
      "\u001b[32m[10/04 20:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 1137/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0511 s/iter. Total: 0.1626 s/iter. ETA=0:02:05\n",
      "\u001b[32m[10/04 20:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 1169/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0510 s/iter. Total: 0.1625 s/iter. ETA=0:02:00\n",
      "\u001b[32m[10/04 20:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 1198/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0513 s/iter. Total: 0.1628 s/iter. ETA=0:01:55\n",
      "\u001b[32m[10/04 20:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 1230/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0512 s/iter. Total: 0.1627 s/iter. ETA=0:01:50\n",
      "\u001b[32m[10/04 20:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 1265/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0509 s/iter. Total: 0.1623 s/iter. ETA=0:01:44\n",
      "\u001b[32m[10/04 20:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 1295/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:01:39\n",
      "\u001b[32m[10/04 20:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 1327/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1623 s/iter. ETA=0:01:34\n",
      "\u001b[32m[10/04 20:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 1358/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/04 20:09:03 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0507 s/iter. Total: 0.1621 s/iter. ETA=0:01:23\n",
      "\u001b[32m[10/04 20:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 1424/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0507 s/iter. Total: 0.1620 s/iter. ETA=0:01:18\n",
      "\u001b[32m[10/04 20:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 1454/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0508 s/iter. Total: 0.1622 s/iter. ETA=0:01:13\n",
      "\u001b[32m[10/04 20:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 1483/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/04 20:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 1514/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0511 s/iter. Total: 0.1625 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/04 20:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 1547/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0510 s/iter. Total: 0.1624 s/iter. ETA=0:00:58\n",
      "\u001b[32m[10/04 20:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 1580/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0509 s/iter. Total: 0.1622 s/iter. ETA=0:00:53\n",
      "\u001b[32m[10/04 20:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 1608/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0512 s/iter. Total: 0.1626 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/04 20:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 1640/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0512 s/iter. Total: 0.1625 s/iter. ETA=0:00:43\n",
      "\u001b[32m[10/04 20:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 1670/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0513 s/iter. Total: 0.1626 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/04 20:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 1704/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0511 s/iter. Total: 0.1624 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/04 20:10:00 d2.evaluation.evaluator]: \u001b[0mInference done 1735/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0511 s/iter. Total: 0.1624 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/04 20:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 1768/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0510 s/iter. Total: 0.1622 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/04 20:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 1800/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0509 s/iter. Total: 0.1621 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/04 20:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 1829/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0510 s/iter. Total: 0.1623 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/04 20:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 1861/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0510 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/04 20:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 1894/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0509 s/iter. Total: 0.1621 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/04 20:10:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:08.790651 (0.162180 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:10:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:30 (0.110312 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.809\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.891\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.863\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.683\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.922\n",
      "\u001b[32m[10/04 20:10:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 80.872 | 89.135 | 86.306 | 0.083 | 68.271 | 88.129 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:10:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.51 seconds.\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.836\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.900\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.878\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.871\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.754\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.617 | 89.982 | 87.799 | 0.000 | 70.077 | 90.901 |\n",
      "\u001b[32m[10/04 20:10:31 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: 80.8719,89.1349,86.3063,0.0825,68.2710,88.1293\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:10:31 d2.evaluation.testing]: \u001b[0mcopypaste: 83.6169,89.9817,87.7990,0.0000,70.0774,90.9014\n",
      "\u001b[32m[10/04 20:10:31 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 2399  total_loss: 0.877  loss_cls_stage0: 0.0536  loss_box_reg_stage0: 0.1021  loss_cls_stage1: 0.04621  loss_box_reg_stage1: 0.1966  loss_cls_stage2: 0.0387  loss_box_reg_stage2: 0.3034  loss_mask: 0.05272  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.03102    time: 0.7610  last_time: 0.8328  data_time: 0.0031  last_data_time: 0.0011   lr: 8.6466e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:10:47 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 2419  total_loss: 0.8789  loss_cls_stage0: 0.05557  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.03864  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.03145  loss_box_reg_stage2: 0.3292  loss_mask: 0.0484  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.02789    time: 0.7614  last_time: 0.7446  data_time: 0.0035  last_data_time: 0.0015   lr: 8.4603e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:11:03 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 2439  total_loss: 1.109  loss_cls_stage0: 0.05794  loss_box_reg_stage0: 0.1241  loss_cls_stage1: 0.04932  loss_box_reg_stage1: 0.2553  loss_cls_stage2: 0.04401  loss_box_reg_stage2: 0.3771  loss_mask: 0.05663  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.03125    time: 0.7614  last_time: 0.8146  data_time: 0.0032  last_data_time: 0.0010   lr: 8.275e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:11:18 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 2459  total_loss: 0.9088  loss_cls_stage0: 0.05548  loss_box_reg_stage0: 0.1001  loss_cls_stage1: 0.03205  loss_box_reg_stage1: 0.2165  loss_cls_stage2: 0.03364  loss_box_reg_stage2: 0.2942  loss_mask: 0.05316  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.03087    time: 0.7616  last_time: 0.8289  data_time: 0.0031  last_data_time: 0.0012   lr: 8.0907e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:11:34 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 2479  total_loss: 0.9944  loss_cls_stage0: 0.05274  loss_box_reg_stage0: 0.1136  loss_cls_stage1: 0.03408  loss_box_reg_stage1: 0.2559  loss_cls_stage2: 0.0408  loss_box_reg_stage2: 0.3753  loss_mask: 0.056  loss_rpn_cls: 0.02325  loss_rpn_loc: 0.02935    time: 0.7619  last_time: 0.9230  data_time: 0.0031  last_data_time: 0.0012   lr: 7.9076e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:11:50 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 2499  total_loss: 1.048  loss_cls_stage0: 0.06564  loss_box_reg_stage0: 0.1206  loss_cls_stage1: 0.04921  loss_box_reg_stage1: 0.2291  loss_cls_stage2: 0.05653  loss_box_reg_stage2: 0.3463  loss_mask: 0.05978  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.04399    time: 0.7621  last_time: 0.7040  data_time: 0.0031  last_data_time: 0.0014   lr: 7.7255e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:12:05 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 2519  total_loss: 0.9559  loss_cls_stage0: 0.06821  loss_box_reg_stage0: 0.1137  loss_cls_stage1: 0.05625  loss_box_reg_stage1: 0.2335  loss_cls_stage2: 0.05818  loss_box_reg_stage2: 0.3466  loss_mask: 0.05622  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.03615    time: 0.7621  last_time: 0.8563  data_time: 0.0031  last_data_time: 0.0011   lr: 7.5447e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:12:20 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 2539  total_loss: 0.9964  loss_cls_stage0: 0.06956  loss_box_reg_stage0: 0.1108  loss_cls_stage1: 0.06265  loss_box_reg_stage1: 0.2298  loss_cls_stage2: 0.06354  loss_box_reg_stage2: 0.3576  loss_mask: 0.0557  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.03086    time: 0.7620  last_time: 0.8759  data_time: 0.0029  last_data_time: 0.0011   lr: 7.365e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:12:36 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 2559  total_loss: 1.095  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.123  loss_cls_stage1: 0.04721  loss_box_reg_stage1: 0.2524  loss_cls_stage2: 0.05071  loss_box_reg_stage2: 0.3868  loss_mask: 0.05209  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.0322    time: 0.7622  last_time: 0.6221  data_time: 0.0031  last_data_time: 0.0011   lr: 7.1866e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:12:51 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 2579  total_loss: 0.9776  loss_cls_stage0: 0.06236  loss_box_reg_stage0: 0.1175  loss_cls_stage1: 0.04034  loss_box_reg_stage1: 0.2523  loss_cls_stage2: 0.03842  loss_box_reg_stage2: 0.3919  loss_mask: 0.05056  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.04202    time: 0.7620  last_time: 0.6141  data_time: 0.0029  last_data_time: 0.0010   lr: 7.0096e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:13:06 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 2599  total_loss: 0.9631  loss_cls_stage0: 0.06229  loss_box_reg_stage0: 0.1134  loss_cls_stage1: 0.03553  loss_box_reg_stage1: 0.2264  loss_cls_stage2: 0.0414  loss_box_reg_stage2: 0.3449  loss_mask: 0.05629  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.03522    time: 0.7619  last_time: 0.5958  data_time: 0.0029  last_data_time: 0.0012   lr: 6.8339e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:13:20 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 2619  total_loss: 1.071  loss_cls_stage0: 0.05804  loss_box_reg_stage0: 0.1273  loss_cls_stage1: 0.04282  loss_box_reg_stage1: 0.2569  loss_cls_stage2: 0.03871  loss_box_reg_stage2: 0.3547  loss_mask: 0.0527  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.03153    time: 0.7616  last_time: 0.7519  data_time: 0.0029  last_data_time: 0.0011   lr: 6.6596e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:13:36 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 2639  total_loss: 1.049  loss_cls_stage0: 0.06143  loss_box_reg_stage0: 0.1067  loss_cls_stage1: 0.04628  loss_box_reg_stage1: 0.2387  loss_cls_stage2: 0.06037  loss_box_reg_stage2: 0.3241  loss_mask: 0.05261  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.04218    time: 0.7619  last_time: 0.7530  data_time: 0.0030  last_data_time: 0.0021   lr: 6.4867e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:13:51 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 2659  total_loss: 1.001  loss_cls_stage0: 0.07328  loss_box_reg_stage0: 0.1206  loss_cls_stage1: 0.05707  loss_box_reg_stage1: 0.2359  loss_cls_stage2: 0.04375  loss_box_reg_stage2: 0.3265  loss_mask: 0.05493  loss_rpn_cls: 0.02015  loss_rpn_loc: 0.02882    time: 0.7619  last_time: 0.7192  data_time: 0.0029  last_data_time: 0.0009   lr: 6.3153e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:14:07 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 2679  total_loss: 1.01  loss_cls_stage0: 0.06076  loss_box_reg_stage0: 0.1202  loss_cls_stage1: 0.05648  loss_box_reg_stage1: 0.2534  loss_cls_stage2: 0.0525  loss_box_reg_stage2: 0.3679  loss_mask: 0.05376  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.03192    time: 0.7620  last_time: 0.9548  data_time: 0.0031  last_data_time: 0.0027   lr: 6.1454e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:14:23 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 2699  total_loss: 1.169  loss_cls_stage0: 0.06157  loss_box_reg_stage0: 0.1249  loss_cls_stage1: 0.04265  loss_box_reg_stage1: 0.2552  loss_cls_stage2: 0.05625  loss_box_reg_stage2: 0.3938  loss_mask: 0.05951  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.03754    time: 0.7621  last_time: 0.9503  data_time: 0.0032  last_data_time: 0.0011   lr: 5.9771e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:14:38 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 2719  total_loss: 0.9628  loss_cls_stage0: 0.05857  loss_box_reg_stage0: 0.1043  loss_cls_stage1: 0.04859  loss_box_reg_stage1: 0.2095  loss_cls_stage2: 0.0571  loss_box_reg_stage2: 0.322  loss_mask: 0.05177  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.03035    time: 0.7621  last_time: 0.9408  data_time: 0.0028  last_data_time: 0.0012   lr: 5.8105e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:14:53 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 2739  total_loss: 0.9145  loss_cls_stage0: 0.04599  loss_box_reg_stage0: 0.1226  loss_cls_stage1: 0.02947  loss_box_reg_stage1: 0.2313  loss_cls_stage2: 0.03263  loss_box_reg_stage2: 0.3791  loss_mask: 0.04929  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.03404    time: 0.7622  last_time: 0.7300  data_time: 0.0030  last_data_time: 0.0059   lr: 5.6454e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:15:08 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 2759  total_loss: 0.9103  loss_cls_stage0: 0.06459  loss_box_reg_stage0: 0.114  loss_cls_stage1: 0.04533  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.0433  loss_box_reg_stage2: 0.3417  loss_mask: 0.05477  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.03712    time: 0.7620  last_time: 0.6168  data_time: 0.0030  last_data_time: 0.0059   lr: 5.4821e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:15:23 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 2779  total_loss: 1.083  loss_cls_stage0: 0.05809  loss_box_reg_stage0: 0.1215  loss_cls_stage1: 0.04766  loss_box_reg_stage1: 0.2546  loss_cls_stage2: 0.04562  loss_box_reg_stage2: 0.3764  loss_mask: 0.05122  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.02896    time: 0.7620  last_time: 0.8964  data_time: 0.0030  last_data_time: 0.0069   lr: 5.3205e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:15:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:15:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:15:39 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:15:39 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 20:15:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 20:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0009 s/iter. Inference: 0.1073 s/iter. Eval: 0.0377 s/iter. Total: 0.1459 s/iter. ETA=0:04:36\n",
      "\u001b[32m[10/04 20:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0470 s/iter. Total: 0.1588 s/iter. ETA=0:04:56\n",
      "\u001b[32m[10/04 20:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 75/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0470 s/iter. Total: 0.1578 s/iter. ETA=0:04:49\n",
      "\u001b[32m[10/04 20:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 108/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0470 s/iter. Total: 0.1575 s/iter. ETA=0:04:43\n",
      "\u001b[32m[10/04 20:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 141/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0466 s/iter. Total: 0.1570 s/iter. ETA=0:04:37\n",
      "\u001b[32m[10/04 20:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 173/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0467 s/iter. Total: 0.1571 s/iter. ETA=0:04:32\n",
      "\u001b[32m[10/04 20:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 205/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0471 s/iter. Total: 0.1575 s/iter. ETA=0:04:28\n",
      "\u001b[32m[10/04 20:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 239/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0461 s/iter. Total: 0.1565 s/iter. ETA=0:04:21\n",
      "\u001b[32m[10/04 20:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 270/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0467 s/iter. Total: 0.1572 s/iter. ETA=0:04:17\n",
      "\u001b[32m[10/04 20:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 304/1909. Dataloading: 0.0009 s/iter. Inference: 0.1096 s/iter. Eval: 0.0460 s/iter. Total: 0.1565 s/iter. ETA=0:04:11\n",
      "\u001b[32m[10/04 20:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 333/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0459 s/iter. Total: 0.1583 s/iter. ETA=0:04:09\n",
      "\u001b[32m[10/04 20:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 364/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0465 s/iter. Total: 0.1588 s/iter. ETA=0:04:05\n",
      "\u001b[32m[10/04 20:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 396/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0464 s/iter. Total: 0.1587 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/04 20:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 428/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0465 s/iter. Total: 0.1587 s/iter. ETA=0:03:55\n",
      "\u001b[32m[10/04 20:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 461/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0463 s/iter. Total: 0.1584 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/04 20:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 493/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0463 s/iter. Total: 0.1583 s/iter. ETA=0:03:44\n",
      "\u001b[32m[10/04 20:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 524/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0467 s/iter. Total: 0.1587 s/iter. ETA=0:03:39\n",
      "\u001b[32m[10/04 20:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 555/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0471 s/iter. Total: 0.1591 s/iter. ETA=0:03:35\n",
      "\u001b[32m[10/04 20:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 583/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0482 s/iter. Total: 0.1603 s/iter. ETA=0:03:32\n",
      "\u001b[32m[10/04 20:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 615/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0482 s/iter. Total: 0.1603 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/04 20:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 647/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0482 s/iter. Total: 0.1602 s/iter. ETA=0:03:22\n",
      "\u001b[32m[10/04 20:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 676/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0487 s/iter. Total: 0.1609 s/iter. ETA=0:03:18\n",
      "\u001b[32m[10/04 20:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 707/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0488 s/iter. Total: 0.1610 s/iter. ETA=0:03:13\n",
      "\u001b[32m[10/04 20:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 738/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0489 s/iter. Total: 0.1611 s/iter. ETA=0:03:08\n",
      "\u001b[32m[10/04 20:17:44 d2.evaluation.evaluator]: \u001b[0mInference done 769/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0491 s/iter. Total: 0.1612 s/iter. ETA=0:03:03\n",
      "\u001b[32m[10/04 20:17:49 d2.evaluation.evaluator]: \u001b[0mInference done 800/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0491 s/iter. Total: 0.1613 s/iter. ETA=0:02:58\n",
      "\u001b[32m[10/04 20:17:54 d2.evaluation.evaluator]: \u001b[0mInference done 833/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0489 s/iter. Total: 0.1611 s/iter. ETA=0:02:53\n",
      "\u001b[32m[10/04 20:17:59 d2.evaluation.evaluator]: \u001b[0mInference done 864/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0490 s/iter. Total: 0.1611 s/iter. ETA=0:02:48\n",
      "\u001b[32m[10/04 20:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 896/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0489 s/iter. Total: 0.1610 s/iter. ETA=0:02:43\n",
      "\u001b[32m[10/04 20:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 928/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0488 s/iter. Total: 0.1608 s/iter. ETA=0:02:37\n",
      "\u001b[32m[10/04 20:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 960/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0487 s/iter. Total: 0.1608 s/iter. ETA=0:02:32\n",
      "\u001b[32m[10/04 20:18:20 d2.evaluation.evaluator]: \u001b[0mInference done 989/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0491 s/iter. Total: 0.1611 s/iter. ETA=0:02:28\n",
      "\u001b[32m[10/04 20:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 1023/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0488 s/iter. Total: 0.1609 s/iter. ETA=0:02:22\n",
      "\u001b[32m[10/04 20:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 1053/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0490 s/iter. Total: 0.1611 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/04 20:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 1084/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0491 s/iter. Total: 0.1612 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/04 20:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 1115/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0492 s/iter. Total: 0.1613 s/iter. ETA=0:02:08\n",
      "\u001b[32m[10/04 20:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 1148/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0490 s/iter. Total: 0.1610 s/iter. ETA=0:02:02\n",
      "\u001b[32m[10/04 20:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 1178/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0492 s/iter. Total: 0.1613 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/04 20:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 1211/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0491 s/iter. Total: 0.1612 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/04 20:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 1242/1909. Dataloading: 0.0009 s/iter. Inference: 0.1111 s/iter. Eval: 0.0491 s/iter. Total: 0.1612 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/04 20:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 1276/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0488 s/iter. Total: 0.1609 s/iter. ETA=0:01:41\n",
      "\u001b[32m[10/04 20:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 1307/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0489 s/iter. Total: 0.1610 s/iter. ETA=0:01:36\n",
      "\u001b[32m[10/04 20:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 1340/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0488 s/iter. Total: 0.1608 s/iter. ETA=0:01:31\n",
      "\u001b[32m[10/04 20:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 1372/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0488 s/iter. Total: 0.1607 s/iter. ETA=0:01:26\n",
      "\u001b[32m[10/04 20:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 1405/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0486 s/iter. Total: 0.1606 s/iter. ETA=0:01:20\n",
      "\u001b[32m[10/04 20:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 1437/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0486 s/iter. Total: 0.1605 s/iter. ETA=0:01:15\n",
      "\u001b[32m[10/04 20:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 1465/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0490 s/iter. Total: 0.1610 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/04 20:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 1499/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0488 s/iter. Total: 0.1607 s/iter. ETA=0:01:05\n",
      "\u001b[32m[10/04 20:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 1530/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0489 s/iter. Total: 0.1608 s/iter. ETA=0:01:00\n",
      "\u001b[32m[10/04 20:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 1563/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0487 s/iter. Total: 0.1607 s/iter. ETA=0:00:55\n",
      "\u001b[32m[10/04 20:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 1595/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0488 s/iter. Total: 0.1607 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/04 20:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 1624/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0490 s/iter. Total: 0.1610 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/04 20:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 1654/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0491 s/iter. Total: 0.1611 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/04 20:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 1686/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0491 s/iter. Total: 0.1611 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/04 20:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 1720/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0489 s/iter. Total: 0.1609 s/iter. ETA=0:00:30\n",
      "\u001b[32m[10/04 20:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 1752/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0489 s/iter. Total: 0.1609 s/iter. ETA=0:00:25\n",
      "\u001b[32m[10/04 20:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 1785/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0488 s/iter. Total: 0.1607 s/iter. ETA=0:00:19\n",
      "\u001b[32m[10/04 20:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 1815/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0489 s/iter. Total: 0.1608 s/iter. ETA=0:00:15\n",
      "\u001b[32m[10/04 20:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 1846/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0490 s/iter. Total: 0.1609 s/iter. ETA=0:00:10\n",
      "\u001b[32m[10/04 20:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 1881/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0488 s/iter. Total: 0.1607 s/iter. ETA=0:00:04\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:05.968464 (0.160698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:31 (0.110888 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:20:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:20:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/04 20:20:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:20:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.809\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.865\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.884\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.849\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.719\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.922\n",
      "\u001b[32m[10/04 20:20:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 80.877 | 89.268 | 86.452 | 0.012 | 68.200 | 88.365 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:20:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.98 seconds.\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.834\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.695\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.746\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.443 | 89.481 | 87.950 | 0.000 | 69.550 | 90.851 |\n",
      "\u001b[32m[10/04 20:20:50 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: 80.8773,89.2685,86.4519,0.0115,68.2004,88.3645\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: 83.4434,89.4812,87.9501,0.0000,69.5498,90.8510\n",
      "\u001b[32m[10/04 20:20:50 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 2799  total_loss: 1.026  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.1202  loss_cls_stage1: 0.05147  loss_box_reg_stage1: 0.2381  loss_cls_stage2: 0.05062  loss_box_reg_stage2: 0.3446  loss_mask: 0.0638  loss_rpn_cls: 0.02259  loss_rpn_loc: 0.03736    time: 0.7619  last_time: 0.8504  data_time: 0.0030  last_data_time: 0.0051   lr: 5.1606e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:21:06 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 2819  total_loss: 1.015  loss_cls_stage0: 0.05182  loss_box_reg_stage0: 0.118  loss_cls_stage1: 0.04376  loss_box_reg_stage1: 0.2347  loss_cls_stage2: 0.05454  loss_box_reg_stage2: 0.3466  loss_mask: 0.05255  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.02813    time: 0.7619  last_time: 0.5891  data_time: 0.0035  last_data_time: 0.0077   lr: 5.0026e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:21:21 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 2839  total_loss: 0.9905  loss_cls_stage0: 0.06353  loss_box_reg_stage0: 0.1219  loss_cls_stage1: 0.05157  loss_box_reg_stage1: 0.2403  loss_cls_stage2: 0.04694  loss_box_reg_stage2: 0.3449  loss_mask: 0.0616  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.03347    time: 0.7620  last_time: 0.7483  data_time: 0.0032  last_data_time: 0.0083   lr: 4.8464e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:21:36 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 2859  total_loss: 0.9217  loss_cls_stage0: 0.06029  loss_box_reg_stage0: 0.1169  loss_cls_stage1: 0.04651  loss_box_reg_stage1: 0.2106  loss_cls_stage2: 0.03712  loss_box_reg_stage2: 0.3024  loss_mask: 0.0519  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.03574    time: 0.7620  last_time: 0.8681  data_time: 0.0029  last_data_time: 0.0037   lr: 4.6921e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:21:52 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 2879  total_loss: 1.157  loss_cls_stage0: 0.0714  loss_box_reg_stage0: 0.1191  loss_cls_stage1: 0.06867  loss_box_reg_stage1: 0.2494  loss_cls_stage2: 0.06635  loss_box_reg_stage2: 0.3503  loss_mask: 0.05537  loss_rpn_cls: 0.02251  loss_rpn_loc: 0.03505    time: 0.7622  last_time: 0.6998  data_time: 0.0036  last_data_time: 0.0064   lr: 4.5398e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:22:08 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 2899  total_loss: 1.005  loss_cls_stage0: 0.06734  loss_box_reg_stage0: 0.1182  loss_cls_stage1: 0.05474  loss_box_reg_stage1: 0.2415  loss_cls_stage2: 0.05337  loss_box_reg_stage2: 0.3646  loss_mask: 0.0571  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.03398    time: 0.7623  last_time: 0.8735  data_time: 0.0032  last_data_time: 0.0086   lr: 4.3894e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:22:23 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 2919  total_loss: 1.037  loss_cls_stage0: 0.06496  loss_box_reg_stage0: 0.1094  loss_cls_stage1: 0.04017  loss_box_reg_stage1: 0.2279  loss_cls_stage2: 0.03987  loss_box_reg_stage2: 0.34  loss_mask: 0.05184  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.03882    time: 0.7624  last_time: 0.8185  data_time: 0.0032  last_data_time: 0.0080   lr: 4.241e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:22:38 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 2939  total_loss: 0.9047  loss_cls_stage0: 0.05769  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.02972  loss_box_reg_stage1: 0.2126  loss_cls_stage2: 0.02475  loss_box_reg_stage2: 0.3316  loss_mask: 0.04574  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.03087    time: 0.7622  last_time: 0.6495  data_time: 0.0034  last_data_time: 0.0111   lr: 4.0946e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:22:54 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 2959  total_loss: 1.039  loss_cls_stage0: 0.07704  loss_box_reg_stage0: 0.1282  loss_cls_stage1: 0.06072  loss_box_reg_stage1: 0.2599  loss_cls_stage2: 0.06715  loss_box_reg_stage2: 0.3434  loss_mask: 0.06485  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.043    time: 0.7624  last_time: 0.6812  data_time: 0.0030  last_data_time: 0.0076   lr: 3.9503e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:23:09 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 2979  total_loss: 0.9141  loss_cls_stage0: 0.06398  loss_box_reg_stage0: 0.1106  loss_cls_stage1: 0.03891  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.03305  loss_box_reg_stage2: 0.3245  loss_mask: 0.05206  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.03543    time: 0.7623  last_time: 0.6934  data_time: 0.0032  last_data_time: 0.0079   lr: 3.8081e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:23:24 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 2999  total_loss: 1.055  loss_cls_stage0: 0.0763  loss_box_reg_stage0: 0.1117  loss_cls_stage1: 0.04811  loss_box_reg_stage1: 0.2397  loss_cls_stage2: 0.04222  loss_box_reg_stage2: 0.3672  loss_mask: 0.0526  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.0352    time: 0.7621  last_time: 0.6351  data_time: 0.0033  last_data_time: 0.0058   lr: 3.6681e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:23:39 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 3019  total_loss: 1.085  loss_cls_stage0: 0.07085  loss_box_reg_stage0: 0.1189  loss_cls_stage1: 0.0397  loss_box_reg_stage1: 0.2434  loss_cls_stage2: 0.04736  loss_box_reg_stage2: 0.3889  loss_mask: 0.06096  loss_rpn_cls: 0.02296  loss_rpn_loc: 0.03679    time: 0.7621  last_time: 0.8021  data_time: 0.0031  last_data_time: 0.0077   lr: 3.5303e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:23:54 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 3039  total_loss: 0.9707  loss_cls_stage0: 0.05843  loss_box_reg_stage0: 0.1123  loss_cls_stage1: 0.05533  loss_box_reg_stage1: 0.2251  loss_cls_stage2: 0.04915  loss_box_reg_stage2: 0.3204  loss_mask: 0.05397  loss_rpn_cls: 0.02281  loss_rpn_loc: 0.02583    time: 0.7621  last_time: 0.7530  data_time: 0.0031  last_data_time: 0.0082   lr: 3.3946e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:24:10 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 3059  total_loss: 1.041  loss_cls_stage0: 0.05612  loss_box_reg_stage0: 0.1197  loss_cls_stage1: 0.04152  loss_box_reg_stage1: 0.2549  loss_cls_stage2: 0.04725  loss_box_reg_stage2: 0.3531  loss_mask: 0.05551  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.02884    time: 0.7622  last_time: 0.6838  data_time: 0.0030  last_data_time: 0.0081   lr: 3.2612e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:24:25 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 3079  total_loss: 1.068  loss_cls_stage0: 0.06665  loss_box_reg_stage0: 0.1164  loss_cls_stage1: 0.03746  loss_box_reg_stage1: 0.2528  loss_cls_stage2: 0.03985  loss_box_reg_stage2: 0.3958  loss_mask: 0.05195  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.03254    time: 0.7622  last_time: 0.7224  data_time: 0.0030  last_data_time: 0.0069   lr: 3.1301e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:24:40 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 3099  total_loss: 0.9212  loss_cls_stage0: 0.05831  loss_box_reg_stage0: 0.1053  loss_cls_stage1: 0.04254  loss_box_reg_stage1: 0.2222  loss_cls_stage2: 0.04359  loss_box_reg_stage2: 0.3218  loss_mask: 0.04859  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.02513    time: 0.7622  last_time: 0.8458  data_time: 0.0033  last_data_time: 0.0082   lr: 3.0013e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:24:55 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 3119  total_loss: 1.066  loss_cls_stage0: 0.06412  loss_box_reg_stage0: 0.1338  loss_cls_stage1: 0.03869  loss_box_reg_stage1: 0.2601  loss_cls_stage2: 0.04527  loss_box_reg_stage2: 0.3991  loss_mask: 0.05863  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.03541    time: 0.7621  last_time: 0.6776  data_time: 0.0030  last_data_time: 0.0075   lr: 2.8748e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:25:10 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 3139  total_loss: 0.9288  loss_cls_stage0: 0.06506  loss_box_reg_stage0: 0.1036  loss_cls_stage1: 0.03888  loss_box_reg_stage1: 0.1956  loss_cls_stage2: 0.03311  loss_box_reg_stage2: 0.3137  loss_mask: 0.05141  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.03335    time: 0.7620  last_time: 0.6207  data_time: 0.0030  last_data_time: 0.0082   lr: 2.7508e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:25:25 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 3159  total_loss: 0.9505  loss_cls_stage0: 0.05729  loss_box_reg_stage0: 0.1064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.2239  loss_cls_stage2: 0.05915  loss_box_reg_stage2: 0.3338  loss_mask: 0.0573  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.03453    time: 0.7618  last_time: 0.7815  data_time: 0.0030  last_data_time: 0.0086   lr: 2.6291e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:25:41 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 3179  total_loss: 0.8883  loss_cls_stage0: 0.05297  loss_box_reg_stage0: 0.1166  loss_cls_stage1: 0.03747  loss_box_reg_stage1: 0.2128  loss_cls_stage2: 0.04076  loss_box_reg_stage2: 0.3477  loss_mask: 0.05278  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.02916    time: 0.7620  last_time: 0.7945  data_time: 0.0031  last_data_time: 0.0050   lr: 2.5098e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:25:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:25:57 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:25:57 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:25:57 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 20:25:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 20:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0007 s/iter. Inference: 0.1078 s/iter. Eval: 0.0373 s/iter. Total: 0.1457 s/iter. ETA=0:04:36\n",
      "\u001b[32m[10/04 20:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 43/1909. Dataloading: 0.0029 s/iter. Inference: 0.1094 s/iter. Eval: 0.0467 s/iter. Total: 0.1591 s/iter. ETA=0:04:56\n",
      "\u001b[32m[10/04 20:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 75/1909. Dataloading: 0.0020 s/iter. Inference: 0.1093 s/iter. Eval: 0.0469 s/iter. Total: 0.1583 s/iter. ETA=0:04:50\n",
      "\u001b[32m[10/04 20:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 108/1909. Dataloading: 0.0016 s/iter. Inference: 0.1090 s/iter. Eval: 0.0460 s/iter. Total: 0.1568 s/iter. ETA=0:04:42\n",
      "\u001b[32m[10/04 20:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 141/1909. Dataloading: 0.0014 s/iter. Inference: 0.1090 s/iter. Eval: 0.0455 s/iter. Total: 0.1559 s/iter. ETA=0:04:35\n",
      "\u001b[32m[10/04 20:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 173/1909. Dataloading: 0.0013 s/iter. Inference: 0.1090 s/iter. Eval: 0.0458 s/iter. Total: 0.1562 s/iter. ETA=0:04:31\n",
      "\u001b[32m[10/04 20:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 205/1909. Dataloading: 0.0013 s/iter. Inference: 0.1090 s/iter. Eval: 0.0460 s/iter. Total: 0.1563 s/iter. ETA=0:04:26\n",
      "\u001b[32m[10/04 20:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 239/1909. Dataloading: 0.0012 s/iter. Inference: 0.1088 s/iter. Eval: 0.0449 s/iter. Total: 0.1550 s/iter. ETA=0:04:18\n",
      "\u001b[32m[10/04 20:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 271/1909. Dataloading: 0.0012 s/iter. Inference: 0.1089 s/iter. Eval: 0.0457 s/iter. Total: 0.1559 s/iter. ETA=0:04:15\n",
      "\u001b[32m[10/04 20:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 305/1909. Dataloading: 0.0011 s/iter. Inference: 0.1088 s/iter. Eval: 0.0451 s/iter. Total: 0.1552 s/iter. ETA=0:04:08\n",
      "\u001b[32m[10/04 20:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 338/1909. Dataloading: 0.0011 s/iter. Inference: 0.1089 s/iter. Eval: 0.0452 s/iter. Total: 0.1553 s/iter. ETA=0:04:03\n",
      "\u001b[32m[10/04 20:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 370/1909. Dataloading: 0.0011 s/iter. Inference: 0.1089 s/iter. Eval: 0.0454 s/iter. Total: 0.1555 s/iter. ETA=0:03:59\n",
      "\u001b[32m[10/04 20:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 402/1909. Dataloading: 0.0011 s/iter. Inference: 0.1089 s/iter. Eval: 0.0455 s/iter. Total: 0.1556 s/iter. ETA=0:03:54\n",
      "\u001b[32m[10/04 20:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 434/1909. Dataloading: 0.0011 s/iter. Inference: 0.1090 s/iter. Eval: 0.0458 s/iter. Total: 0.1558 s/iter. ETA=0:03:49\n",
      "\u001b[32m[10/04 20:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 468/1909. Dataloading: 0.0011 s/iter. Inference: 0.1089 s/iter. Eval: 0.0454 s/iter. Total: 0.1554 s/iter. ETA=0:03:43\n",
      "\u001b[32m[10/04 20:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 501/1909. Dataloading: 0.0010 s/iter. Inference: 0.1089 s/iter. Eval: 0.0454 s/iter. Total: 0.1554 s/iter. ETA=0:03:38\n",
      "\u001b[32m[10/04 20:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 531/1909. Dataloading: 0.0010 s/iter. Inference: 0.1090 s/iter. Eval: 0.0461 s/iter. Total: 0.1562 s/iter. ETA=0:03:35\n",
      "\u001b[32m[10/04 20:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 561/1909. Dataloading: 0.0010 s/iter. Inference: 0.1091 s/iter. Eval: 0.0468 s/iter. Total: 0.1570 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/04 20:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 591/1909. Dataloading: 0.0010 s/iter. Inference: 0.1092 s/iter. Eval: 0.0474 s/iter. Total: 0.1576 s/iter. ETA=0:03:27\n",
      "\u001b[32m[10/04 20:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 622/1909. Dataloading: 0.0010 s/iter. Inference: 0.1092 s/iter. Eval: 0.0475 s/iter. Total: 0.1578 s/iter. ETA=0:03:23\n",
      "\u001b[32m[10/04 20:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 655/1909. Dataloading: 0.0010 s/iter. Inference: 0.1092 s/iter. Eval: 0.0477 s/iter. Total: 0.1580 s/iter. ETA=0:03:18\n",
      "\u001b[32m[10/04 20:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 686/1909. Dataloading: 0.0010 s/iter. Inference: 0.1093 s/iter. Eval: 0.0478 s/iter. Total: 0.1582 s/iter. ETA=0:03:13\n",
      "\u001b[32m[10/04 20:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 718/1909. Dataloading: 0.0010 s/iter. Inference: 0.1093 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:03:08\n",
      "\u001b[32m[10/04 20:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 748/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0483 s/iter. Total: 0.1588 s/iter. ETA=0:03:04\n",
      "\u001b[32m[10/04 20:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 779/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0484 s/iter. Total: 0.1589 s/iter. ETA=0:02:59\n",
      "\u001b[32m[10/04 20:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 812/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0482 s/iter. Total: 0.1587 s/iter. ETA=0:02:54\n",
      "\u001b[32m[10/04 20:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 844/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0482 s/iter. Total: 0.1587 s/iter. ETA=0:02:49\n",
      "\u001b[32m[10/04 20:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 878/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:02:43\n",
      "\u001b[32m[10/04 20:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 911/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0479 s/iter. Total: 0.1585 s/iter. ETA=0:02:38\n",
      "\u001b[32m[10/04 20:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 944/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0477 s/iter. Total: 0.1582 s/iter. ETA=0:02:32\n",
      "\u001b[32m[10/04 20:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 974/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1586 s/iter. ETA=0:02:28\n",
      "\u001b[32m[10/04 20:28:38 d2.evaluation.evaluator]: \u001b[0mInference done 1006/1909. Dataloading: 0.0010 s/iter. Inference: 0.1096 s/iter. Eval: 0.0480 s/iter. Total: 0.1586 s/iter. ETA=0:02:23\n",
      "\u001b[32m[10/04 20:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 1038/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1587 s/iter. ETA=0:02:18\n",
      "\u001b[32m[10/04 20:28:48 d2.evaluation.evaluator]: \u001b[0mInference done 1070/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:02:13\n",
      "\u001b[32m[10/04 20:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 1099/1909. Dataloading: 0.0010 s/iter. Inference: 0.1096 s/iter. Eval: 0.0485 s/iter. Total: 0.1591 s/iter. ETA=0:02:08\n",
      "\u001b[32m[10/04 20:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 1133/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0482 s/iter. Total: 0.1587 s/iter. ETA=0:02:03\n",
      "\u001b[32m[10/04 20:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 1166/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/04 20:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 1196/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0483 s/iter. Total: 0.1588 s/iter. ETA=0:01:53\n",
      "\u001b[32m[10/04 20:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 1228/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0483 s/iter. Total: 0.1589 s/iter. ETA=0:01:48\n",
      "\u001b[32m[10/04 20:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 1263/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/04 20:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 1294/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/04 20:29:28 d2.evaluation.evaluator]: \u001b[0mInference done 1327/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1585 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/04 20:29:33 d2.evaluation.evaluator]: \u001b[0mInference done 1358/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/04 20:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0478 s/iter. Total: 0.1583 s/iter. ETA=0:01:21\n",
      "\u001b[32m[10/04 20:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 1425/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0477 s/iter. Total: 0.1582 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/04 20:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 1456/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0478 s/iter. Total: 0.1583 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/04 20:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 1486/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0480 s/iter. Total: 0.1585 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/04 20:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 1518/1909. Dataloading: 0.0010 s/iter. Inference: 0.1095 s/iter. Eval: 0.0481 s/iter. Total: 0.1585 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/04 20:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 1551/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/04 20:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 1584/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0479 s/iter. Total: 0.1583 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/04 20:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 1613/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0482 s/iter. Total: 0.1586 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/04 20:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 1645/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0482 s/iter. Total: 0.1587 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/04 20:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 1676/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0483 s/iter. Total: 0.1588 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/04 20:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 1711/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0481 s/iter. Total: 0.1586 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/04 20:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 1742/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0482 s/iter. Total: 0.1586 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/04 20:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 1776/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/04 20:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 1808/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0481 s/iter. Total: 0.1585 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/04 20:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 1838/1909. Dataloading: 0.0010 s/iter. Inference: 0.1094 s/iter. Eval: 0.0482 s/iter. Total: 0.1586 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/04 20:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 1872/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0481 s/iter. Total: 0.1585 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/04 20:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 1905/1909. Dataloading: 0.0009 s/iter. Inference: 0.1094 s/iter. Eval: 0.0480 s/iter. Total: 0.1584 s/iter. ETA=0:00:00\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:01.761409 (0.158488 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:28 (0.109428 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/04 20:31:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:31:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.813\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.865\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.686\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.886\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.723\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.925\n",
      "\u001b[32m[10/04 20:31:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 81.297 | 89.272 | 86.529 | 0.000 | 68.604 | 88.624 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:31:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.46 seconds.\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.835\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.911\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.869\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.747\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.535 | 89.482 | 87.984 | 0.000 | 69.845 | 91.113 |\n",
      "\u001b[32m[10/04 20:31:04 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: 81.2965,89.2715,86.5289,0.0000,68.6041,88.6235\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:31:04 d2.evaluation.testing]: \u001b[0mcopypaste: 83.5354,89.4820,87.9835,0.0000,69.8454,91.1134\n",
      "\u001b[32m[10/04 20:31:04 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 3199  total_loss: 1.027  loss_cls_stage0: 0.06931  loss_box_reg_stage0: 0.1207  loss_cls_stage1: 0.05081  loss_box_reg_stage1: 0.2425  loss_cls_stage2: 0.05563  loss_box_reg_stage2: 0.3449  loss_mask: 0.05294  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.04362    time: 0.7621  last_time: 0.8338  data_time: 0.0033  last_data_time: 0.0065   lr: 2.3931e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:31:20 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 3219  total_loss: 0.9249  loss_cls_stage0: 0.05656  loss_box_reg_stage0: 0.1062  loss_cls_stage1: 0.03844  loss_box_reg_stage1: 0.2286  loss_cls_stage2: 0.04954  loss_box_reg_stage2: 0.3237  loss_mask: 0.0517  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.03595    time: 0.7622  last_time: 0.7606  data_time: 0.0032  last_data_time: 0.0087   lr: 2.2788e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:31:35 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 3239  total_loss: 0.8824  loss_cls_stage0: 0.05517  loss_box_reg_stage0: 0.1014  loss_cls_stage1: 0.04595  loss_box_reg_stage1: 0.2011  loss_cls_stage2: 0.0403  loss_box_reg_stage2: 0.3297  loss_mask: 0.04631  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.0232    time: 0.7622  last_time: 0.7823  data_time: 0.0030  last_data_time: 0.0078   lr: 2.167e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:31:50 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 3259  total_loss: 0.9422  loss_cls_stage0: 0.0588  loss_box_reg_stage0: 0.1025  loss_cls_stage1: 0.03945  loss_box_reg_stage1: 0.2239  loss_cls_stage2: 0.03732  loss_box_reg_stage2: 0.3232  loss_mask: 0.04866  loss_rpn_cls: 0.02444  loss_rpn_loc: 0.04125    time: 0.7621  last_time: 0.7879  data_time: 0.0032  last_data_time: 0.0079   lr: 2.0578e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:32:05 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 3279  total_loss: 0.9761  loss_cls_stage0: 0.05192  loss_box_reg_stage0: 0.1135  loss_cls_stage1: 0.03775  loss_box_reg_stage1: 0.2302  loss_cls_stage2: 0.03113  loss_box_reg_stage2: 0.3227  loss_mask: 0.0539  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.03708    time: 0.7620  last_time: 0.8364  data_time: 0.0032  last_data_time: 0.0065   lr: 1.9512e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:32:20 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 3299  total_loss: 0.9773  loss_cls_stage0: 0.06436  loss_box_reg_stage0: 0.09964  loss_cls_stage1: 0.04548  loss_box_reg_stage1: 0.2112  loss_cls_stage2: 0.04215  loss_box_reg_stage2: 0.3171  loss_mask: 0.05198  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.03683    time: 0.7621  last_time: 0.9245  data_time: 0.0033  last_data_time: 0.0094   lr: 1.8471e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:32:36 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 3319  total_loss: 1.004  loss_cls_stage0: 0.07162  loss_box_reg_stage0: 0.1101  loss_cls_stage1: 0.05716  loss_box_reg_stage1: 0.2266  loss_cls_stage2: 0.04738  loss_box_reg_stage2: 0.3213  loss_mask: 0.05017  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.03019    time: 0.7621  last_time: 0.8462  data_time: 0.0029  last_data_time: 0.0080   lr: 1.7457e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:32:52 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 3339  total_loss: 0.9819  loss_cls_stage0: 0.06165  loss_box_reg_stage0: 0.1015  loss_cls_stage1: 0.04564  loss_box_reg_stage1: 0.2132  loss_cls_stage2: 0.04997  loss_box_reg_stage2: 0.3484  loss_mask: 0.05643  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.03693    time: 0.7623  last_time: 0.8184  data_time: 0.0029  last_data_time: 0.0077   lr: 1.647e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:33:07 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 3359  total_loss: 0.9834  loss_cls_stage0: 0.06384  loss_box_reg_stage0: 0.1042  loss_cls_stage1: 0.06518  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.05979  loss_box_reg_stage2: 0.2947  loss_mask: 0.05341  loss_rpn_cls: 0.02097  loss_rpn_loc: 0.02938    time: 0.7623  last_time: 0.5689  data_time: 0.0031  last_data_time: 0.0071   lr: 1.5509e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:33:22 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 3379  total_loss: 0.9011  loss_cls_stage0: 0.04643  loss_box_reg_stage0: 0.1134  loss_cls_stage1: 0.03166  loss_box_reg_stage1: 0.2239  loss_cls_stage2: 0.03117  loss_box_reg_stage2: 0.3154  loss_mask: 0.05293  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.03041    time: 0.7623  last_time: 0.7853  data_time: 0.0032  last_data_time: 0.0051   lr: 1.4575e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:33:37 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 3399  total_loss: 1.176  loss_cls_stage0: 0.06307  loss_box_reg_stage0: 0.1274  loss_cls_stage1: 0.05386  loss_box_reg_stage1: 0.2751  loss_cls_stage2: 0.05644  loss_box_reg_stage2: 0.4568  loss_mask: 0.06424  loss_rpn_cls: 0.02023  loss_rpn_loc: 0.03468    time: 0.7621  last_time: 0.9472  data_time: 0.0034  last_data_time: 0.0093   lr: 1.3669e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:33:52 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 3419  total_loss: 1.069  loss_cls_stage0: 0.07059  loss_box_reg_stage0: 0.1219  loss_cls_stage1: 0.04418  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.04887  loss_box_reg_stage2: 0.3777  loss_mask: 0.06027  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.03364    time: 0.7621  last_time: 0.6816  data_time: 0.0033  last_data_time: 0.0091   lr: 1.279e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:34:07 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 3439  total_loss: 0.9529  loss_cls_stage0: 0.05418  loss_box_reg_stage0: 0.1095  loss_cls_stage1: 0.03808  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.03581  loss_box_reg_stage2: 0.3524  loss_mask: 0.05599  loss_rpn_cls: 0.01762  loss_rpn_loc: 0.02915    time: 0.7620  last_time: 0.7106  data_time: 0.0032  last_data_time: 0.0093   lr: 1.1938e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:34:22 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 3459  total_loss: 0.9186  loss_cls_stage0: 0.06739  loss_box_reg_stage0: 0.1122  loss_cls_stage1: 0.03567  loss_box_reg_stage1: 0.2148  loss_cls_stage2: 0.03807  loss_box_reg_stage2: 0.3182  loss_mask: 0.05234  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.02251    time: 0.7620  last_time: 0.8532  data_time: 0.0030  last_data_time: 0.0076   lr: 1.1115e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:34:37 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 3479  total_loss: 1.008  loss_cls_stage0: 0.06546  loss_box_reg_stage0: 0.1154  loss_cls_stage1: 0.04519  loss_box_reg_stage1: 0.2443  loss_cls_stage2: 0.04503  loss_box_reg_stage2: 0.3507  loss_mask: 0.05856  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.03067    time: 0.7620  last_time: 0.6903  data_time: 0.0032  last_data_time: 0.0087   lr: 1.032e-05  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:34:53 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 3499  total_loss: 1.084  loss_cls_stage0: 0.07059  loss_box_reg_stage0: 0.1267  loss_cls_stage1: 0.05279  loss_box_reg_stage1: 0.2484  loss_cls_stage2: 0.05246  loss_box_reg_stage2: 0.3511  loss_mask: 0.06219  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.03594    time: 0.7621  last_time: 0.6955  data_time: 0.0031  last_data_time: 0.0076   lr: 9.5527e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:35:09 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 3519  total_loss: 0.8611  loss_cls_stage0: 0.05676  loss_box_reg_stage0: 0.0913  loss_cls_stage1: 0.04332  loss_box_reg_stage1: 0.1703  loss_cls_stage2: 0.03419  loss_box_reg_stage2: 0.269  loss_mask: 0.05236  loss_rpn_cls: 0.02162  loss_rpn_loc: 0.03112    time: 0.7622  last_time: 0.7671  data_time: 0.0033  last_data_time: 0.0089   lr: 8.8141e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:35:24 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 3539  total_loss: 1.087  loss_cls_stage0: 0.06133  loss_box_reg_stage0: 0.1044  loss_cls_stage1: 0.0438  loss_box_reg_stage1: 0.2485  loss_cls_stage2: 0.04281  loss_box_reg_stage2: 0.3446  loss_mask: 0.05205  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.03037    time: 0.7622  last_time: 0.7477  data_time: 0.0033  last_data_time: 0.0097   lr: 8.1042e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:35:40 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 3559  total_loss: 0.9412  loss_cls_stage0: 0.0651  loss_box_reg_stage0: 0.1112  loss_cls_stage1: 0.04012  loss_box_reg_stage1: 0.22  loss_cls_stage2: 0.03581  loss_box_reg_stage2: 0.3343  loss_mask: 0.05028  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.02502    time: 0.7623  last_time: 0.9208  data_time: 0.0031  last_data_time: 0.0092   lr: 7.4232e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:35:55 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 3579  total_loss: 0.9955  loss_cls_stage0: 0.06045  loss_box_reg_stage0: 0.1171  loss_cls_stage1: 0.04355  loss_box_reg_stage1: 0.2317  loss_cls_stage2: 0.03682  loss_box_reg_stage2: 0.3996  loss_mask: 0.05435  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.03563    time: 0.7624  last_time: 0.6963  data_time: 0.0030  last_data_time: 0.0073   lr: 6.7712e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:36:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:36:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:36:11 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:36:12 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 20:36:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 20:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0008 s/iter. Inference: 0.1087 s/iter. Eval: 0.0411 s/iter. Total: 0.1506 s/iter. ETA=0:04:45\n",
      "\u001b[32m[10/04 20:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 43/1909. Dataloading: 0.0008 s/iter. Inference: 0.1100 s/iter. Eval: 0.0464 s/iter. Total: 0.1574 s/iter. ETA=0:04:53\n",
      "\u001b[32m[10/04 20:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 75/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0471 s/iter. Total: 0.1580 s/iter. ETA=0:04:49\n",
      "\u001b[32m[10/04 20:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 108/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0464 s/iter. Total: 0.1573 s/iter. ETA=0:04:43\n",
      "\u001b[32m[10/04 20:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 141/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0459 s/iter. Total: 0.1567 s/iter. ETA=0:04:37\n",
      "\u001b[32m[10/04 20:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 173/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0461 s/iter. Total: 0.1569 s/iter. ETA=0:04:32\n",
      "\u001b[32m[10/04 20:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 205/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0462 s/iter. Total: 0.1570 s/iter. ETA=0:04:27\n",
      "\u001b[32m[10/04 20:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 239/1909. Dataloading: 0.0009 s/iter. Inference: 0.1097 s/iter. Eval: 0.0451 s/iter. Total: 0.1557 s/iter. ETA=0:04:20\n",
      "\u001b[32m[10/04 20:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 270/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0457 s/iter. Total: 0.1565 s/iter. ETA=0:04:16\n",
      "\u001b[32m[10/04 20:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 304/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0452 s/iter. Total: 0.1559 s/iter. ETA=0:04:10\n",
      "\u001b[32m[10/04 20:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 337/1909. Dataloading: 0.0009 s/iter. Inference: 0.1098 s/iter. Eval: 0.0452 s/iter. Total: 0.1559 s/iter. ETA=0:04:05\n",
      "\u001b[32m[10/04 20:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 369/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0455 s/iter. Total: 0.1563 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/04 20:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 401/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0456 s/iter. Total: 0.1565 s/iter. ETA=0:03:55\n",
      "\u001b[32m[10/04 20:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 433/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0457 s/iter. Total: 0.1566 s/iter. ETA=0:03:51\n",
      "\u001b[32m[10/04 20:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 467/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0452 s/iter. Total: 0.1561 s/iter. ETA=0:03:45\n",
      "\u001b[32m[10/04 20:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 499/1909. Dataloading: 0.0009 s/iter. Inference: 0.1099 s/iter. Eval: 0.0453 s/iter. Total: 0.1562 s/iter. ETA=0:03:40\n",
      "\u001b[32m[10/04 20:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 529/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0458 s/iter. Total: 0.1568 s/iter. ETA=0:03:36\n",
      "\u001b[32m[10/04 20:37:41 d2.evaluation.evaluator]: \u001b[0mInference done 558/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0467 s/iter. Total: 0.1578 s/iter. ETA=0:03:33\n",
      "\u001b[32m[10/04 20:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 588/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0472 s/iter. Total: 0.1584 s/iter. ETA=0:03:29\n",
      "\u001b[32m[10/04 20:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 620/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0472 s/iter. Total: 0.1584 s/iter. ETA=0:03:24\n",
      "\u001b[32m[10/04 20:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 652/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0473 s/iter. Total: 0.1585 s/iter. ETA=0:03:19\n",
      "\u001b[32m[10/04 20:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 682/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0476 s/iter. Total: 0.1590 s/iter. ETA=0:03:15\n",
      "\u001b[32m[10/04 20:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 714/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0478 s/iter. Total: 0.1591 s/iter. ETA=0:03:10\n",
      "\u001b[32m[10/04 20:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 744/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0481 s/iter. Total: 0.1595 s/iter. ETA=0:03:05\n",
      "\u001b[32m[10/04 20:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 775/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0483 s/iter. Total: 0.1598 s/iter. ETA=0:03:01\n",
      "\u001b[32m[10/04 20:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 808/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0480 s/iter. Total: 0.1594 s/iter. ETA=0:02:55\n",
      "\u001b[32m[10/04 20:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 840/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0480 s/iter. Total: 0.1594 s/iter. ETA=0:02:50\n",
      "\u001b[32m[10/04 20:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 873/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0479 s/iter. Total: 0.1593 s/iter. ETA=0:02:45\n",
      "\u001b[32m[10/04 20:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 906/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0478 s/iter. Total: 0.1592 s/iter. ETA=0:02:39\n",
      "\u001b[32m[10/04 20:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 939/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0478 s/iter. Total: 0.1592 s/iter. ETA=0:02:34\n",
      "\u001b[32m[10/04 20:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 971/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0478 s/iter. Total: 0.1592 s/iter. ETA=0:02:29\n",
      "\u001b[32m[10/04 20:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 1001/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0480 s/iter. Total: 0.1595 s/iter. ETA=0:02:24\n",
      "\u001b[32m[10/04 20:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 1033/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0479 s/iter. Total: 0.1594 s/iter. ETA=0:02:19\n",
      "\u001b[32m[10/04 20:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 1064/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0480 s/iter. Total: 0.1595 s/iter. ETA=0:02:14\n",
      "\u001b[32m[10/04 20:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 1095/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0483 s/iter. Total: 0.1598 s/iter. ETA=0:02:10\n",
      "\u001b[32m[10/04 20:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 1129/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0481 s/iter. Total: 0.1595 s/iter. ETA=0:02:04\n",
      "\u001b[32m[10/04 20:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 1162/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0480 s/iter. Total: 0.1594 s/iter. ETA=0:01:59\n",
      "\u001b[32m[10/04 20:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 1193/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0481 s/iter. Total: 0.1594 s/iter. ETA=0:01:54\n",
      "\u001b[32m[10/04 20:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 1225/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0481 s/iter. Total: 0.1594 s/iter. ETA=0:01:49\n",
      "\u001b[32m[10/04 20:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 1260/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0478 s/iter. Total: 0.1590 s/iter. ETA=0:01:43\n",
      "\u001b[32m[10/04 20:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 1291/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0479 s/iter. Total: 0.1591 s/iter. ETA=0:01:38\n",
      "\u001b[32m[10/04 20:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 1325/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0478 s/iter. Total: 0.1589 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/04 20:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 1357/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0478 s/iter. Total: 0.1588 s/iter. ETA=0:01:27\n",
      "\u001b[32m[10/04 20:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 1392/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0475 s/iter. Total: 0.1585 s/iter. ETA=0:01:21\n",
      "\u001b[32m[10/04 20:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 1425/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0475 s/iter. Total: 0.1584 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/04 20:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 1456/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0476 s/iter. Total: 0.1585 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/04 20:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 1486/1909. Dataloading: 0.0009 s/iter. Inference: 0.1100 s/iter. Eval: 0.0477 s/iter. Total: 0.1587 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/04 20:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 1514/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0478 s/iter. Total: 0.1591 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/04 20:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 1547/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0477 s/iter. Total: 0.1590 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/04 20:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 1580/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0476 s/iter. Total: 0.1589 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/04 20:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 1609/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0479 s/iter. Total: 0.1591 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/04 20:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 1641/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0479 s/iter. Total: 0.1591 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/04 20:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 1672/1909. Dataloading: 0.0009 s/iter. Inference: 0.1103 s/iter. Eval: 0.0480 s/iter. Total: 0.1592 s/iter. ETA=0:00:37\n",
      "\u001b[32m[10/04 20:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 1707/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0478 s/iter. Total: 0.1590 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/04 20:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 1739/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0478 s/iter. Total: 0.1590 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/04 20:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 1772/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0477 s/iter. Total: 0.1588 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/04 20:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 1806/1909. Dataloading: 0.0009 s/iter. Inference: 0.1102 s/iter. Eval: 0.0476 s/iter. Total: 0.1588 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/04 20:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 1836/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0478 s/iter. Total: 0.1589 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/04 20:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 1870/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0476 s/iter. Total: 0.1587 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/04 20:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 1903/1909. Dataloading: 0.0009 s/iter. Inference: 0.1101 s/iter. Eval: 0.0476 s/iter. Total: 0.1586 s/iter. ETA=0:00:00\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:02.153235 (0.158694 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:29 (0.110087 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:41:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:41:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/04 20:41:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:41:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.814\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.866\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.687\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.887\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.724\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.925\n",
      "\u001b[32m[10/04 20:41:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 81.370 | 89.311 | 86.559 | 0.000 | 68.738 | 88.736 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:41:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.47 seconds.\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.837\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.870\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.698 | 89.510 | 88.012 | 0.000 | 70.129 | 91.169 |\n",
      "\u001b[32m[10/04 20:41:19 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: 81.3703,89.3112,86.5585,0.0000,68.7381,88.7356\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:41:19 d2.evaluation.testing]: \u001b[0mcopypaste: 83.6981,89.5104,88.0120,0.0000,70.1287,91.1691\n",
      "\u001b[32m[10/04 20:41:19 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 3599  total_loss: 0.8685  loss_cls_stage0: 0.05962  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.02907  loss_box_reg_stage1: 0.2026  loss_cls_stage2: 0.02977  loss_box_reg_stage2: 0.3204  loss_mask: 0.05267  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.03041    time: 0.7626  last_time: 0.7032  data_time: 0.0031  last_data_time: 0.0071   lr: 6.1483e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:41:35 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 3619  total_loss: 0.8177  loss_cls_stage0: 0.05342  loss_box_reg_stage0: 0.09603  loss_cls_stage1: 0.03753  loss_box_reg_stage1: 0.1998  loss_cls_stage2: 0.0336  loss_box_reg_stage2: 0.3144  loss_mask: 0.04427  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.03234    time: 0.7627  last_time: 0.8899  data_time: 0.0032  last_data_time: 0.0081   lr: 5.5548e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:41:50 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 3639  total_loss: 0.9031  loss_cls_stage0: 0.06006  loss_box_reg_stage0: 0.1031  loss_cls_stage1: 0.03942  loss_box_reg_stage1: 0.2062  loss_cls_stage2: 0.02986  loss_box_reg_stage2: 0.3291  loss_mask: 0.04745  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.02711    time: 0.7626  last_time: 0.7934  data_time: 0.0029  last_data_time: 0.0073   lr: 4.9907e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:42:05 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 3659  total_loss: 0.9245  loss_cls_stage0: 0.0575  loss_box_reg_stage0: 0.09843  loss_cls_stage1: 0.04538  loss_box_reg_stage1: 0.2118  loss_cls_stage2: 0.04086  loss_box_reg_stage2: 0.3311  loss_mask: 0.05195  loss_rpn_cls: 0.02116  loss_rpn_loc: 0.02866    time: 0.7627  last_time: 0.7059  data_time: 0.0032  last_data_time: 0.0085   lr: 4.4563e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:42:21 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 3679  total_loss: 1.059  loss_cls_stage0: 0.06633  loss_box_reg_stage0: 0.1161  loss_cls_stage1: 0.04547  loss_box_reg_stage1: 0.2534  loss_cls_stage2: 0.04688  loss_box_reg_stage2: 0.3981  loss_mask: 0.04933  loss_rpn_cls: 0.02319  loss_rpn_loc: 0.03512    time: 0.7627  last_time: 0.7933  data_time: 0.0030  last_data_time: 0.0077   lr: 3.9516e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:42:36 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 3699  total_loss: 0.9963  loss_cls_stage0: 0.05556  loss_box_reg_stage0: 0.1158  loss_cls_stage1: 0.0425  loss_box_reg_stage1: 0.261  loss_cls_stage2: 0.0495  loss_box_reg_stage2: 0.4012  loss_mask: 0.04972  loss_rpn_cls: 0.01933  loss_rpn_loc: 0.02858    time: 0.7628  last_time: 0.8106  data_time: 0.0033  last_data_time: 0.0085   lr: 3.4767e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:42:52 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3719  total_loss: 0.9692  loss_cls_stage0: 0.06758  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.0445  loss_box_reg_stage1: 0.2158  loss_cls_stage2: 0.03082  loss_box_reg_stage2: 0.3403  loss_mask: 0.0493  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.03795    time: 0.7630  last_time: 0.8324  data_time: 0.0032  last_data_time: 0.0084   lr: 3.0319e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:43:08 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 3739  total_loss: 0.9473  loss_cls_stage0: 0.05614  loss_box_reg_stage0: 0.1024  loss_cls_stage1: 0.04298  loss_box_reg_stage1: 0.2229  loss_cls_stage2: 0.03733  loss_box_reg_stage2: 0.3482  loss_mask: 0.04704  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.02832    time: 0.7633  last_time: 0.8269  data_time: 0.0030  last_data_time: 0.0085   lr: 2.6171e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:43:24 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 3759  total_loss: 1.1  loss_cls_stage0: 0.07133  loss_box_reg_stage0: 0.1149  loss_cls_stage1: 0.05111  loss_box_reg_stage1: 0.2224  loss_cls_stage2: 0.04747  loss_box_reg_stage2: 0.3486  loss_mask: 0.05398  loss_rpn_cls: 0.02162  loss_rpn_loc: 0.03418    time: 0.7633  last_time: 0.7732  data_time: 0.0030  last_data_time: 0.0091   lr: 2.2325e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:43:40 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 3779  total_loss: 0.9137  loss_cls_stage0: 0.05756  loss_box_reg_stage0: 0.1086  loss_cls_stage1: 0.04258  loss_box_reg_stage1: 0.2056  loss_cls_stage2: 0.04448  loss_box_reg_stage2: 0.3166  loss_mask: 0.06047  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.03648    time: 0.7634  last_time: 0.9277  data_time: 0.0029  last_data_time: 0.0077   lr: 1.8783e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:43:55 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 3799  total_loss: 0.9085  loss_cls_stage0: 0.06061  loss_box_reg_stage0: 0.1096  loss_cls_stage1: 0.04558  loss_box_reg_stage1: 0.2137  loss_cls_stage2: 0.04296  loss_box_reg_stage2: 0.332  loss_mask: 0.04919  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.0473    time: 0.7635  last_time: 0.7585  data_time: 0.0030  last_data_time: 0.0089   lr: 1.5544e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:44:11 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 3819  total_loss: 1.04  loss_cls_stage0: 0.0516  loss_box_reg_stage0: 0.1196  loss_cls_stage1: 0.04245  loss_box_reg_stage1: 0.2411  loss_cls_stage2: 0.04036  loss_box_reg_stage2: 0.3432  loss_mask: 0.04909  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.03465    time: 0.7637  last_time: 0.7701  data_time: 0.0031  last_data_time: 0.0095   lr: 1.2609e-06  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:44:27 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3839  total_loss: 1.138  loss_cls_stage0: 0.06435  loss_box_reg_stage0: 0.1214  loss_cls_stage1: 0.05179  loss_box_reg_stage1: 0.2793  loss_cls_stage2: 0.0593  loss_box_reg_stage2: 0.3361  loss_mask: 0.04794  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.03126    time: 0.7639  last_time: 0.7690  data_time: 0.0029  last_data_time: 0.0087   lr: 9.9801e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:44:43 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 3859  total_loss: 0.8826  loss_cls_stage0: 0.04685  loss_box_reg_stage0: 0.1014  loss_cls_stage1: 0.02899  loss_box_reg_stage1: 0.2072  loss_cls_stage2: 0.03317  loss_box_reg_stage2: 0.2952  loss_mask: 0.04616  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.02964    time: 0.7640  last_time: 0.7895  data_time: 0.0031  last_data_time: 0.0078   lr: 7.6569e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:44:58 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 3879  total_loss: 1.007  loss_cls_stage0: 0.0682  loss_box_reg_stage0: 0.1111  loss_cls_stage1: 0.06216  loss_box_reg_stage1: 0.2412  loss_cls_stage2: 0.06217  loss_box_reg_stage2: 0.3577  loss_mask: 0.05305  loss_rpn_cls: 0.01606  loss_rpn_loc: 0.03132    time: 0.7640  last_time: 0.6379  data_time: 0.0029  last_data_time: 0.0086   lr: 5.6403e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:45:13 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 3899  total_loss: 0.8379  loss_cls_stage0: 0.05627  loss_box_reg_stage0: 0.1072  loss_cls_stage1: 0.03674  loss_box_reg_stage1: 0.1948  loss_cls_stage2: 0.04189  loss_box_reg_stage2: 0.3074  loss_mask: 0.05125  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.0238    time: 0.7639  last_time: 0.8077  data_time: 0.0031  last_data_time: 0.0044   lr: 3.9307e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:45:28 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 3919  total_loss: 1.028  loss_cls_stage0: 0.05881  loss_box_reg_stage0: 0.1094  loss_cls_stage1: 0.04108  loss_box_reg_stage1: 0.2426  loss_cls_stage2: 0.03997  loss_box_reg_stage2: 0.3631  loss_mask: 0.0527  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.03626    time: 0.7639  last_time: 0.7058  data_time: 0.0033  last_data_time: 0.0078   lr: 2.5286e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:45:44 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 3939  total_loss: 0.9642  loss_cls_stage0: 0.06106  loss_box_reg_stage0: 0.1063  loss_cls_stage1: 0.04851  loss_box_reg_stage1: 0.2266  loss_cls_stage2: 0.05801  loss_box_reg_stage2: 0.3212  loss_mask: 0.06153  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.03423    time: 0.7641  last_time: 0.8606  data_time: 0.0029  last_data_time: 0.0051   lr: 1.4343e-07  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:45:59 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 3959  total_loss: 1.023  loss_cls_stage0: 0.06019  loss_box_reg_stage0: 0.1162  loss_cls_stage1: 0.03898  loss_box_reg_stage1: 0.2434  loss_cls_stage2: 0.04  loss_box_reg_stage2: 0.3624  loss_mask: 0.05026  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.02834    time: 0.7640  last_time: 0.6083  data_time: 0.0029  last_data_time: 0.0081   lr: 6.4802e-08  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:46:15 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 3979  total_loss: 1.011  loss_cls_stage0: 0.06397  loss_box_reg_stage0: 0.1109  loss_cls_stage1: 0.03767  loss_box_reg_stage1: 0.2554  loss_cls_stage2: 0.04643  loss_box_reg_stage2: 0.3696  loss_mask: 0.0512  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.03327    time: 0.7641  last_time: 0.9336  data_time: 0.0031  last_data_time: 0.0084   lr: 1.7002e-08  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:46:31 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.9887  loss_cls_stage0: 0.06177  loss_box_reg_stage0: 0.1189  loss_cls_stage1: 0.03652  loss_box_reg_stage1: 0.2374  loss_cls_stage2: 0.03398  loss_box_reg_stage2: 0.3335  loss_mask: 0.05514  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.02662    time: 0.7641  last_time: 0.7808  data_time: 0.0030  last_data_time: 0.0087   lr: 3.8553e-11  max_mem: 5695M\n",
      "\u001b[32m[10/04 20:46:31 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:50:55 (0.7641 s / it)\n",
      "\u001b[32m[10/04 20:46:31 d2.engine.hooks]: \u001b[0mTotal training time: 1:42:29 (0:51:34 on hooks)\n",
      "\u001b[32m[10/04 20:46:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:46:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:46:31 d2.data.common]: \u001b[0mSerializing 1909 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:46:31 d2.data.common]: \u001b[0mSerialized dataset takes 23.19 MiB\n",
      "\u001b[32m[10/04 20:46:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 1909 batches\n",
      "\u001b[32m[10/04 20:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/1909. Dataloading: 0.0008 s/iter. Inference: 0.1089 s/iter. Eval: 0.0381 s/iter. Total: 0.1478 s/iter. ETA=0:04:40\n",
      "\u001b[32m[10/04 20:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 43/1909. Dataloading: 0.0008 s/iter. Inference: 0.1098 s/iter. Eval: 0.0474 s/iter. Total: 0.1581 s/iter. ETA=0:04:54\n",
      "\u001b[32m[10/04 20:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 71/1909. Dataloading: 0.0009 s/iter. Inference: 0.1186 s/iter. Eval: 0.0485 s/iter. Total: 0.1681 s/iter. ETA=0:05:08\n",
      "\u001b[32m[10/04 20:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 104/1909. Dataloading: 0.0009 s/iter. Inference: 0.1154 s/iter. Eval: 0.0472 s/iter. Total: 0.1635 s/iter. ETA=0:04:55\n",
      "\u001b[32m[10/04 20:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 137/1909. Dataloading: 0.0009 s/iter. Inference: 0.1138 s/iter. Eval: 0.0466 s/iter. Total: 0.1613 s/iter. ETA=0:04:45\n",
      "\u001b[32m[10/04 20:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 169/1909. Dataloading: 0.0009 s/iter. Inference: 0.1127 s/iter. Eval: 0.0467 s/iter. Total: 0.1604 s/iter. ETA=0:04:39\n",
      "\u001b[32m[10/04 20:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 202/1909. Dataloading: 0.0009 s/iter. Inference: 0.1122 s/iter. Eval: 0.0466 s/iter. Total: 0.1598 s/iter. ETA=0:04:32\n",
      "\u001b[32m[10/04 20:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 236/1909. Dataloading: 0.0009 s/iter. Inference: 0.1117 s/iter. Eval: 0.0459 s/iter. Total: 0.1585 s/iter. ETA=0:04:25\n",
      "\u001b[32m[10/04 20:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 267/1909. Dataloading: 0.0009 s/iter. Inference: 0.1116 s/iter. Eval: 0.0466 s/iter. Total: 0.1592 s/iter. ETA=0:04:21\n",
      "\u001b[32m[10/04 20:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 300/1909. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 0.0460 s/iter. Total: 0.1584 s/iter. ETA=0:04:14\n",
      "\u001b[32m[10/04 20:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 332/1909. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 0.0458 s/iter. Total: 0.1583 s/iter. ETA=0:04:09\n",
      "\u001b[32m[10/04 20:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 363/1909. Dataloading: 0.0009 s/iter. Inference: 0.1115 s/iter. Eval: 0.0464 s/iter. Total: 0.1588 s/iter. ETA=0:04:05\n",
      "\u001b[32m[10/04 20:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 396/1909. Dataloading: 0.0009 s/iter. Inference: 0.1114 s/iter. Eval: 0.0463 s/iter. Total: 0.1587 s/iter. ETA=0:04:00\n",
      "\u001b[32m[10/04 20:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 428/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0463 s/iter. Total: 0.1586 s/iter. ETA=0:03:54\n",
      "\u001b[32m[10/04 20:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 462/1909. Dataloading: 0.0009 s/iter. Inference: 0.1112 s/iter. Eval: 0.0459 s/iter. Total: 0.1580 s/iter. ETA=0:03:48\n",
      "\u001b[32m[10/04 20:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 495/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0459 s/iter. Total: 0.1577 s/iter. ETA=0:03:43\n",
      "\u001b[32m[10/04 20:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 526/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0464 s/iter. Total: 0.1581 s/iter. ETA=0:03:38\n",
      "\u001b[32m[10/04 20:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 556/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0474 s/iter. Total: 0.1591 s/iter. ETA=0:03:35\n",
      "\u001b[32m[10/04 20:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 586/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0479 s/iter. Total: 0.1596 s/iter. ETA=0:03:31\n",
      "\u001b[32m[10/04 20:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 618/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0479 s/iter. Total: 0.1596 s/iter. ETA=0:03:26\n",
      "\u001b[32m[10/04 20:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 649/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0480 s/iter. Total: 0.1597 s/iter. ETA=0:03:21\n",
      "\u001b[32m[10/04 20:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 678/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0485 s/iter. Total: 0.1603 s/iter. ETA=0:03:17\n",
      "\u001b[32m[10/04 20:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 710/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0484 s/iter. Total: 0.1602 s/iter. ETA=0:03:12\n",
      "\u001b[32m[10/04 20:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 741/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0485 s/iter. Total: 0.1603 s/iter. ETA=0:03:07\n",
      "\u001b[32m[10/04 20:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 772/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0487 s/iter. Total: 0.1606 s/iter. ETA=0:03:02\n",
      "\u001b[32m[10/04 20:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 803/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0488 s/iter. Total: 0.1606 s/iter. ETA=0:02:57\n",
      "\u001b[32m[10/04 20:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 836/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0485 s/iter. Total: 0.1603 s/iter. ETA=0:02:52\n",
      "\u001b[32m[10/04 20:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 867/1909. Dataloading: 0.0009 s/iter. Inference: 0.1109 s/iter. Eval: 0.0486 s/iter. Total: 0.1604 s/iter. ETA=0:02:47\n",
      "\u001b[32m[10/04 20:48:57 d2.evaluation.evaluator]: \u001b[0mInference done 900/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0485 s/iter. Total: 0.1603 s/iter. ETA=0:02:41\n",
      "\u001b[32m[10/04 20:49:02 d2.evaluation.evaluator]: \u001b[0mInference done 932/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0484 s/iter. Total: 0.1601 s/iter. ETA=0:02:36\n",
      "\u001b[32m[10/04 20:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 964/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0483 s/iter. Total: 0.1601 s/iter. ETA=0:02:31\n",
      "\u001b[32m[10/04 20:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 993/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0487 s/iter. Total: 0.1605 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/04 20:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 1025/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0487 s/iter. Total: 0.1604 s/iter. ETA=0:02:21\n",
      "\u001b[32m[10/04 20:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 1056/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0487 s/iter. Total: 0.1605 s/iter. ETA=0:02:16\n",
      "\u001b[32m[10/04 20:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 1087/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0489 s/iter. Total: 0.1607 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/04 20:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 1119/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0488 s/iter. Total: 0.1606 s/iter. ETA=0:02:06\n",
      "\u001b[32m[10/04 20:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 1151/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0488 s/iter. Total: 0.1605 s/iter. ETA=0:02:01\n",
      "\u001b[32m[10/04 20:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 1182/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0489 s/iter. Total: 0.1607 s/iter. ETA=0:01:56\n",
      "\u001b[32m[10/04 20:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 1215/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0489 s/iter. Total: 0.1605 s/iter. ETA=0:01:51\n",
      "\u001b[32m[10/04 20:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 1248/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0487 s/iter. Total: 0.1603 s/iter. ETA=0:01:45\n",
      "\u001b[32m[10/04 20:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 1281/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0487 s/iter. Total: 0.1603 s/iter. ETA=0:01:40\n",
      "\u001b[32m[10/04 20:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 1314/1909. Dataloading: 0.0009 s/iter. Inference: 0.1106 s/iter. Eval: 0.0486 s/iter. Total: 0.1601 s/iter. ETA=0:01:35\n",
      "\u001b[32m[10/04 20:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 1347/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0485 s/iter. Total: 0.1600 s/iter. ETA=0:01:29\n",
      "\u001b[32m[10/04 20:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 1381/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0484 s/iter. Total: 0.1598 s/iter. ETA=0:01:24\n",
      "\u001b[32m[10/04 20:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 1414/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0482 s/iter. Total: 0.1596 s/iter. ETA=0:01:19\n",
      "\u001b[32m[10/04 20:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 1445/1909. Dataloading: 0.0009 s/iter. Inference: 0.1104 s/iter. Eval: 0.0484 s/iter. Total: 0.1598 s/iter. ETA=0:01:14\n",
      "\u001b[32m[10/04 20:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 1473/1909. Dataloading: 0.0009 s/iter. Inference: 0.1105 s/iter. Eval: 0.0487 s/iter. Total: 0.1603 s/iter. ETA=0:01:09\n",
      "\u001b[32m[10/04 20:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 1504/1909. Dataloading: 0.0009 s/iter. Inference: 0.1107 s/iter. Eval: 0.0487 s/iter. Total: 0.1604 s/iter. ETA=0:01:04\n",
      "\u001b[32m[10/04 20:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 1535/1909. Dataloading: 0.0009 s/iter. Inference: 0.1108 s/iter. Eval: 0.0487 s/iter. Total: 0.1604 s/iter. ETA=0:01:00\n",
      "\u001b[32m[10/04 20:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 1565/1909. Dataloading: 0.0009 s/iter. Inference: 0.1110 s/iter. Eval: 0.0486 s/iter. Total: 0.1606 s/iter. ETA=0:00:55\n",
      "\u001b[32m[10/04 20:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 1593/1909. Dataloading: 0.0009 s/iter. Inference: 0.1113 s/iter. Eval: 0.0487 s/iter. Total: 0.1609 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/04 20:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 1618/1909. Dataloading: 0.0009 s/iter. Inference: 0.1116 s/iter. Eval: 0.0490 s/iter. Total: 0.1616 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/04 20:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 1646/1909. Dataloading: 0.0009 s/iter. Inference: 0.1119 s/iter. Eval: 0.0491 s/iter. Total: 0.1620 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/04 20:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 1672/1909. Dataloading: 0.0009 s/iter. Inference: 0.1122 s/iter. Eval: 0.0493 s/iter. Total: 0.1625 s/iter. ETA=0:00:38\n",
      "\u001b[32m[10/04 20:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 1701/1909. Dataloading: 0.0009 s/iter. Inference: 0.1125 s/iter. Eval: 0.0492 s/iter. Total: 0.1627 s/iter. ETA=0:00:33\n",
      "\u001b[32m[10/04 20:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 1732/1909. Dataloading: 0.0009 s/iter. Inference: 0.1125 s/iter. Eval: 0.0492 s/iter. Total: 0.1626 s/iter. ETA=0:00:28\n",
      "\u001b[32m[10/04 20:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 1766/1909. Dataloading: 0.0009 s/iter. Inference: 0.1124 s/iter. Eval: 0.0490 s/iter. Total: 0.1624 s/iter. ETA=0:00:23\n",
      "\u001b[32m[10/04 20:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 1799/1909. Dataloading: 0.0009 s/iter. Inference: 0.1124 s/iter. Eval: 0.0489 s/iter. Total: 0.1623 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/04 20:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 1829/1909. Dataloading: 0.0009 s/iter. Inference: 0.1123 s/iter. Eval: 0.0491 s/iter. Total: 0.1624 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/04 20:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 1862/1909. Dataloading: 0.0009 s/iter. Inference: 0.1123 s/iter. Eval: 0.0490 s/iter. Total: 0.1623 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/04 20:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 1896/1909. Dataloading: 0.0009 s/iter. Inference: 0.1122 s/iter. Eval: 0.0488 s/iter. Total: 0.1620 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/04 20:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:08.687096 (0.162126 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:33 (0.112197 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_balloon_segmentation_v2/inference/coco_instances_results.json\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.814\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.866\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.887\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.724\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.925\n",
      "\u001b[32m[10/04 20:51:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 81.428 | 89.324 | 86.569 | 0.000 | 68.778 | 88.723 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/04 20:51:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.03 seconds.\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.837\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.702\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.870\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.707 | 89.531 | 88.033 | 0.000 | 70.166 | 91.185 |\n",
      "\u001b[32m[10/04 20:51:46 d2.engine.defaults]: \u001b[0mEvaluation results for manga_balloon_val in csv format:\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: 81.4282,89.3244,86.5693,0.0000,68.7784,88.7232\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/04 20:51:46 d2.evaluation.testing]: \u001b[0mcopypaste: 83.7070,89.5314,88.0329,0.0000,70.1665,91.1845\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "\n",
    "print(\"Starting training process...\")\n",
    "print(f\"Training will run for {train_args['epochs']} epochs\")\n",
    "print(f\"Early stopping patience: {train_args['patience']} epochs\")\n",
    "print(f\"Results will be saved to: {os.path.join(train_args['project'], train_args['name'])}\")\n",
    "\n",
    "# Training\n",
    "from tqdm.notebook import tqdm\n",
    "with tqdm(total=train_args['epochs'], desc='Training Progress') as pbar:\n",
    "    def on_train_epoch_end(trainer):\n",
    "        pbar.update(1)\n",
    "    \n",
    "    results = model.train(\n",
    "        **train_args,\n",
    "        callbacks=[on_train_epoch_end]\n",
    "    )\n",
    "\n",
    "# Print detailed results summary\n",
    "print(\"\\n=== Training Completed ===\")\n",
    "metrics = results.results_dict\n",
    "print(\"\\nAccuracy Metrics:\")\n",
    "print(f\"mAP50-95: {metrics['metrics/mAP50-95(B)']:.4f} (primary metric)\")\n",
    "print(f\"mAP50: {metrics['metrics/mAP50(B)']:.4f}\")\n",
    "print(f\"Precision: {metrics['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall: {metrics['metrics/recall(B)']:.4f}\")\n",
    "\n",
    "print(\"\\nTraining Statistics:\")\n",
    "print(f\"Best epoch: {results.best_epoch}\")\n",
    "print(f\"Final epoch: {results.epoch}\")\n",
    "if results.epoch < train_args['epochs']:\n",
    "    print(\"Note: Training stopped early due to patience criterion\")\n",
    "\n",
    "# Save training plots\n",
    "results.plot_results()\n",
    "print(\"\\nTraining plots have been saved to the project directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up for testing ---\n",
      "Found best checkpoint: Iteration=3999 with segm/AP=83.7070\n",
      "Loading best model weights from: ./output_balloon_segmentation_v2/model_0003999.pth\n",
      "Copied best model to: ./output_balloon_segmentation_v2/model_best.pth\n",
      "\u001b[32m[10/04 21:07:27 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output_balloon_segmentation_v2/model_0003999.pth ...\n",
      "Predictor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Model Evaluation ---\n",
    "print(\"\\n=== Starting Model Evaluation ===\")\n",
    "\n",
    "# Validate on validation set\n",
    "print(\"\\nRunning validation...\")\n",
    "val_results = model.val(\n",
    "    data=yaml_path,\n",
    "    split='val',\n",
    "    conf=0.25,  # Confidence threshold\n",
    "    iou=0.45,   # NMS IOU threshold\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print detailed metrics\n",
    "metrics = val_results.results_dict\n",
    "print(\"\\nDetailed Evaluation Metrics:\")\n",
    "print(\"1. Average Precision (AP):\")\n",
    "print(f\"  - mAP50-95: {metrics['metrics/mAP50-95']:.4f}\")\n",
    "print(f\"  - mAP50: {metrics['metrics/mAP50']:.4f}\")\n",
    "print(f\"  - mAP75: {metrics['metrics/mAP75']:.4f}\")\n",
    "\n",
    "print(\"\\n2. Precision/Recall:\")\n",
    "print(f\"  - Precision: {metrics['metrics/precision']:.4f}\")\n",
    "print(f\"  - Recall: {metrics['metrics/recall']:.4f}\")\n",
    "\n",
    "print(\"\\n3. Performance:\")\n",
    "print(f\"  - Speed: {metrics.get('speed/inference', 'N/A')} ms per image\")\n",
    "print(f\"  - Total images: {val_results.need}\")\n",
    "print(f\"  - Processed images: {val_results.done}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "val_results.plot_confusion_matrix()\n",
    "print(\"\\nConfusion matrix has been saved to the project directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Qualitative Visualization on Random Validation Samples ---\n",
      "Processing sample 1/20: Manga='LoveHina_vol14', Page='011.jpg'\n",
      "Processing sample 2/20: Manga='TsubasaNoKioku', Page='023.jpg'\n",
      "Processing sample 3/20: Manga='BokuHaSitatakaKun', Page='037.jpg'\n",
      "Processing sample 4/20: Manga='PrayerHaNemurenai', Page='059.jpg'\n",
      "Processing sample 5/20: Manga='ARMS', Page='054.jpg'\n",
      "Processing sample 6/20: Manga='SaladDays_vol18', Page='064.jpg'\n",
      "Processing sample 7/20: Manga='SaladDays_vol18', Page='025.jpg'\n",
      "Processing sample 8/20: Manga='EvaLady', Page='047.jpg'\n",
      "Processing sample 9/20: Manga='BokuHaSitatakaKun', Page='087.jpg'\n",
      "Processing sample 10/20: Manga='EvaLady', Page='012.jpg'\n",
      "Processing sample 11/20: Manga='PikaruGenkiDesu', Page='081.jpg'\n",
      "Processing sample 12/20: Manga='BurariTessenTorimonocho', Page='049.jpg'\n",
      "Processing sample 13/20: Manga='PikaruGenkiDesu', Page='039.jpg'\n",
      "Processing sample 14/20: Manga='KyokugenCyclone', Page='039.jpg'\n",
      "Processing sample 15/20: Manga='ByebyeC-BOY', Page='060.jpg'\n",
      "Processing sample 16/20: Manga='OL_Lunch', Page='060.jpg'\n",
      "Processing sample 17/20: Manga='SonokiDeABC', Page='017.jpg'\n",
      "Processing sample 18/20: Manga='Joouari', Page='081.jpg'\n",
      "Processing sample 19/20: Manga='SeisinkiVulnus', Page='040.jpg'\n",
      "Processing sample 20/20: Manga='SaladDays_vol01', Page='046.jpg'\n",
      "Saved 20 visualization results to './balloon_test_visualizations'\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Visualize Predictions ---\n",
    "print(\"\\n=== Generating Visualizations ===\")\n",
    "\n",
    "# Create directories\n",
    "vis_output_dir = \"./balloon_test_visualizations\"\n",
    "os.makedirs(vis_output_dir, exist_ok=True)\n",
    "\n",
    "# Get validation images\n",
    "val_images_dir = os.path.join(DATASET_DIR, 'images/val')\n",
    "val_images = list(Path(val_images_dir).glob('*.jpg'))\n",
    "print(f\"\\nFound {len(val_images)} validation images\")\n",
    "\n",
    "# Select random samples\n",
    "num_samples = min(20, len(val_images))\n",
    "sample_images = random.sample(val_images, num_samples)\n",
    "\n",
    "print(f\"\\nProcessing {num_samples} random samples...\")\n",
    "for i, img_path in enumerate(sample_images, 1):\n",
    "    print(f\"\\nImage {i}/{num_samples}: {img_path.name}\")\n",
    "    \n",
    "    # Run prediction\n",
    "    results = model.predict(\n",
    "        source=str(img_path),\n",
    "        save=True,          # Save annotated images\n",
    "        save_txt=True,      # Save predictions as txt\n",
    "        conf=0.25,          # Confidence threshold\n",
    "        iou=0.45,          # NMS IOU threshold\n",
    "        line_width=2,       # Box thickness\n",
    "        boxes=True,         # Show boxes\n",
    "        labels=True,        # Show labels\n",
    "        hide_conf=False     # Show confidences\n",
    "    )\n",
    "    \n",
    "    # Print detection summary\n",
    "    r = results[0]  # Get first (only) result\n",
    "    print(f\"Detections: {len(r)} balloons\")\n",
    "    if len(r) > 0:\n",
    "        print(\"Confidence scores:\", [f\"{conf:.2f}\" for conf in r.boxes.conf])\n",
    "    \n",
    "    # Copy visualization\n",
    "    pred_img = Path(r.save_dir) / img_path.name\n",
    "    if pred_img.exists():\n",
    "        dest_path = os.path.join(vis_output_dir, img_path.name)\n",
    "        shutil.copy2(pred_img, dest_path)\n",
    "        print(f\"Saved visualization to: {dest_path}\")\n",
    "\n",
    "print(f\"\\nAll visualizations saved to '{vis_output_dir}'\")\n",
    "print(\"Note: Green boxes show predicted balloons with confidence scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Export and Save Model ---\n",
    "print(\"\\n=== Exporting Model ===\")\n",
    "\n",
    "# 1. Save PyTorch model\n",
    "best_model_path = 'balloon_detector_best.pt'\n",
    "shutil.copy2(str(model.best), best_model_path)\n",
    "print(f\"\\n1. PyTorch model saved as '{best_model_path}'\")\n",
    "\n",
    "# 2. Export to ONNX\n",
    "print(\"\\n2. Exporting to ONNX format...\")\n",
    "model.export(format='onnx', dynamic=True)\n",
    "print(\"ONNX model exported successfully\")\n",
    "\n",
    "# 3. Export to TensorRT (if supported)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print(\"\\n3. Exporting to TensorRT format...\")\n",
    "        model.export(format='engine', dynamic=True)\n",
    "        print(\"TensorRT model exported successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"TensorRT export failed: {e}\")\n",
    "\n",
    "# 4. Export to CoreML (if on MacOS)\n",
    "if os.uname().sysname == 'Darwin':\n",
    "    try:\n",
    "        print(\"\\n4. Exporting to CoreML format...\")\n",
    "        model.export(format='coreml', dynamic=True)\n",
    "        print(\"CoreML model exported successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"CoreML export failed: {e}\")\n",
    "\n",
    "# Save training plots\n",
    "print(\"\\nGenerating training plots...\")\n",
    "results.plot_results()\n",
    "print(\"Training plots saved in the project directory\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n=== Export Summary ===\")\n",
    "print(\"The following files have been created:\")\n",
    "print(f\"1. PyTorch model: {best_model_path}\")\n",
    "print(f\"2. ONNX model: {best_model_path.replace('.pt', '.onnx')}\")\n",
    "print(\"3. Training plots: In the project directory\")\n",
    "print(\"\\nModel is ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
