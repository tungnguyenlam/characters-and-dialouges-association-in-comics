{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02877384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "%cd ../..\n",
    "!ls\n",
    "# Now you should see the characters-and-dialouges-association-in-comics directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "END_WITH_LOCAL = 'characters-and-dialouges-association-in-comics'\n",
    "\n",
    "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (BASE_DIR.endswith('/content') or BASE_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "# --- 1. Re-register the datasets (important if in a new script/session) ---\n",
    "base_path = os.path.join(BASE_DIR, \"data\", \"Manga109_released_2023_12_07\")  # Adjusted to the new dataset directory\n",
    "images_dir = os.path.join(base_path, \"images\")\n",
    "train_json_path = os.path.join(base_path, \"train.json\")\n",
    "val_json_path = os.path.join(base_path, \"val.json\")\n",
    "\n",
    "# Register the datasets\n",
    "register_coco_instances(\"manga109_train\", {}, train_json_path, images_dir)\n",
    "register_coco_instances(\"manga109_val\", {}, val_json_path, images_dir)\n",
    "\n",
    "\n",
    "# --- 2. Setup Configuration ---\n",
    "cfg = get_cfg()\n",
    "# Use the same config file as for training\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(BASE_DIR, \"models/bubble-detection/detectron2/model_final_280758.pkl\")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "\n",
    "# cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "# Point to the model weights you just trained\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"./output\", \"model_final.pth\")\n",
    "\n",
    "# Set the number of classes (must match your training config)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # body, frame\n",
    "\n",
    "# Set the test dataset\n",
    "cfg.DATASETS.TEST = (\"manga109_val\",)\n",
    "\n",
    "# Set a confidence threshold for this evaluation\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # You can adjust this threshold\n",
    "\n",
    "\n",
    "# --- 3. Build the Model and Run Evaluation ---\n",
    "\n",
    "# Build the model from the config\n",
    "model = build_model(cfg)\n",
    "# Load the weights\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "# Create an evaluator for the validation dataset\n",
    "# It will save detailed results in the \"evaluation\" subfolder of your output directory\n",
    "evaluator = COCOEvaluator(\"manga109_val\", output_dir=\"./output/evaluation\")\n",
    "\n",
    "# Create a data loader for the validation set\n",
    "val_loader = build_detection_test_loader(cfg, \"manga109_val\")\n",
    "\n",
    "# Use the official `inference_on_dataset` tool\n",
    "# This will run the model on all images in the val_loader and feed the results to the evaluator\n",
    "print(\"Running evaluation...\")\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "\n",
    "# The results dictionary will also be printed, but the table above is the most readable\n",
    "print(\"\\nEvaluation results dictionary:\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
