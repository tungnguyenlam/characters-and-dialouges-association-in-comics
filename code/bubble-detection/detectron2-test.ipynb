{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02877384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "%cd ../..\n",
    "!ls\n",
    "# Now you should see the characters-and-dialouges-association-in-comics directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf60eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: e:\\B3\\group_prj\\characters-and-dialouges-association-in-comics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "END_WITH_LOCAL = 'characters-and-dialouges-association-in-comics'\n",
    "\n",
    "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "BASE_DIR = str(Path(os.getcwd()).parent.parent)\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "\n",
    "# Simple validation\n",
    "if not (BASE_DIR.endswith('/content') or BASE_DIR.endswith(END_WITH_LOCAL)):\n",
    "    raise ValueError(f\"Expected to be in .../{END_WITH_LOCAL} or .../content directory, but got: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea23fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3335f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.926\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.901\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
      "\n",
      "Evaluation results dictionary:\n",
      "OrderedDict([('bbox', {'AP': 76.24568365574332, 'AP50': 92.58497917880207, 'AP75': 90.08211426113459, 'APs': 0.0, 'APm': 61.66365276882435, 'APl': 78.57442040773026})])\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.926\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.901\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.823\n",
      "\n",
      "Evaluation results dictionary:\n",
      "OrderedDict([('bbox', {'AP': 76.24568365574332, 'AP50': 92.58497917880207, 'AP75': 90.08211426113459, 'APs': 0.0, 'APm': 61.66365276882435, 'APl': 78.57442040773026})])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "# --- 1. Re-register the datasets (important if in a new script/session) ---\n",
    "base_path = os.path.join(BASE_DIR, \"data\", \"Manga109\", \"Human_Annotate_300\")\n",
    "images_dir = os.path.join(base_path, \"train\")\n",
    "train_json_path = os.path.join(base_path, \"train.json\")\n",
    "val_json_path = os.path.join(base_path, \"val.json\")\n",
    "\n",
    "# Register the datasets\n",
    "register_coco_instances(\"manga109_train\", {}, train_json_path, images_dir)\n",
    "register_coco_instances(\"manga109_val\", {}, val_json_path, images_dir)\n",
    "\n",
    "\n",
    "# --- 2. Setup Configuration ---\n",
    "cfg = get_cfg()\n",
    "# Use the same config file as for training\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Set the device\n",
    "cfg.MODEL.DEVICE = str(device)\n",
    "\n",
    "# Point to the model weights you just trained\n",
    "model_output_dir = os.path.join(BASE_DIR, \"models\", \"bubble-detection\", \"detectron2\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(model_output_dir, \"model_final.pth\")\n",
    "\n",
    "# Set the number of classes (must match your training config)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # bubble\n",
    "\n",
    "# Set the test dataset\n",
    "cfg.DATASETS.TEST = (\"manga109_val\",)\n",
    "\n",
    "# Set a confidence threshold for this evaluation\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # You can adjust this threshold\n",
    "\n",
    "\n",
    "# --- 3. Build the Model and Run Evaluation ---\n",
    "\n",
    "# Build the model from the config\n",
    "model = build_model(cfg)\n",
    "# Load the weights\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "# Create an evaluator for the validation dataset\n",
    "eval_output_dir = os.path.join(model_output_dir, \"evaluation\")\n",
    "os.makedirs(eval_output_dir, exist_ok=True)\n",
    "evaluator = COCOEvaluator(\"manga109_val\", output_dir=eval_output_dir)\n",
    "\n",
    "# Create a data loader for the validation set\n",
    "val_loader = build_detection_test_loader(cfg, \"manga109_val\")\n",
    "\n",
    "# Use the official `inference_on_dataset` tool\n",
    "print(\"Running evaluation...\")\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "\n",
    "# The results dictionary will also be printed\n",
    "print(\"\\nEvaluation results dictionary:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e7b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.787\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.954\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.666\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.830\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.761\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844\n",
      "\n",
      "Evaluation results dictionary:\n",
      "OrderedDict([('bbox', {'AP': 78.7465316078129, 'AP50': 95.41467696540765, 'AP75': 92.78566721667364, 'APs': 0.0, 'APm': 66.59798704732262, 'APl': 80.49994059921681})])\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.787\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.954\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.666\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.830\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.761\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.844\n",
      "\n",
      "Evaluation results dictionary:\n",
      "OrderedDict([('bbox', {'AP': 78.7465316078129, 'AP50': 95.41467696540765, 'AP75': 92.78566721667364, 'APs': 0.0, 'APm': 66.59798704732262, 'APl': 80.49994059921681})])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "# --- 1. Re-register the datasets (important if in a new script/session) ---\n",
    "base_path = os.path.join(BASE_DIR, \"data\", \"Manga109\", \"Human_Annotate_300\")\n",
    "images_dir = os.path.join(base_path, \"train\")\n",
    "train_json_path = os.path.join(base_path, \"train.json\")\n",
    "val_json_path = os.path.join(base_path, \"val.json\")\n",
    "\n",
    "# Register the datasets\n",
    "register_coco_instances(\"manga109_train\", {}, train_json_path, images_dir)\n",
    "register_coco_instances(\"manga109_val\", {}, val_json_path, images_dir)\n",
    "\n",
    "\n",
    "# --- 2. Setup Configuration ---\n",
    "cfg = get_cfg()\n",
    "# Use the same config file as for training\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Set the device\n",
    "cfg.MODEL.DEVICE = str(device)\n",
    "\n",
    "# Point to the model weights you just trained\n",
    "model_output_dir = os.path.join(BASE_DIR, \"models\", \"bubble-detection\", \"detectron2\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(model_output_dir, \"model_final.pth\")\n",
    "\n",
    "# Set the number of classes (must match your training config)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # bubble\n",
    "\n",
    "# Set the test dataset\n",
    "cfg.DATASETS.TEST = (\"manga109_val\",)\n",
    "\n",
    "# Set a confidence threshold for this evaluation\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.01  # You can adjust this threshold\n",
    "\n",
    "\n",
    "# --- 3. Build the Model and Run Evaluation ---\n",
    "\n",
    "# Build the model from the config\n",
    "model = build_model(cfg)\n",
    "# Load the weights\n",
    "DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "\n",
    "# Create an evaluator for the validation dataset\n",
    "eval_output_dir = os.path.join(model_output_dir, \"evaluation\")\n",
    "os.makedirs(eval_output_dir, exist_ok=True)\n",
    "evaluator = COCOEvaluator(\"manga109_val\", output_dir=eval_output_dir)\n",
    "\n",
    "# Create a data loader for the validation set\n",
    "val_loader = build_detection_test_loader(cfg, \"manga109_val\")\n",
    "\n",
    "# Use the official `inference_on_dataset` tool\n",
    "print(\"Running evaluation...\")\n",
    "results = inference_on_dataset(model, val_loader, evaluator)\n",
    "\n",
    "# The results dictionary will also be printed\n",
    "print(\"\\nEvaluation results dictionary:\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
